 none 	o_k 
 none 	oh  i don t  
 none 	i think i m zero 
 none 	wow 
 none 	ah 
 none 	hello  hello  hello  hello 
 none 	wh  what causes the crash 
 none 	unprecedented 
 none 	did you fix something 
 none 	hello 
 none 	five  five 
 none 	oh  maybe it s the turning   turning off and turning on of the mike  right 
 none 	hello  hello 
 none 	uh  you think that s you 
 none 	yeah  o_k  mine s working 
 none 	aaa aaa aaa  o_k  that s me 
 none 	oh 
 none 	o_k 
 none 	o_k  so  um i guess we are um gonna do the digits at the end 
 none 	uh
 none 	channel   channel three  yeah  o_k 
 none 	mmm  channel five 
 none 	channel two 
 none 	doesn t work 
 none 	two 
 none 	yeah  that s the mike number there  uh
 none 	no 
 none 	is it written on her sheet  i believe 
 none 	mike four 
 none 	watch this  yep  that s me 
 none 	uh  mike number five  and channel   channel four 
 none 	ah  era el cuatro  yeah 
 none 	but  channel
 none 	yeah yeah yeah 
 none 	this is you 
 none 	o_k  i saw that 
 none 	ah   yeah  it s o_k 
 none 	yeah 
 none 	and i m channel uh two i think  or channel  
 none 	ooo 
 none 	i think i m channel two 
 none 	oh  i m channel   must be channel one  channel one  yes  o_k 
 none 	channel  
 none 	o_k  so uh
 find_email 	i also copied uh the results that we all got in the mail i think from uh   from  o_g_i  and we ll go   go through them also  
 none 	so where are we on   on uh our runs 
 none 	uh so  uh   we   so as i was already said  we   we mainly focused on
 none 	uh four kind of features  the p_l_p  the p_l_p with j_rasta  the m_s_g  and the m_f_c_c from the baseline aurora 
 none 	excuse me 
 none 	i decided to talk about that 
 none 	mm hmm 
 none 	uh  and we focused for the   the test part on the english and the italian 
 none 	um  we ve trained uh several neural networks on   so   on the t_i digits english and on the italian data and also on the broad uh english uh french and uh spanish databases 
 none 	mmm  so there s our result tables here  for the tandem approach  and um  actually what we   we  observed is that if the network is trained on the task data it works pretty well 
 none 	i can t get back far enough 
 none 	chicken on the grill 
 none 	o_k  our   our uh  
 none 	there s a   we re pausing for a photo  
 none 	sorry  guys 
 none 	try that corner 
 none 	how about over th  from the front of the room 
 none 	yeah  it s longer 
 none 	we re pausing for a photo opportunity here  uh 
 none 	uh 
 none 	so 
 none 	oh wait wait wait wait wait  wait  hold on  hold on  let me give you a black screen 
 none 	get out of the   yeah 
 none 	o_k 
 none 	one more 
 none 	he s facing this way 
 none 	because we said we were gonna do this and i just remembered 
 none 	what 
 none 	o_k  this   this would be a good section for our silence detection 
 none 	o_k 
 none 	um
 none 	mm hmm 
 none 	musical chairs everybody 
 none 	oh 
 none 	o_k 
 none 	so um  you were saying about the training data  
 none 	yeah  so if the network is trained on the task data um tandem works pretty well  and uh actually we have uh  results are similar
 none 	yeah 
 none 	do you mean if it s trained only on  
 none 	only on  yeah 
 none 	on data from just that task  that language 
 none 	just that task 
 none 	but actually we didn t train network on uh both types of data i mean uh phonetically ba  phonetically balanced uh data and task data 
 none 	we only did either task   task data or uh broad data 
 none 	mmm 
 none 	mm hmm 
 none 	um
 none 	yeah  so 
 none 	so how   i mean   clearly it s gonna be good then but the question is how much worse is it if you have broad data 
 none 	so what s th 
 none 	i mean  my assump 
 none 	from what i saw from the earlier results  uh i guess last week  was that um  if you trained on one language and tested on another  say  that the results were   were relatively poor 
 none 	mmm  yeah 
 none 	but   but the question is if you train on one language but you have a broad coverage and then test in another  does that   is that improve things i  c  in comparison 
 none 	if we use the same language 
 none 	no  no  no 
 none 	different lang 
 none 	so um
 none 	if you train on t_i digits and test on italian digits  you do poorly  let s say 
 none 	mm hmm 
 none 	i don t have the numbers in front of me  so i m just imagining 
 none 	but  
 none 	yeah but i did not uh do that  we  
 none 	e 
 none 	so  you didn t train on timit and test on   on italian digits  say 
 none 	no  we did four   four kind of   of testing  actually 
 none 	the first testing is with task data  
 none 	so  with nets trained on task data 
 none 	so for italian on the italian speech   
 none 	the second test is trained on a single language um with broad database  but the same language as the t  task data 
 none 	o_k 
 none 	but for italian we choose spanish which we assume is close to italian 
 none 	the third test is by using  um the three language database and the fourth is
 none 	w  which in   it has three languages  that s including the w  the   the   the one that it s  
 none 	this includes  
 none 	yeah 
 none 	but not digits  i mean it s  
 none 	in 
 none 	right 
 none 	the three languages is not digits  it s the broad data  o_k 
 none 	yeah
 none 	and the fourth test is uh excluding from these three languages the language that is the task language 
 none 	oh  o_k  yeah  so  that is what i wanted to know 
 none 	yeah 
 none 	i just wasn t saying it very well  i guess 
 none 	uh  yeah 
 none 	so um for uh t_i digits for ins  example uh when we go from t_i digits training to timit training uh we lose uh around ten percent  uh 
 none 	relative 
 none 	the error rate increase u  of   of   of ten percent  relative 
 none 	right 
 none 	so this is not so bad  and then when we jump to the multilingual data it s uh it become worse and  well
 none 	ab  about how much 
 none 	around uh  let s say  twenty perc  twenty percent further  so  yeah 
 none 	twenty percent further 
 none 	twenty to   to thirty percent further  yeah 
 none 	and so  remind me  the multilingual stuff is just the broad data  right 
 none 	yeah 
 none 	it s not the digits  so it s the combination of two things there 
 none 	it s removing the task specific training and it s adding other languages 
 none 	yeah 
 none 	yeah 
 none 	o_k 
 none 	but the first step is al  already removing the task s  specific from   from  
 none 	already  right right right 
 none 	so  and we lose  
 none 	so they were sort of building here  o_k 
 none 	yeah 
 none 	uh so  basically when it s trained on the   the multilingual broad data um or number   so  the   the ratio of our error rates uh with the baseline error rate is around uh one point one 
 none 	so 
 none 	yes 
 none 	and it s something like one point three of   of the uh  
 none 	i  i  if you compare everything to the first case at the baseline  you get something like one point one for the   for the using the same language but a different task  and something like one point three for three   three languages broad stuff 
 none 	no no no 
 none 	uh same language we are at uh   for at english at o_ point eight 
 none 	so it improves  compared to the baseline 
 none 	but  
 none 	so  le  let me 
 none 	i   i   i m sorry  i   i   i meant something different by baseline
 none 	tas  task data we are u 
 none 	yeah 
 none 	so let me   let me  
 none 	um  so  um  
 none 	mmm 
 none 	o_k  fine  let s   let s use the conventional meaning of baseline  i   i  
 none 	hmm 
 none 	by baseline here i meant uh using the task specific data 
 none 	oh yeah  the f 
 none 	yeah  o_k  yeah 
 none 	but uh   uh  because that s what you were just doing with this ten percent 
 none 	so i was just   i just trying to understand that  so if we call a factor of w  just one  just normalized to one  the word error rate that you have for using t_i digits as   as training and t_i digits as test  uh different words  i m sure  but   but uh  uh the same task and so on 
 none 	yeah  sure 
 none 	mmm 
 none 	mm hmm 
 none 	if we call that  one   then what you re saying is that the word error rate for the same language but using uh different training data than you re testing on  say timit and so forth  it s one point one 
 none 	mm hmm 
 none 	mm hmm 
 none 	yeah  it s around one point one  yeah 
 none 	right 
 none 	and if it s   you do go to three languages including the english  it s something like one point three 
 none 	ye 
 none 	that s what you were just saying  i think 
 none 	uh  more actually  if i  
 none 	one point four 
 none 	yeah 
 none 	so  it s an additional thirty percent 
 none 	what would you say  around one point four yeah 
 none 	o_k 
 none 	and if you exclude english  from this combination  what s that 
 none 	if we exclude english  um there is not much difference with the data with english 
 none 	aha 
 none 	so 
 none 	yeah 
 none 	that s interesting 
 none 	that s interesting 
 none 	do you see  because  
 none 	uh 
 none 	uh  so  
 none 	no  that   that s important  so what   what it s saying here is just that  yes  there is a reduction in performance  when you don t um have the s  when you don t have um
 none 	task data 
 none 	wait a minute  th  th  the  
 none 	hmm 
 none 	no  actually it s interesting  so it s  
 none 	so when you go to a different task  there s actually not so different  it s when you went to these  
 none 	so what s the difference between two and three 
 none 	between the one point one case and the one point four case  i m confused 
 none 	it s multilingual 
 none 	yeah  the only difference it s   is that it s multilingual  
 none 	um yeah 
 none 	cuz in both   in both   both of those cases  you don t have the same task 
 none 	yeah sure 
 none 	so is   is the training data for the   for this one point four case   does it include the training data for the one point one case 
 none 	uh yeah 
 none 	yeah  a fraction of it 
 none 	a part of it  yeah 
 none 	how m  how much bigger is it 
 none 	um
 none 	yeah  um 
 none 	it s two times  actually  yeah 
 none 	um 
 none 	the english data  
 none 	no  the multilingual databases are two times the broad english data 
 none 	we just wanted to keep this  w  well  not too huge  so 
 none 	so it s two times  but it includes the   but it includes the broad english data 
 none 	i think so  do you  
 none 	uh 
 none 	yeah 
 none 	and the broad english data is what you got this one point one with  so that s timit basically right 
 none 	mm hmm 
 none 	yeah 
 none 	so it s band limited timit 
 none 	mm hmm 
 none 	mm hmm 
 none 	this is all eight kilohertz sampling 
 none 	yeah 
 none 	downs 
 none 	right 
 none 	so you have band limited timit  gave you uh almost as good as a result as using t_i  digits on a t_i digits test 
 none 	o_k 
 none 	hmm 
 none 	um and um
 none 	but  when you add in more training data but keep the neural net the same size  it um performs worse on the t_i digits 
 none 	o_k  now all of this is  
 none 	this is noisy t_i digits  i assume 
 none 	yep 
 none 	both training and test 
 none 	yeah  o_k 
 none 	um
 none 	o_k 
 none 	well 
 none 	we   we   we may just need to uh  
 none 	so i mean it s interesting that h  going to a different   different task didn t seem to hurt us that much  and going to a different language um
 none 	it doesn t seem to matter  
 none 	the difference between three and four is not particularly great  so that means that whether you have the language in or not is not such a big deal 
 none 	mmm 
 none 	it sounds like um uh we may need to have more of uh things that are similar to a target language or   i mean 
 none 	you have the same number of parameters in the neural net  you haven t increased the size of the neural net  and maybe there s just   just not enough complexity to it to represent the variab  increased variability in the   in the training set 
 none 	that   that could be 
 none 	um
 none 	so  what about  
 none 	so these are results with uh th  that you re describing now  that they are pretty similar for the different features or   or uh  
 none 	uh  let me check  uh 
 none 	so  this was for the p_l_p 
 none 	yeah 
 none 	um  the   yeah  for the p_l_p with j_rasta the   the   we  
 none 	yeah 
 none 	this is quite the same tendency  with a slight increase of the error rate  uh if we go to   to timit 
 none 	and then it s   it gets worse with the multilingual 
 none 	um 
 none 	yeah  there   there is a difference actually with   b  between p_l_p and j_rasta is that
 none 	j_rasta seems to perform better with the highly mismatched condition but slightly   slightly worse for the well matched condition 
 none 	mmm 
 none 	i have a suggestion  actually  even though it ll delay us slightly  would   would you mind running into the other room and making copies of this  cuz we re all sort of  
 none 	yeah  yeah 
 none 	if we c  if we could look at it  while we re talking  i think it  d be uh  
 none 	o_k 
 none 	uh  i ll   i ll sing a song or dance or something while you do it  too 
 none 	alright 
 none 	so um   go ahead  ah  while you re gone i ll ask s  some of my questions 
 none 	yeah 
 none 	um 
 none 	yeah 
 none 	uh  this way and just slightly to the left  yeah 
 none 	the um  
 none 	what was   was this number forty or   it was roughly the same as this one  he said  when you had the two language versus the three language 
 none 	um 
 none 	that s what he was saying 
 none 	that s where he removed english  right 
 none 	yeah 
 none 	right 
 none 	it sometimes  actually  depends on what features you re using 
 none 	yeah 
 none 	but   but i  it sounds like  
 none 	um  but  
 none 	i mean  that s interesting because it   it seems like what it s saying is not so much that you got hurt uh because you uh didn t have so much representation of english  because in the other case you don t get hurt any more  at least when it seemed like uh it   it might simply be a case that you have something that is just much more diverse  but you have the same number of parameters representing it 
 none 	mm hmm 
 none 	mm hmm  i wonder   were um all three of these nets using the same output  this multi language uh labeling 
 none 	he  
 none 	mm hmm 
 none 	he was using uh sixty four phonemes from sampa 
 none 	o_k  o_k 
 none 	yeah 
 none 	so this would  
 none 	from this you would say   well  it doesn t really matter if we put finnish into the training of the neural net  if there s gonna be  you know  finnish in the test data   right 
 none 	well  it s   it sounds  
 none 	i mean  we have to be careful  cuz we haven t gotten a good result yet 
 none 	yeah 
 none 	and comparing different bad results can be tricky 
 none 	hmm 
 none 	but i   i   i  
 none 	i think it does suggest that it s not so much uh uh cross language as cross type of speech 
 none 	mm hmm 
 none 	it s   it s um  
 none 	but we did   oh yeah  the other thing i was asking him  though  is that i think that in the case  
 none 	yeah  you   you do have to be careful because of com  compounded results  i think we got some earlier results in which you trained on one language and tested on another and you didn t have three  but you just had one language  so you trained on one type of digits and tested on another  didn 
 none 	wasn t there something of that  where you  say  trained on spanish and tested on   on t_i digits  or the other way around 
 none 	something like that 
 none 	no 
 none 	i thought there was something like that  that he showed me last week 
 none 	we ll have to wait till we get  
 none 	yeah  that would be interesting 
 none 	um 
 none 	this may have been what i was asking before  stephane  but   but  um  wasn t there something that you did  where you trained on one language and tested on another 
 none 	i mean no   no mixture but just  
 none 	i ll get it for you 
 none 	uh  no  no 
 none 	we ve never just trained on one lang 
 none 	training on a single language  you mean  and testing on the other one 
 none 	yeah 
 none 	not yet 
 none 	uh  no 
 none 	so the only task that s similar to this is the training on two languages  and that  
 none 	but we ve done a bunch of things where we just trained on one language  right 
 none 	i mean  you haven t   you haven t done all your tests on multiple languages 
 none 	uh 
 none 	no 
 none 	either thi  this is test with uh the same language but from the broad data  or it s test with uh different languages also from the broad data  excluding the  
 none 	the early experiment that  
 none 	so  it s   it s three or   three and four 
 none 	did you do different languages from digits 
 none 	uh  no 
 none 	you mean training digits on one language and using the net to recognize on the other 
 none 	digits on another language 
 none 	no 
 none 	see  i thought you showed me something like that last week 
 none 	you had a   you had a little  
 none 	uh 
 none 	no  i don t think so 
 none 	um
 none 	what  
 none 	these numbers are uh ratio to baseline 
 none 	so  i mean wha  what s the   this   this chart   this table that we re looking at is um 
 none 	so 
 none 	show  is all testing for t_i  digits  or    
 none 	bigger is worse  this is error rate  i think 
 none 	so you have uh basically two uh parts  the upper part is for t_i digits and it s divided in three rows of four   four rows each 
 none 	ratio 
 none 	no  no 
 none 	yeah  yeah  yeah 
 none 	mm hmm 
 none 	yeah 
 none 	and the first four rows is well matched  then the s  the second group of four rows is mismatched  and finally highly mismatched 
 none 	and then the lower part is for italian and it s the same   the same thing 
 none 	so  so the upper part is training t_i digits 
 none 	so 
 none 	it s   it s the h_t_k results  i mean  so it s
 none 	h_t_k training testings with different kind of features and what appears in the uh left column is the networks that are used for doing this 
 none 	ah 
 none 	hmm 
 none 	so 
 none 	uh
 none 	yeah 
 none 	well 
 none 	what was is that i 
 open_agenda 	what was it that you had done last week when you showed   do you remember 
 none 	wh  when you showed me the   your table last week 
 none 	it  it was part of these results 
 none 	mmm 
 none 	mmm 
 none 	so where is the baseline for the t_i digits located in here 
 none 	you mean the h_t_k aurora baseline 
 none 	yeah 
 none 	it s uh the one hundred number 
 none 	it s  well  all these numbers are the ratio with respect to the baseline 
 none 	ah 
 none 	ah  o_k  o_k 
 none 	so this is word   word error rate  so a high number is bad 
 none 	yeah  this is a word error rate ratio 
 none 	yeah 
 none 	yeah 
 none 	o_k  i see 
 none 	so  seventy point two means that we reduced the error rate uh by thirty   thirty percent  so 
 none 	o_k  o_k  gotcha 
 none 	o_k  so if we take uh um let s see
 none 	hmm 
 none 	p_l_p uh with on line normalization and delta del  so that s this thing you have circled here in the second column  um and  multi english  refers to what 
 none 	yeah 
 none 	to timit 
 none 	mmm 
 none 	then you have uh m_f  m_s and m_e which are for french  spanish and english 
 none 	and  yeah 
 none 	actually i   i uh forgot to say that the multilingual net are trained on uh features without the s  derivatives uh but with increased frame numbers  mmm 
 none 	and we can   we can see on the first line of the table that it   it   it s slightly   slightly worse when we don t use delta but it s not   not that much 
 none 	right 
 none 	so w  w 
 none 	so  i m sorry  i missed that  what s m_f  m_s and m_e 
 none 	multi french  multi spanish
 none 	so  multi french  multi spanish  and multi english 
 none 	uh o_k  so  it s uh broader vocabulary 
 none 	yeah 
 none 	then  
 none 	and  
 none 	o_k so i think what i m   what i saw in your smaller chart that i was thinking of was   was there were some numbers i saw  i think  that included these multiple languages and it   and i was seeing that it got worse 
 none 	i   i think that was all it was  you had some very limited results that   at that point which showed having in these   these other languages  in fact it might have been just this last category  having two languages broad that were   where   where english was removed 
 none 	yeah 
 none 	so that was cross language and the   and the result was quite poor 
 none 	what i   we hadn t seen yet was that if you added in the english  it s still poor 
 none 	yeah  still poor 
 none 	uh
 none 	um now  what s the noise condition um of the training data  
 none 	well  i think this is what you were explaining  the noise condition is the same  
 none 	it s the same uh aurora noises uh  in all these cases for the training 
 none 	yeah 
 none 	yeah 
 none 	so there s not a statistical   sta  a strong st  statistically different noise characteristic between uh the training and test and yet we re seeing some kind of effect  
 none 	no these are the s  s  s  same noises  yeah 
 none 	at least   at least for the first   for the well matched  yeah 
 none 	well matched condition 
 none 	right 
 none 	so there s some kind of a   a   an effect from having these   uh this broader coverage um
 create_single_reminder 	now i guess what we should try doing with this is  try testing these on u  this same sort of thing on    you probably must have this lined up to do    to try the same t  with the exact same training  do testing on the other languages  
 none 	mmm 
 none 	on   on um  
 none 	so 
 none 	um  oh i well  wait a minute  you have this here  for the italian  that s right  o_k  so 
 none 	yeah 
 none 	yeah  so for the italian the results are uh stranger um
 none 	so 
 none 	mmm 
 none 	so what appears is that perhaps spanish is not very close to italian because uh  well  when using the   the network trained only on spanish it s   the error rate is almost uh twice the baseline error rate 
 none 	mm hmm 
 none 	mmm  uh 
 none 	well  i mean  let s see 
 none 	is there any difference in  
 none 	so it s in the uh  
 none 	so you re saying that when you train on english and uh and   and test on  
 none 	yeah 
 none 	no  you don t have training on english testing  
 none 	there   there is   another difference  is that the noise   the noises are different  well 
 none 	in   in what 
 none 	for   for the italian part i mean the uh the um networks are trained with noise from aurora   t_i  digits  mmm 
 none 	aurora two 
 none 	yeah 
 none 	and the noise is different in th 
 none 	and perhaps the noise are quite different from the noises in the speech that italian  
 none 	and  
 none 	do we have any um test sets uh in any other language that um have the same noise as in the aurora 
 none 	mmm  no 
 none 	no 
 none 	can i ask something real quick 
 none 	in   in the upper part   in the english stuff  it looks like the very best number is sixty point nine  and that s in the uh   the third section in the upper part under p_l_p j_rasta  sort of the middle column 
 none 	yeah 
 none 	i  is that a noisy condition 
 none 	yeah 
 none 	so that s matched training  is that what that is 
 none 	it s   no  the third part  so it s uh highly mismatched 
 none 	so  training and test noise are different 
 none 	so   why do you get your best number in  
 none 	wouldn t you get your best number in the clean case 
 none 	well  it s relative to the um baseline mismatching
 none 	yeah 
 none 	ah  o_k so these are not  
 none 	yeah 
 none 	o_k  alright  i see 
 none 	yeah 
 none 	yeah 
 none 	o_k 
 none 	and then   so  in the   in the um   in the non mismatched clean case  your best one was under m_f_c_c 
 none 	that sixty one point four 
 none 	yeah  but it s not a clean case  it s a noisy case but uh training and test noises are the same 
 none 	oh  so this upper third 
 none 	so   yeah 
 none 	uh that s still noisy 
 none 	yeah 
 none 	ah  o_k 
 none 	so it s always noisy basically  and  well  the  
 none 	mm hmm 
 none 	i see 
 none 	mmm 
 none 	o_k 
 none 	um
 none 	so uh  i think this will take some looking at  thinking about  but  what is uh   what is currently running  that s   uh  i  that   just filling in the holes here or   or     pretty much 
 none 	uh  no we don t plan to fill the holes but actually there is something important  is that um we made a lot of assumption concerning the on line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to h_t_k 
 none 	o_k 
 none 	um
 none 	mmm  so basically d  if you look at the   at the left of the table  the first uh row  with eighty six  one hundred  and forty three and seventy five  these are the results we obtained for italian uh with straight mmm  p_l_p features using on line normalization 
 none 	mm hmm 
 none 	mmm 
 none 	and the  mmm   what s in the table  just at the left of the p_l_p twelve on line normalization column  so  the numbers seventy nine  fifty four and uh forty two are the results obtained by uh pratibha with uh his on line normalization   uh her on line normalization approach 
 none 	where is that  seventy nine  fifty
 none 	fifty one  this  
 none 	uh  it s just sort of sitting right on the uh   the column line 
 none 	so 
 none 	uh 
 none 	oh i see  o_k 
 none 	just   uh
 none 	yeah 
 none 	yeah 
 none 	so these are the results of o_g_i with on line normalization and straight features to h_t_k 
 none 	and the previous result  eighty six and so on  are with our features straight to h_t_k  so what we see that   is   there is that um uh the way we were doing this was not correct  but still the networks are very good 
 none 	yes 
 none 	yes 
 none 	when we use the networks our number are better that uh pratibha results 
 none 	we improve 
 none 	so  do you know what was wrong with the on line normalization  or    
 none 	yeah  there were diff  there were different things and basically  the first thing is the mmm  alpha uh value  so  the recursion uh part  um 
 none 	i used point five percent  which was the default value in the   in the programs here 
 none 	and pratibha used five percent 
 none 	uh huh 
 none 	so it adapts more quickly
 none 	yes  yeah 
 none 	um  but  yeah  i assume that this was not important because uh previous results from   from dan and   show that basically the both   both values g  give the same   same uh results 
 none 	it was true on uh t_i digits but it s not true on italian 
 none 	mm hmm 
 none 	uh  second thing is the initialization of the stuff  actually  uh what we were doing is to start the recursion from the beginning of the utterance 
 none 	and using initial values that are the global mean and variances measured across the whole database 
 none 	right  right 
 none 	and pratibha did something different is that he   uh she initialed the um values of the mean and variance by computing this on the twenty five first frames of each utterance 
 none 	mmm  there were other minor differences  the fact that she used fifteen dissities instead s  instead of thirteen  and that she used c_zero instead of log energy 
 none 	uh  but the main differences concerns the recursion 
 none 	so 
 none 	uh  i changed the code uh and now we have a baseline that s similar to the o_g_i baseline 
 none 	o_k 
 none 	we   it   it s slightly uh different because
 none 	i don t exactly initialize the same way she does 
 none 	actually i start  mmm  i don t wait to a fifteen   twenty five   twenty five frames before computing a mean and the variance to e  to   to start the recursion 
 none 	mm hmm 
 none 	yeah 
 none 	i   i use the on line scheme and only start the re  recursion after the twenty five   twenty fifth frame 
 none 	but  well it s similar 
 none 	so uh i retrained the networks with these   well  the   the   the networks are retaining with these new features 
 none 	mm hmm 
 none 	and  yeah 
 none 	o_k 
 none 	so basically what i expect is that these numbers will a little bit go down but perhaps not   not so much because i think the neural networks learn perhaps to   even if the features are not normalized  it   it will learn how to normalize and  
 none 	right 
 none 	right 
 none 	o_k  but i think that given the pressure of time we probably want to draw   because of that especially  we wanna draw some conclusions from this  do some reductions in what we re looking at  and make some strong decisions for what we re gonna do testing on before next week 
 none 	mmm 
 none 	yeah 
 none 	yeah i d  
 none 	so do you   are you   w  did you have something going on  on the side  with uh multi band or   on   on this  or    
 none 	no  i   we plan to start this uh so  act  actually we have discussed uh um  these   what we could do more as a   as a research and   and we were thinking perhaps that uh the way we use the tandem is not  
 none 	uh  well  there is basically perhaps a flaw in the   in the   the stuff because we trained the networks  
 none 	if we trained the networks on the   on a language and a t  or a specific task  um  what we ask is   to the network   is to put the bound  the decision boundaries somewhere in the space 
 none 	mm hmm 
 none 	and uh mmm and ask the network to put one  at one side of the   for   for a particular phoneme at one side of the boundary   decision boundary and one for another phoneme at the other side 
 none 	mmm 
 none 	and so there is kind of reduction of the information there that s not correct because if we change task and if the phonemes are not in the same context in the new task  obviously the decision boundaries are not   should not be at the same place 
 none 	but the way the feature gives  
 none 	i di 
 none 	the   the way the network gives the features is that it reduce completely the   it removes completely the information   a lot of information from the   the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data 
 none 	it s a trade off  right  any  anyway go ahead 
 none 	so  
 none 	yeah  so uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks 
 none 	doing something like  um um phonemes within context and  well  basically context dependent phonemes 
 none 	maybe  i mean  i   i think you could make the same argument  it d be just as legitimate  for hybrid systems as well 
 none 	yeah but  we know that  
 none 	right 
 none 	and in fact  th  things get better with context dependent versions 
 none 	right 
 none 	ye  yeah but here it s something different  we want to have features uh well  um 
 none 	yeah 
 none 	yeah  but it s still true that what you re doing is you re ignoring   you re   you re coming up with something to represent  whether it s a distribution  probability distribution or features  you re coming up with a set of variables that are representing uh  things that vary w  over context 
 none 	mm hmm 
 none 	uh  and you re putting it all together  ignoring the differences in context 
 none 	that   that s true for the hybrid system  it s true for a tandem system 
 none 	so  for that reason  when you   in   in   in a hybrid system  when you incorporate context one way or another  you do get better scores 
 none 	yeah 
 none 	o_k  but i   it s   it s a big deal to get that 
 none 	i   i m   i m sort of  
 none 	and once you   the other thing is that once you represent   start representing more and more context it is uh much more um specific to a particular task in language 
 none 	so um
 none 	uh  the   the acoustics associated with uh a particular context  for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other  so the qu  the issue of getting enough training for a particular kind of context becomes harder 
 none 	we already actually don t have a huge amount of training data um
 none 	yeah  but  
 none 	mmm 
 none 	i mean  the   the way we   we do it now is that we have a neural network and basically the net  network is trained almost to give binary decisions 
 none 	right 
 none 	and uh   binary decisions about phonemes  nnn  
 none 	uh
 none 	almost 
 none 	but i mean it   it   it does give a distribution 
 none 	it s  
 none 	yeah 
 none 	it s   and   and it is true that if there s two phones that are very similar  that uh the   i  it may prefer one but it will give a reasonably high value to the other  too 
 none 	yeah 
 none 	yeah  sure but uh
 none 	so basically it s almost binary decisions and um the idea of using more classes is to get something that s less binary decisions 
 none 	oh no  but it would still be even more of a binary decision 
 none 	it   it d be even more of one 
 none 	because then you would say that in   that this phone in this context is a one  but the same phone in a slightly different context is a zero 
 none 	but   yeah  but  
 none 	that would be even   even more distinct of a binary decision 
 create_single_reminder 	i actually would have thought you d wanna  go the other way and have fewer classes   
 none 	yeah  but if  
 create_single_reminder 	uh  i mean for instance  the   the thing i was arguing for before  but again which i don t think we have time to try  is something in which  you would modify the code so you could train to have several outputs on and use articulatory features cuz then that would   that would go   that would be much broader and cover many different situations   
 none 	mmm 
 none 	mm hmm 
 none 	but if you go to very very fine categories  it s very binary 
 none 	mmm  yeah  but i think  
 none 	yeah  perhaps you re right  but you have more classes so you   you have more information in your features  so 
 none 	mm hmm 
 none 	um you have more information in the uh posteriors vector um which means that  
 none 	true 
 none 	but still the information is relevant because it s   it s information that helps to discriminate  if it s possible to be able to discriminate among the phonemes in context 
 none 	mm hmm 
 none 	mm hmm 
 none 	well it s   it s   it s an interesting thought  i mean we   we could disagree about it at length but the   the real thing is if you re interested in it you ll probably try it and   and we ll see 
 none 	but the  
 none 	mmm 
 none 	mmm 
 none 	but   but what i m more concerned with now  as an operational level  is uh  you know  what do we do in four or five days 
 none 	mmm 
 none 	uh  and   so we have to be concerned with
 none 	are we gonna look at any combinations of things  you know once the nets get retrained so you have this problem out of it 
 none 	mmm 
 none 	um  are we going to look at multi band  are we gonna look at combinations of things 
 none 	uh  what questions are we gonna ask  uh now that  i mean  we should probably turn shortly to this o_g_ i note 
 none 	um  how are we going to combine with what they ve been focusing on 
 none 	uh 
 none 	uh we haven t been doing any of the l_d_ a rasta sort of thing 
 none 	mm hmm 
 none 	and they  although they don t talk about it in this note  um  there s um  the issue of the um mu law business uh versus the logarithm  um  so 
 none 	mm hmm 
 none 	so what i  what is going on right now  what s right   you ve got nets retraining 
 none 	are there   is there   are there any h_t_ k trainings   testings going on 
 none 	n 
 none 	i   i   i m trying the h_t_k with eh 
 none 	p_l_p twelve on line delta delta and m_s_g filter together 
 none 	the combination  i see 
 none 	the combination  yeah  but i haven t result at this moment 
 none 	m_s_g and   and p_l_p 
 none 	yeah 
 none 	and is this with the revised on line normalization 
 none 	ye  uh  with the old older   yeah 
 none 	yeah 
 none 	old one 
 none 	so it s using all the nets for that but again we have the hope that it  
 none 	yeah  but we can know soon 
 none 	we have the hope that it   maybe it s not making too much difference  but   but yeah 
 none 	maybe 
 none 	i don t know 
 none 	yeah 
 none 	uh  o_k 
 none 	uh so there is this combination  yeah  working on combination obviously 
 create_single_reminder 	um  i will  start work on multi band   
 none 	mm hmm 
 create_single_reminder 	and we plan to  work also on the idea of using both features and net outputs   
 none 	yep 
 none 	um 
 none 	and we think that with this approach perhaps we could reduce the number of outputs of the neural network 
 none 	um 
 none 	so  get simpler networks  because we still have the features 
 none 	so we have um come up with um different kind of broad phonetic categories 
 none 	and we have  
 none 	basically we have three types of broad phonetic classes 
 none 	well  something using place of articulation which   which leads to nine  i think  broad classes 
 none 	uh  another which is based on manner  which is   is also something like nine classes 
 none 	and then  something that combine both  and we have twenty f  twenty five 
 none 	twenty seven 
 none 	twenty seven broad classes 
 none 	so like  uh  oh  i don t know  like back vowels  front vowels 
 none 	so what you do   um i just wanna understand so
 none 	um
 none 	you have two net or three nets  was this 
 none 	how many   how many nets do you have 
 none 	for the moments we do not   don t have nets  i mean 
 none 	no nets 
 none 	it s just  
 none 	begin to work in this 
 none 	were we just changing the labels to retrain nets with fewer out  outputs 
 none 	we are   
 none 	right 
 none 	and then  
 none 	but   but i didn t understand  
 none 	mm hmm 
 none 	uh  the software currently just has   uh a   allows for i think  the one   one hot output  so you re having multiple nets and combining them  or    
 none 	uh  how are you   how are you coming up with  
 none 	if you say uh if you have a place characteristic and a manner characteristic  how do you  
 none 	it 
 none 	it s the single net  yeah 
 none 	i think they have one output 
 none 	oh  it s just one net 
 none 	mm hmm
 none 	yeah 
 none 	it s one net with um twenty seven outputs if we have twenty seven classes  yeah 
 none 	i see 
 none 	i see  o_k 
 none 	so it s   well  it s basically a standard net with fewer classes 
 none 	so you re sort of going the other way of what you were saying a bit ago instead of   yeah 
 none 	yeah  but i think   yeah 
 none 	but including the features 
 none 	b  b  including the features  yeah 
 none 	yeah 
 none 	i don t think this will work alone 
 none 	i think it will get worse because
 none 	uh huh 
 none 	well  i believe the effect that   of   of too reducing too much the information is basically   basically what happens and   but  
 none 	but you think if you include that plus the other features 
 none 	yeah  because there is perhaps one important thing that the net brings  and o_g_i show  showed that  is the distinction between sp  speech and silence
 none 	because these nets are trained on well controlled condition  i mean the labels are obtained on clean speech  and we add noise after 
 none 	so this is one thing
 none 	and
 none 	but perhaps  something intermediary using also some broad classes could   could bring so much more information 
 none 	uh 
 none 	so   so again then we have these broad classes and   well  somewhat broad  i mean  it s twenty seven instead of sixty four  basically 
 none 	yeah 
 none 	and you have the original features 
 none 	yeah 
 none 	which are p_l_p  or something 
 none 	mm hmm 
 none 	and then uh  just to remind me  all of that goes into   uh  that all of that is transformed by uh  uh  k_  k_l or something  or    
 none 	there will probably be  yeah  one single k_l to transform everything or uh  per 
 none 	mu 
 none 	right 
 none 	no transform the p_l_p and only transform the other
 none 	i m not sure 
 none 	this is still something that yeah  we don t know  
 none 	well no  i think  
 none 	i see 
 none 	two e 
 none 	so there s a question of whether you would  
 none 	yeah 
 none 	right 
 none 	whether you would transform together or just one 
 none 	it s one 
 none 	yeah 
 create_single_reminder 	might wanna  try it both ways   
 none 	but that s interesting 
 none 	so that s something that you re   you haven t trained yet but are preparing to train  and  
 none 	yeah 
 none 	yeah 
 none 	um
 none 	mmm 
 find_calendar_entry 	yeah  so i think  hynek  will be here  monday   
 none 	monday or tuesday   so
 none 	uh  yeah 
 none 	so i think  you know  we need to choose the   choose the experiments carefully  so we can get uh key   key questions answered uh before then and leave other ones aside even if it leaves incomplete tables someplace  uh uh  it s   it s really time to   time to choose 
 none 	mm hmm 
 none 	mm hmm 
 none 	um  let me pass this out  by the way 
 none 	um
 none 	these are  
 none 	did   did   did i interrupt you  were there other things that you wanted to  
 none 	yeah  i have one 
 none 	uh  no  i don t think so 
 none 	yeah  i have one 
 none 	oh  thanks 
 none 	ah  o_k 
 none 	we have one 
 none 	o_k  we have lots of them 
 none 	o_k  so um 
 none 	something i asked  
 none 	so they re   they re doing the   the v_a_d i guess they mean voice activity detection
 none 	so again  it s the silence  
 none 	so they ve just trained up a net which has two outputs  i believe 
 none 	um
 none 	i asked uh hynek whether  
 none 	i haven t talked to sunil   i asked hynek whether they compared that to just taking the nets we already had and summing up the probabilities 
 none 	mm hmm 
 none 	uh 
 none 	to get the speech   voice activity detection  or else just using the silence  if there s only one silence output 
 none 	um and  he didn t think they had  um 
 none 	but on the other hand  maybe they can get by with a smaller net and maybe sometimes you don t run the other  maybe there s a computational advantage to having a separate net  anyway 
 none 	mm hmm 
 none 	so um
 none 	their uh   the results look pretty good 
 none 	yeah 
 none 	um  i mean  not uniformly 
 none 	i mean  there s a   an example or two that you can find  where it made it slightly worse  but uh in   in all but a couple examples 
 none 	mmm 
 none 	uh 
 none 	but they have a question of the result  um how are trained the   the l_d_a filter 
 none 	how obtained the l_d_a filter 
 none 	mmm 
 none 	i  i m sorry  i don t understand your question 
 none 	yes  um the l_d_a filter needs some training set to obtain the filter 
 none 	maybe
 none 	i don t know exactly how they are obtained 
 none 	it s on training 
 none 	training  with the training test of each  
 none 	you understand me 
 none 	no 
 none 	yeah  uh for example 
 none 	l_d_a filter need a set of   a set of training to obtain the filter 
 none 	and maybe for the italian  for the t_d t_e on for finnish  these filter are   are obtained with their own training set 
 none 	yes 
 none 	yes  i don t know 
 none 	that s   that s   so that s a   that s a very good question  then   now that it  
 none 	i understand it  it s
 none 	 yeah  where does the l_d_a come from   in the  
 none 	in earlier experiments  they had taken l_d_a from a completely different database  right 
 none 	yeah 
 none 	yeah  because maybe it the same situation that the neural network training with their own set 
 none 	mmm 
 none 	so that s a good question  where does it come from 
 none 	yeah  i don t know 
 none 	um  but uh to tell you the truth  i wasn t actually looking at the l_d_a so much when i   i was looking at it i was mostly thinking about the   the v_a_d 
 none 	and um  it ap  it ap 
 none 	oh what does   what does a_s_p 
 none 	oh that s  
 none 	the features  yeah 
 none 	yeah 
 none 	i don t understand also what is   what is the difference between a_s_p and uh baseline over  
 none 	it says  baseline a_s_p  
 none 	yeah  i don t know 
 none 	a_s_p 
 none 	this is  
 none 	oh 
 none 	anybody know any  
 none 	there it is 
 none 	um
 none 	cuz there s  baseline aurora   above it 
 none 	mm hmm 
 none 	and it s  
 none 	this is mostly better than baseline  although in some cases it s a little worse  in a couple cases 
 none 	well  it says baseline a_s_p is twenty three mill minus thirteen 
 none 	yeah 
 none 	yeah  it says what it is  but i don t how that s different from  
 none 	from the baseline  o_k 
 none 	i think this was  
 none 	yeah 
 none 	i think this is the same point we were at when   when we were up in oregon 
 none 	i think  
 none 	i think it s the c_zero   using c_zero instead of log energy  yeah  it s this 
 none 	ah  o_k  mm hmm  yeah 
 none 	oh 
 none 	o_k 
 none 	it should be that  yeah 
 none 	because  
 none 	shouldn t it be  
 none 	they s  they say in here that the v_a_d is not used as an additional feature  does   does anybody know how they re using it 
 none 	yeah  so   so what they re doing here is  i  if you look down at the block diagram  um  they estimate   they get a   they get an estimate of whether it s speech or silence  and then they have a median filter of it 
 none 	yeah 
 none 	but that  
 none 	mm hmm 
 none 	and so um  basically they re trying to find stretches 
 none 	the median filter is enforcing a   i  it having some continuity 
 none 	mm hmm 
 none 	you find stretches where the combination of the frame wise v_a_d and the   the median filter say that there s a stretch of silence 
 none 	and then it s going through and just throwing the data away 
 none 	hmm 
 none 	right 
 none 	so um  
 none 	so it s   it s  
 none 	i don t understand  you mean it s throwing out frames 
 none 	before  
 none 	it s throwing out chunks of frames  yeah 
 none 	there s   the   the median filter is enforcing that it s not gonna be single cases of frames  or isolated frames 
 none 	yeah 
 none 	so it s throwing out frames and the thing is um  what i don t understand is how they re doing this with h_t_ k 
 none 	this is  
 none 	yeah  that s what i was just gonna ask  how can you just throw out frames 
 none 	yeah 
 none 	well  you   you can  right  i mean y  you   you   it stretches again  for single frames i think it would be pretty hard  but if you say speech starts here  speech ends there  right 
 none 	i 
 none 	yeah 
 none 	yeah 
 none 	mm hmm 
 none 	huh 
 none 	yeah 
 none 	yeah  you can basically remove the   the frames from the feature   feature files  and 
 none 	yeah 
 none 	yeah  so i mean in the   i  i  in the   in the decoding  you re saying that we re gonna decode from here to here 
 none 	i t 
 none 	mm hmm 
 none 	i think they re   they re   they re treating it  you know  like uh   well  it s not isolated word  but   but connected  you know  the   the  
 none 	in the text they say that this   this is a tentative block diagram of a possible configuration we could think of 
 none 	so that sort of sounds like they re not doing that yet 
 none 	well  no they   they have numbers though  right  so i think they re   they re doing something like that  i think that they re   they re  
 none 	i think what i mean by tha  that is they re trying to come up with a block diagram that s plausible for the standard 
 none 	in other words  it s   uh  
 none 	i mean from the point of view of   of uh reducing the number of bits you have to transmit it s not a bad idea to detect silence anyway 
 none 	yeah 
 none 	yeah 
 none 	um 
 none 	i m just wondering what exactly did they do up in this table if it wasn t this 
 none 	but it s   the thing is it s that   that   that s   that s i   i  
 none 	certainly it would be tricky about it intrans  in transmitting voice  uh uh for listening to  is that these kinds of things uh cut speech off a lot  right 
 none 	mm hmm 
 none 	and so um
 none 	plus it s gonna introduce delays 
 none 	it does introduce delays but they re claiming that it s   it s within the   the boundaries of it 
 none 	mmm 
 none 	and the l_d_a introduces delays  and b  what he s suggesting this here is a parallel path so that it doesn t introduce uh  any more delay 
 none 	i  it introduces two hundred milliseconds of delay but at the same time the l_d_a down here  
 none 	i don t know   wh  what s the difference between t_l_d_a and s_l_d_a  
 none 	temporal and spectral 
 none 	ah  thank you 
 none 	temporal l_d_a 
 none 	yeah  you would know that 
 none 	yeah
 none 	so um 
 none 	the temporal l_d_a does in fact include the same   so that   i think he   well  by   by saying this is a b  a tentative block di  diagram i think means if you construct it this way  this   this delay would work in that way and then it d be o_k 
 none 	ah 
 none 	they   they clearly did actually remove silent sections in order   because they got these word error rate results 
 none 	so um
 none 	i think that it s   it s nice to do that in this because in fact  it s gonna give a better word error result and therefore will help within an evaluation 
 none 	whereas to whether this would actually be in a final standard  i don t know 
 none 	um 
 none 	uh  as you know  part of the problem with evaluation right now is that the word models are pretty bad and nobody wants   has   has approached improving them 
 none 	so it s possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with 
 none 	so this might just be a temporary thing  but  
 none 	but  on the other hand  and maybe   maybe it s a decent idea 
 none 	so um
 create_single_reminder 	the question we re gonna wanna go through next week when hynek shows up i guess is  given that we ve been   if you look at what we ve been trying  we re uh looking at uh  by then i guess  combinations of features and multi band
 none 	uh  and we ve been looking at cross language  cross task issues 
 none 	and they ve been not so much looking at the cross task uh multiple language issues 
 none 	but they ve been looking at uh   at these issues  at the on line normalization and the uh voice activity detection 
 create_single_reminder 	and i guess when he comes here we re gonna have to  start deciding about um what do we choose from what we ve looked at to um blend with some group of things in what they ve looked at
 none 	and once we choose that  how do we split up the effort 
 none 	uh  because we still have   even once we choose  we ve still got uh another month or so  i mean there s holidays in the way  but   but uh
 find_calendar_entry 	i think  the evaluation data comes   january thirty  first  so there s still a fair amount of time to do things together it s just that they probably should be somewhat more coherent between the two sites in that   that amount of time  
 none 	when they removed the silence frames  did they insert some kind of a marker so that the recognizer knows it s   knows when it s time to back trace or something 
 none 	well  see they  i   i think they re
 none 	um 
 none 	i don t know the   the specifics of how they re doing it  they re   they re getting around the way the recognizer works because they re not allowed to um  change the scripts for the recognizer 
 none 	oh  right 
 none 	i believe  so  uh 
 none 	maybe they re just inserting some nummy frames or something 
 none 	uh  you know that s what i had thought 
 none 	but i don t   i don t think they are 
 none 	i mean that s   sort of what   the way i had imagined would happen is that on the other side  yeah you p  put some low level noise or something 
 none 	hmm 
 none 	probably don t want all zeros  most recognizers don t like zeros but but you know  put some epsilon in or some rand  sorry epsilon random variable in or something 
 none 	hmm 
 none 	yeah 
 none 	some constant vector 
 none 	maybe not a constant but it doesn t  uh   don t like to divide by the variance of that  but i mean it s
 none 	i mean i  w 
 none 	or something  
 none 	that s right  but something that   what i mean is something that is very distinguishable from speech 
 none 	mm hmm 
 none 	so that the   the silence model in h_t_k will always pick it up 
 none 	yeah  so i   i   that s what i thought they would do  or else  uh uh maybe there is some indicator to tell it to start and stop  i don t know 
 none 	hmm 
 none 	but whatever they did  i mean they have to play within the rules of this specific evaluation 
 none 	yeah 
 none 	we c  we can find out 
 none 	cuz you gotta do something  otherwise  if it s just a bunch of speech  stuck together  
 none 	no they re  
 none 	yeah 
 none 	it would do badly and it didn t so badly  right  so they did something 
 none 	yeah  right 
 none 	yeah  yeah 
 none 	yeah 
 none 	uh 
 none 	so  o_k  so i think this brings me up to date a bit 
 none 	it hopefully brings other people up to date a bit 
 none 	and um
 none 	um i think  
 create_single_reminder 	uh  i wanna  look at these numbers off line a little bit and think about it and   and talk with everybody uh  outside of this meeting   
 none 	um  but uh
 none 	no i mean it sounds like   i mean there   there   there are the usual number of   of little   little problems and bugs and so forth but it sounds like they re getting ironed out 
 none 	and now we re seem to be kind of in a position to actually uh  look at stuff and   and   and compare things 
 none 	so i think that s   that s pretty good 
 none 	um
 none 	i don t know what the  
 none 	one of the things i wonder about  coming back to the first results you talked about  is   is how much  uh things could be helped by more parameters 
 none 	and uh  
 none 	and uh how many more parameters we can afford to have  in terms of the uh computational limits 
 create_single_reminder 	because anyway when we go to twice as much data and have the same number of parameters  particularly when it s twice as much data and it s quite diverse  um  i wonder  if having twice as many parameters would help   
 none 	uh  just have a bigger hidden layer 
 none 	mm hmm 
 none 	uh
 none 	but  
 none 	i doubt it would help by forty per cent 
 none 	but but uh
 none 	yeah 
 none 	just curious 
 none 	how are we doing on the resources  disk  and  
 none 	i think we re alright  um  not much problems with that 
 none 	o_k 
 none 	computation 
 none 	it s o_k 
 none 	well this table took uh more than five days to get back  
 none 	we  
 none 	yeah  yeah  well 
 none 	but   yeah 
 none 	are   were you folks using gin  that s a   that just died  you know 
 none 	mmm  no  you were using gin perhaps  yeah  no 
 none 	no 
 none 	it just died 
 none 	no  oh  that s good  o_k 
 none 	yeah  we re gonna get a replacement server that ll be a faster server  actually  that ll be   it s a seven hundred fifty megahertz uh sun uh
 none 	yes 
 none 	hmm 
 none 	tonic 
 none 	but it won t be installed for a little while 
 none 	mm hmm 
 none 	u 
 none 	do we  
 none 	go ahead 
 none 	do we have that big new i_b_m machine the  i think in th 
 none 	we have the little tiny i_b_m machine that might someday grow up to be a big i_b_m machine 
 none 	it s got s  slots for eight  uh i_b_m was donating five  i think we only got two so far  processors 
 none 	we had originally hoped we were getting eight hundred megahertz processors  they ended up being five fifty 
 none 	so instead of having eight processors that were eight hundred megahertz  we ended up with two that are five hundred and fifty megahertz 
 none 	and more are supposed to come soon and there s only a moderate amount of dat  of memory  so i don t think anybody has been sufficiently excited by it to spend much time uh with it  but uh
 none 	hopefully  they ll get us some more parts  soon and  
 none 	uh  yeah  i think that ll be   once we get it populated  that ll be a nice machine  i mean we will ultimately get eight processors in there 
 none 	and uh   and uh a nice amount of memory  uh so it ll be a pr  pretty fast linux machine 
 none 	and if we can do things on linux  some of the machines we have going already  like swede 
 none 	mm hmm 
 none 	um
 none 	it seems pretty fast 
 none 	mm hmm 
 none 	but  
 none 	i think fudge is pretty fast too 
 create_single_reminder 	yeah  i mean you can  check with uh dave johnson    i mean  it   it s  
 none 	i think the machine is just sitting there 
 none 	and it does have two processors  you know and  
 none 	somebody could do   you know  uh  check out uh the multi threading libraries  and
 none 	i mean i  it s possible that the  
 none 	i mean  i guess the prudent thing to do would be for somebody to do the work on   on getting our code running on that machine with two processors even though there aren t five or eight 
 none 	there s   there s   there s gonna be debugging hassles and then we d be set for when we did have five or eight  to have it really be useful 
 none 	but 
 none 	notice how i said somebody and turned my head your direction  that s one thing you don t get in these recordings  you don t get the   don t get the visuals but  
 none 	i  is it um mostly um the neural network trainings that are um slowing us down or the h_t_k runs that are slowing us down 
 none 	uh  i think yes 
 none 	uh 
 none 	isn t that right  i mean i think you re   you re sort of held up by both  right 
 none 	if the   if the neural net trainings were a hundred times faster you still wouldn t be anything   running through these a hundred times faster because you d be stuck by the h_t_k trainings  right 
 none 	mmm 
 none 	yeah 
 none 	but if the h_t_k   i mean i think they re both  
 none 	it sounded like they were roughly equal 
 none 	is that about right 
 none 	yeah 
 none 	yeah 
 none 	because  um i think that ll be running linux  and sw  swede and fudge are already running linux so  um i could try to get um the train  the neural network trainings or the h_t_k stuff running under linux  and to start with i m wondering which one i should pick first 
 none 	uh  probably the neural net cuz it s probably   it   it s   it s um  
 none 	well  i   i don t know 
 none 	they both  
 none 	h_t_k we use for um this aurora stuff
 none 	um
 none 	um  i think
 none 	it s not clear yet what we re gonna use for trainings uh  
 none 	well  there s the trainings uh   is it the training that takes the time  or the decoding 
 none 	uh  is it about equal between the two 
 none 	for   for aurora 
 none 	for h_t_k 
 none 	for   yeah  for the aurora 
 none 	uh
 none 	training is longer 
 none 	o_k 
 none 	yeah 
 none 	o_k 
 none 	well  i don t know how we can  
 none 	i don t know how to  
 none 	do we have h_t_k source  is that  
 none 	mmm 
 none 	yeah 
 none 	you would think that would fairly trivially   the training would  anyway  th  the testing uh i don t   i don t think would parallelize all that well 
 none 	but i think that you could certainly do d  um  distributed  sort of   ah  no  it s the   each individual sentence is pretty tricky to parallelize 
 none 	but you could split up the sentences in a test set 
 none 	they have a   they have a thing for doing that and th  they have for awhile  in h_t_ k 
 none 	yeah 
 none 	and you can parallelize the training 
 none 	and run it on several machines and it just basically keeps counts 
 none 	aha 
 none 	and there s something   a final thing that you run and it accumulates all the counts together 
 none 	i see 
 none 	mmm 
 none 	i don t what their scripts are set up to do for the aurora stuff  but  
 none 	yeah 
 none 	something that we haven t really settled on yet is other than this aurora stuff  uh what do we do  large vocabulary training slash testing for uh tandem systems 
 none 	cuz we hadn t really done much with tandem systems for larger stuff 
 none 	cuz we had this one collaboration with c_m_u and we used sphinx 
 none 	uh  we re also gonna be collaborating with s_r_i and we have their   have theirs 
 none 	um so
 none 	i don t know
 none 	um 
 none 	so i   i think the   the advantage of going with the neural net thing is that we re gonna use the neural net trainings  no matter what  for a lot of the things we re doing  whereas  w  exactly which
 none 	o_k 
 none 	h_m_m   gaussian mixture based h_m_m thing we use is gonna depend uh
 none 	so with that  maybe we should uh go to our
 none 	digit recitation task 
 none 	and  it s about eleven fifty 
 none 	canned 
 none 	uh  i can   i can start over here 
 none 	two zero one one dash two zero three zero
 none 	o_ six nine zero six zero one four two three zero five one zero eight one four zero zero four seven two two six one seven four two eight seven eight nine nine seven five nine 
 none 	o_  zero  one zero three two two four three zero zero one five five six nine two four zero six three seven eight nine zero three
 none 	uh  transcript number one nine nine one two o_ one zero 
 none 	o_ nine zero eight two seven six one nine three three four two o_ five five  three zero five one six three two seven four eight nine one o_ nine
 none 	o_ zero zero zero seven three one two three seven seven four three two five three six one five four eight zero six six zero zero five six seven nine one nine six nine five one
 none 	transcript two o_ seven one dash two o_ nine o_ one two zero eight four six four one  five three six six zero three seven eight nine two nine
 none 	o_ o_ five eight one one one five three five six four two seven five six o_ three six five four zero four five five six seven nine one nine four
 none 	o_ eight six zero three one zero nine one two one eight one zero zero
 none 	transcript two zero five one dash two zero seven zero zero zero two two zero four three two two one three four six nine five six seven eight o_ eight eight three seven seven
 none 	o_ two eight six one o_ five zero two one nine two seven five o_ two two six three nine nine eight three four o_ five seven two five six one o_ eight eight two eight four nine six four seven four
 none 	o_ zero
 none 	transcript one nine seven one dash one nine nine zero nine
 none 	o_ eight zero one o_ three one one three zero six four four three five seven two six seven one three eight seven eight nine zero one one two four two two three five zero seven four five six zero three three eight one six zero three two five mine one eight seven
 none 	transcript two zero three one dash two zero five zero zero two one two o_ two six six three two seven three four nine seven nine o_ five six o_ o_ two eight one two nine four seven nine one six five
 none 	o_ eight three four zero five three one two o_ six o_ seven three zero five two six four eight eight one seven eight six seven four eight six one nine four nine
 none 	o_
 none 	transcript one nine three one dash one nine five zero seven eight
 none 	o_ one zero two six three five three one one four five seven two seven zero one three four five seven one nine o_ o_ eight one o_ nine eight zero seven six zero eight
 none 	o_ five one zero one two four one five two nine zero four six seven eight three six
 make_call 	great  uh  could you give  adam  a call   tell him to
 none 	oh 
 none 	he s at two nine seven seven 
 none 	o_k  i think we can
 find_calendar_entry 	you know  herve s  coming  tomorrow   right  
 none 	herve will be giving a talk  yeah  talk at eleven 
 none 	hello  is adam there 
 none 	hey adam  this is barry 
 none 	yeah we re all done 
 none 	o_k  thanks  bye bye 
 none 	did uh  did everybody sign these consent
 none 	er everybody
 none 	has everyone signed a consent form before  on previous meetings  you don t have to do it again each time
 none 	yes  microphones off
 none 	o_k 
 none 	so  uh
 none 	you can fill those out  uh after  actually  so
 find_email 	so   i  got  uh  these results  from  uh   stephane   
 none 	also  um  i think that  uh um we might hear later today  about other results 
 none 	i think s  that  uh  there were some other very good results that we re gonna wanna compare to 
 none 	but  r  our results from other   other places  yeah 
 none 	i  i m sorry  i didn t 
 none 	um  i got this from you and then i sent a note to sunil about the   cuz he has been running some other systems other than the   the icsi o_g_i one 
 none 	yeah 
 none 	mm hmm 
 none 	oh yeah 
 none 	so um  i wan  wanna   wanna see what that is 
 none 	but  uh  you know  so we ll see what it is comparatively later 
 none 	but it looks like  um
 none 	m  yeah 
 none 	you know most of the time  even   i mean even though it s true that the overall number for danish   we didn t improve it
 none 	if you look at it individually  what it really says is that there s  um  uh
 none 	looks like out of the six cases  between the different kinds of  uh  matching conditions out of the six cases  there s basically  um  a couple where it stays about the same  uh  three where it gets better  and one where it gets worse 
 none 	yeah 
 none 	uh  go ahead 
 none 	y  actually  uh  um  for the danish  there s still some kind of mystery because  um  um  when we use the straight features  we are not able to get these nice number with the icsi o_g_i one  i mean 
 none 	we don t have this ninety three seventy eight  we have eight  yeah 
 none 	eighty nine forty four 
 none 	uh  so  uh  that s probably something wrong with the features that we get from o_g_i 
 none 	uh  and sunil is working on   on trying to   to check everything 
 none 	oh  and   and we have a little time on that   and   actually so
 none 	hmm 
 none 	we have a little bit of time on that  actually 
 none 	yeah 
 none 	we have a day or so  so
 find_calendar_entry 	when   when   when do  you folks   leave   
 none 	uh   sunday  
 none 	sunday 
 none 	so
 none 	so  uh
 none 	yeah  until saturday midnight  or something  we have
 none 	w  we   we have time  yeah 
 none 	well  that would be good 
 none 	that d be good 
 none 	yeah 
 none 	yeah 
 create_single_reminder 	uh  and  you know  i  u   when  whenever anybody figures it out   they  should also  for sure   email hynek because hynek will be over there telling people what we did  so he should know   
 none 	mmm 
 none 	good  o_k 
 none 	yeah 
 none 	so  um
 none 	so  we ll   we ll hold off on that a little bit 
 none 	i mean  even with these results as they are  it s   it s   it s really not that bad 
 none 	but   but  uh  um
 none 	and it looks like the overall result as they are now  even without  you know  any   any bugs being fixed is that  uh  on the   the other tasks  we had this average of  uh  forty  uh   nine percent  or so  improvement 
 none 	and here we have somewhat better than that than the danish  and somewhat worse than that on the german  but i mean  it sounds like  uh  one way or another  the methods that we re doing can reduce the error rate from   from mel cepstrum down by  you know a fourth of them to  uh  a half of them 
 none 	somewhere in there  depending on the exact case 
 none 	so
 none 	so that s good 
 none 	i mean  i think that  uh  one of the things that hynek was talking about was understanding what was in the other really good proposals and   and trying to see if what should ultimately be proposed is some  uh  combination of things 
 none 	um  if  uh  
 none 	cuz there s things that they are doing there that we certainly are not doing 
 none 	and there s things that we re doing that they re not doing 
 none 	and   and they all seem like good things 
 none 	yeah 
 none 	mmm  yeah 
 none 	so
 none 	so
 none 	how much   how much better was the best system than ours 
 none 	well  we don t know yet 
 none 	mmm 
 none 	uh  i mean  first place  there s still this thing to   to work out  and second place   second thing is that the only results that we have so far from before were really development set results 
 none 	oh  o_k 
 none 	so  i think in this community that s of interest 
 none 	it s not like everything is being pinned on the evaluation set 
 none 	but  um  for the development set  our best result was a little bit short of fifty percent 
 none 	and the best result of any system was about fifty four  where these numbers are the  uh  relative  uh  reduction in  uh  word error rate 
 none 	oh  o_k 
 none 	and  um  the other systems were  uh  somewhat lower than that 
 none 	there was actually   there was much less of a huge range than there was in aurora one 
 none 	in aurora one there were   there were systems that ba  basically didn t improve things 
 none 	hmm 
 none 	and here the   the worst system still reduced the error rate by thirty three percent  or something  in development set 
 none 	oh  wow 
 none 	so   so  you know  sort of everybody is doing things between  well  roughly a third of the errors  and half the errors being eliminated  uh  and varying on different test sets and so forth 
 none 	mm hmm 
 none 	so i think
 none 	um
 none 	it s probably a good time to look at what s really going on and seeing if there s a   there s a way to combine the best ideas while at the same time not blowing up the amount of  uh  resources used  cuz that s   that s critical for this   this test 
 none 	do we know anything about   who   who s was it that had the lowest on the dev set 
 none 	um  uh  the  uh  the  there were two systems that were put forth by a combination of   of  uh  french telecom and alcatel 
 none 	and  um they   they differed in some respects  but they e  em  one was called the french telecom alcatel system the other was called the alcatel french telecom system  uh  which is the biggest difference  i think 
 none 	but   but there re   there re   there re some other differences  too 
 none 	uh  and   and  uh  they both did very well  you know 
 none 	uh huh 
 none 	so  um  my impression is they also did very well on   on the   the  uh  evaluation set  but  um  i   i  we haven t seen   you ve  you haven t seen any final results for that yeah 
 none 	and they used   the main thing that   that they used was spectral subtraction  or
 none 	there is a couple pieces to it 
 none 	there s a spectral subtraction style piece   it was basically  you know  wiener filtering 
 none 	and then   then there was some p  some modification of the cepstral parameters  where they  
 none 	yeah  actually  something that s close to cepstral mean subtraction 
 none 	but  uh  the way the mean is adapted   um  it s signal dependent 
 none 	i m   i m  uh
 none 	so  basically  the mean is adapted during speech and not during silence 
 none 	yeah 
 none 	but it s very close to   to cepstral mean subtraction 
 none 	but some people have done exactly that sort of thing  of   of   and the   i mean it s not  
 none 	to   to look in speech only  to try to m  to measure these things during speech  that s p  that s not that uncommon 
 none 	yeah  yeah 
 none 	but i  it  it   so it looks like they did some   some  uh  reasonable things  uh  and they re not things that we did  precisely 
 none 	we did unreasonable things  which   because we like to try strange things  and   and  uh  and our things worked too 
 none 	hmm 
 none 	and so  um  uh  it s possible that some combination of these different things that were done would be the best thing to do 
 none 	but the only caveat to that is that everybody s being real conscious of how much memory and how much c_p_u they re using because these  uh  standards are supposed to go on cell phones with m  moderate resources in both respects 
 none 	mm hmm 
 none 	did anybody  uh  do anything with the models as a   an experiment  or
 none 	uh  they didn t report it  if they did 
 none 	n  nobody reported it 
 none 	yeah 
 none 	i think everybody was focused elsewhere 
 none 	um  now  one of the things that s nice about what we did is  we do have a   a  uh   a filtering  which leads to a   a  uh   a reduction in the bandwidth in the modulation spectrum  which allows us to downsample 
 none 	so  uh  as a result of that we have a reduced  um  transmission rate for the bits 
 none 	mm hmm 
 none 	that was misreported the first time out 
 none 	it   it said the same amount because for convenience sake in the particular way that this is being tested  uh  they were repeating the packets 
 none 	so it was   they were s  they   they had twenty four hundred bits per second  but they were literally creating forty eight hundred bits per second  um  even though y  it was just repeated 
 none 	oh 
 none 	mm hmm 
 none 	right 
 none 	so  uh  in practice
 none 	so you could ve had a repeat count in there or something 
 none 	well  n  i mean  this was just a ph  phoney thing just to   to fit into the   the software that was testing the errors   channel errors and so on 
 none 	oh 
 none 	so   so in reality  if you put this   this system in  into  uh  the field  it would be twenty four hundred bits per second  not forty eight hundred 
 none 	oh 
 none 	so  um  so that s a nice feature of what   what we did 
 none 	um  but  um  well  we still have to see how it all comes out 
 none 	hmm 
 none 	um  and then there s the whole standards process  which is another thing altogether 
 find_calendar_entry 	when is  the development set   i mean  the  uh  uh  test set results due   
 none 	like the day before you leave or something 
 none 	uh  probably the day after they leave  but we ll have to   we ll have to stop it the day before we leave 
 none 	yeah  yeah 
 none 	so
 none 	huh 
 find_calendar_entry 	i think tha  i think the   the  meeting  is on  the thirteenth or something   
 none 	yeah   this tuesday   yeah 
 none 	and  uh  they  uh
 find_calendar_entry 	right   and  the   the  uh  results are due   like the day before the meeting or something   
 none 	so
 none 	yeah  probably  well
 none 	i th  i think   i  i think they are  yeah 
 none 	yeah  well
 none 	so um  since we have a bit farther to travel than some of the others  uh  we ll have to get done a little quicker 
 none 	but  um  i mean  it s just tracing down these bugs 
 none 	i mean  just exactly this sort of thing of  you know  why   why these features seem to be behaving differently  uh  in california than in oregon 
 none 	hmm 
 none 	might have something to do with electricity shortage 
 none 	uh  we didn t   we didn t have enough electrons here and
 none 	uh  but  um
 none 	uh  i think  you know  the main reason for having  
 none 	i mean  it only takes w  to run the   the two test sets in   just in computer time is just a day or so  right 
 none 	so yeah 
 none 	yeah  it s very short interval 
 none 	so  i think the who  the whole reason for having as long as we have  which was like a week and a half  is   is because of bugs like that 
 none 	hmm 
 none 	so
 none 	huh
 none 	so  we re gonna end up with these same kind of sheets that have the the percentages and so on just for the  
 none 	yeah  so there are two more columns in the sheets  two 
 none 	oh  i guess it s the same sheets  yeah  yeah   just with the missing columns filled in 
 none 	yeah  it s the same sheets  yeah 
 none 	yeah 
 none 	yeah 
 none 	well  that ll be good 
 none 	so  i ll dis  i ll disregard these numbers 
 none 	that s   that s   that s good 
 none 	so  hynek will try to push for trying to combine  uh  different things  or
 none 	uh  well that s um yeah
 none 	hmm 
 none 	i mean  i think the question is  is there   is there some advantage  
 none 	i mean  you could just take the best system and say that s the standard 
 none 	but the thing is that if different systems are getting at good things  um  a  again within the constraint of the resources  if there s something simple that you can do
 none 	now for instance  uh  it s  i think  very reasonable to have a standard for the terminal s side and then for the server s side say   here s a number of things that could be done  
 none 	so  um  everything that we did could probably just be added on to what alcatel did  and i  it d probably work pretty well with them  too 
 none 	so  um  uh  that s one   one aspect of it 
 none 	and then on the terminal s side  i don t know how much  um  memory and   and c_p_u it takes  but it seems like the filtering
 none 	uh  i mean  the v_a_d stuff they both had  right 
 none 	and  um  so   and they both had some kind of on line normalization  right 
 none 	uh  yeah 
 none 	of sorts  yeah 
 none 	so   so  it seems like the main different there is the   is the  uh  filtering 
 none 	and the filtering   i think if you can   shouldn t take a lot of memory to do that
 none 	uh  and i also wouldn t think the c_p_u  uh  would be much either for that part 
 none 	so  if you can   if you can add those in um then  uh  you can cut the data rate in half 
 none 	yeah 
 create_single_reminder 	so it seems like the right thing to do is  to   on the   on the terminal s side  take what they did  if it   if it does seem to generalize well to german and danish  uh  take what they did add in a filter  and add in some stuff on the server s side and   and   and that s probably a reasonable standard   
 none 	um
 none 	they are working on this already  because   yeah  su  sunil told me that he was trying already to put some kind of  uh  filtering in the france telecom 
 none 	uh
 none 	yeah  so that s   that s   that s what
 none 	that would be ideal   would be is that they could  you know  they could actually show that  in fact  a combination of some sort  uh  would work even better than what   what any of the systems had 
 none 	and  um  then it would   it would  uh be something to   to discuss in the meeting 
 none 	but  uh  not clear what will go on 
 none 	um  i mean  on the one hand  um  sometimes people are just anxious to get a standard out there 
 none 	i mean  you can always have another standard after that  but this process has gone on for a while on   already and   and people might just wanna pick something and say   o_k  this is it  
 none 	and then  that s a standard 
 none 	uh  standards are always optional 
 none 	it s just that  uh  if you disobey them  then you risk not being able to sell your product  or
 none 	uh um
 none 	and people often work on new standards while an old standard is in place and so on 
 none 	so it s not final even if they declared a standard 
 none 	the other hand  they might just say they just don t know enough yet to   to declare a standard 
 none 	so you   you   you will be   you will become experts on this and know more   far more than me about the tha  this particular standards process once you   you go to this meeting 
 none 	so  be interested in hearing 
 none 	so  uh  i d be  uh  interested in hearing  uh  your thoughts now
 none 	i mean you re almost done 
 none 	i mean  you re done in the sense that  um  you may be able to get some new features from sunil  and we ll re run it 
 none 	uh  but other than that  you re   you re basically done  right 
 none 	so  uh  i m interested in hearing   hearing your thoughts about where you think we should go from this 
 none 	yeah 
 none 	i mean  we tried a lot of things in a hurry  and  uh  if we can back off from this now and sort of take our time with something  and not have doing things quickly be quite so much the constraint  what   what you think would be the best thing to do 
 none 	uh  well
 none 	hmm
 none 	well  first  uh  to really have a look at   at the speech from these databases because  well  we tried several thing  but we did not really look at what  what s happening  and where is the noise  and
 none 	o_k 
 none 	eh
 none 	it s a novel idea 
 create_single_reminder 	look at the data   
 none 	o_k 
 none 	yeah 
 none 	or more generally  i guess  what   what is causing the degradation 
 none 	yeah  yeah 
 none 	actually  there is one thing that   well
 none 	um  generally we   we think that most of the errors are within phoneme classes  and so i think it could be interesting to   to see if it  
 none 	i don t think it s still true when we add noise  and so we have   i   i guess the confusion ma  the confusion matrices are very different when   when we have noise  and when it s clean speech 
 none 	and probably  there is much more between classes errors for noisy speech 
 none 	mm hmm 
 none 	and so  um
 none 	yeah  so perhaps we could have a   a large gain  eh  just by looking at improving the  uh  recognition  not of phonemes  but of phoneme classes  simply 
 none 	mm hmm 
 none 	and which is a s  a s  a simpler problem  perhaps  but   which is perhaps important for noisy speech 
 none 	the other thing that strikes me  just looking at these numbers is  just taking the best cases  i mean  some of these  of course  even with all of our   our wonderful processing  still are horrible kinds of numbers 
 create_single_reminder 	but just take the best case  the well matched uh  german case after   er well matched danish after we   the kind of numbers we re getting are about eight or nine uh p  percent error per digit   
 none 	mm hmm 
 none 	mm hmm 
 none 	yeah 
 none 	this is obviously not usable  right 
 none 	no 
 none 	i mean  if you have ten digits for a phone number i mean  every now and then you ll get it right 
 none 	sure 
 none 	i mean  it s   it s  uh  um
 none 	so  i mean  the other thing is that  uh  
 none 	and   and   a  and   and also  um part of what s nice about this is that this is  uh  um a realistic   almost realistic database 
 none 	i mean  it s still not people who are really trying to accomplish something  but   but  uh  within the artificial setup  it isn t noise artificially added  you know  simulated  uh  additive noise 
 none 	mm hmm 
 none 	it s real noise condition 
 none 	and  um  the   the training   the training  i guess  is always done on the close talking
 none 	no  actually   actually the well matched condition is still quite di  still quite difficult 
 none 	no 
 none 	i mean  it s   they have all these data from the close mike and from the distant mike  from different driving condition  open window  closed window  and they take all of this and they take seventy percent  i think  for training and thirty percent for testing 
 none 	yeah 
 none 	mm hmm 
 none 	so  training is done on different conditions and different microphones  and testing also is done on different microphone and conditions 
 none 	so  probably if we only take the close microphones  i guess the results should be much much better than this 
 none 	i see 
 none 	mmm 
 none 	oh  o_k  that explains it partially 
 none 	uh
 none 	wha  what about i  in   so the   the   go ahead 
 none 	yeah  so   there is this  the mismatched is  um the same kind of thing  but the driving conditions  i mean the speed and the kind of road  is different for training and testing  is that right 
 none 	yeah 
 none 	and the last condition is close microphone for training and distant for testing 
 none 	yeah 
 none 	uh  o_k  so
 none 	so   s  so  
 none 	i see 
 none 	so  yeah  so the high   so the   right   so the highly mismatched case is in some sense a good model for what we ve been  you know  typically talking about when we talk about additive noise in  
 none 	and so   and i  i  k  it does correspond to a realistic situation in the sense that  um  people might really be trying to  uh  call out telephone numbers or some  or something like that  in   in their cars and they re trying to connect to something 
 none 	yeah 
 none 	mmm 
 none 	um
 none 	actually  yeah  it s very close to clean speech training because  well  because the close microphone and noisy speech testing  yeah 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	mmm 
 none 	and the well matched condition is what you might imagine that you might be able to approach  if you know that this is the application 
 none 	you re gonna record a bunch on people in cars and so forth  and do these training 
 none 	and then  uh  when y  you sell it to somebody  they will be a different person with a different car  and so on 
 none 	so it s   this is a  an optim  somewhat optimistic view on it  uh  so  you know  the real thing is somewhere in between the two 
 none 	uh  uh  but
 none 	yeah 
 none 	but the   i mean  the th  th  it doesn t work 
 none 	even the optimistic one is
 none 	yeah  right 
 none 	it  
 none 	right  it doesn t work 
 none 	so  in a way  that s  you know  that s sort of the dominant thing is that even  say on the development set stuff that we saw  the  uh  the numbers that  uh  that alcatel was getting when choosing out the best single numbers  it was just   you know  it wasn t good enough for   for a   a   for a real system 
 none 	mmm 
 none 	mm hmm 
 none 	you   you   you  um
 none 	so  uh  we still have stuff to do 
 none 	yeah 
 none 	uh  and  uh i don t know
 none 	so  looking at the data  where  you know   what s the   what s   what s th  what s characteristic i  e  yeah  i think that s   that s a good thing 
 none 	does a  any  you have any thoughts about what else y  you re thinking that you didn t get to that you would like to do if you had more time 
 none 	uh
 none 	oh  f  a lot of thing 
 none 	because we trying a lot of s  thing  and we doesn t work  we remove these 
 none 	maybe we trying again with the articulatory feature 
 none 	i don t know exactly because we tried   we   some   one experiment that doesn t work 
 none 	um  forgot it  something
 none 	mm hmm 
 none 	i don t know exactly because  tsk maybe do better some step the general  eh  diagram 
 none 	mm hmm 
 none 	i don t know exactly s  to think what we can improve 
 none 	yeah  cuz a lot of time  it s true  there were a lot of times when we ve tried something and it didn t work right away  even though we had an intuition that there should be something there 
 none 	and so then we would just stop it 
 none 	um
 none 	and  uh  one of the things   i don t remember the details on  but i remember at some point  when you were working with a second stream  and you tried a low pass filtering to cepstrum  in some case you got  
 none 	m_s_g
 none 	well  but it was an m_s_g like thing  but it wasn t m_s_g  right 
 none 	yeah 
 none 	uh  you   y  i think in some case you got some little improvement  but it was  you know  sort of a small improvement  and it was a   a big added complication  so you dropped it 
 none 	but  um  that was just sort of one try  right 
 none 	you just took one filter  threw it there  right 
 none 	yeah  yeah 
 none 	and it seems to me that  um  if that is an important idea  which  you know  might be  that one could work at it for a while  as you re saying 
 none 	hmm 
 none 	and  uh
 none 	uh  and you had  you know  you had the multi band things also  and  you know  there was issue of that 
 none 	yeah  mmm 
 none 	mm hmm 
 none 	um  barry s going to be  uh  continuing working on multi band things as well 
 none 	we were just talking about  um  some  uh  some work that we re interested in 
 search 	kind of inspired by the stuff by  larry saul  with the  uh uh   learning articulatory feature in   i think  in the case of his paper   with sonorance based on  uh  multi band information where you have a   a combination of gradient learning an  and  uh  e_m   
 none 	mm hmm 
 none 	um  and
 none 	um  so  i think that  you know  this is a  uh   this is a neat data set 
 none 	um  and then  uh  as we mentioned before  we also have the   the new  uh  digit set coming up from recordings in this room 
 none 	so  there s a lot of things to work with 
 none 	um and  uh what i like about it  in a way  is that  uh  the results are still so terrible 
 none 	uh
 none 	uh
 none 	i mean  they re much better than they were  you know 
 none 	we re talking about thirty to sixty percent  uh  error rate reduction 
 none 	that s   that s really great stuff to   to do that in relatively short time 
 none 	but even after that it s still  you know  so poor that   that  uh  no one could really use it 
 none 	so  um
 none 	i think that s great that   because   and y  also because again  it s not something   sometimes we ve gotten terrible results by taking some data  and artificially  you know  convolving it with some room response  or something   we take a very  
 none 	uh  at one point  uh  brian and i went downstairs into the   the basement where it was   it was in a hallway where it was very reverberant and we   we made some recordings there  and then we   we  uh   uh  made a simulation of the   of the room acoustics there and   and applied it to other things  and uh
 none 	mm hmm 
 none 	but it was all pretty artificial  and   and  you know  how often would you really try to have your most crucial conversations in this very reverberant hallway 
 none 	um
 none 	so  uh
 none 	this is what s nice about the aurora data and the data here  is that   is that it s sort of a realistic room situation uh  acoustics   acoustic situation  both terms in noise and reflections  and so on and n  n 
 none 	and  uh  uh  with something that s still relatively realistic  it s still very very hard to do very well 
 none 	so
 none 	yeah 
 none 	yeah  so d  well
 none 	actually  this is   tha  that s why we   well  it s a different kind of data 
 none 	we re not   we re not used to work with this kind of data 
 none 	yeah 
 none 	that s why we should have a loo  more closer look at what s going on 
 none 	mm hmm 
 none 	um
 none 	yeah 
 none 	so this would be the first thing  and then  of course  try to   well  kind of debug what was wrong  eh  when we do aurora test on the m_s_g particularly  and on the multi band 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	uh
 none 	yeah 
 none 	yeah  no  i   i think there s lots of   lots of good things to do with this 
 none 	so
 none 	um
 none 	so let s   i guess
 none 	you were gonna say something else 
 none 	oh  o_k 
 none 	what do you think 
 none 	about
 none 	anything
 none 	about other experiments 
 none 	uh  now  i m interested in  um  uh looking at the experiments where you use  um uh  data from multiple languages to train the neural net 
 none 	and i don t know how far  or if you guys even had a chance to try that  but that would be some  it d be interesting to me 
 none 	yeah  but
 none 	s  b 
 none 	again  it s the kind of   of thing that  uh  we were thin  thinking   thinking that it would work  but it didn t work 
 none 	and  eh  so there is kind of   of not a bug  but something wrong in what we are doing  perhaps 
 none 	yeah 
 none 	right 
 none 	right 
 none 	right 
 none 	uh  something wrong  perhaps in the   just in the   the fact that the labels are   well
 none 	mm hmm 
 none 	what worked best is the hand labeled data 
 none 	mm hmm 
 none 	um
 none 	uh  so  yeah 
 none 	i don t know if we can get some hand labeled data from other languages 
 none 	yeah 
 none 	it s not so easy to find 
 none 	right 
 none 	but that would be something interesting t  to   to see 
 none 	yeah  yeah 
 none 	yeah 
 none 	also  uh  i mean  there was just the whole notion of having multiple nets that were trained on different data 
 none 	so one form of different data was   is from different languages  but the other
 none 	well  i  in fact  uh  m  in those experiments it wasn t so much combining multiple nets  it was a single net that had different
 none 	yeah 
 none 	so  first thing is would it be better if they were multiple nets  for some reason 
 none 	second thing is  never mind the different languages  just having acoustic conditions rather than training them all up in one  would it be helpful to have different ones 
 none 	so  um
 search 	that was a question that was kind of raised by  mike shire s thesis   and on   in that case in terms of  reverberation   
 none 	right  that   that sometimes it might be better to do that 
 none 	but  um  i don t think we know for sure 
 none 	so  um
 none 	right   so   next week    we   uh  won t meet because you ll be in europe  
 find_calendar_entry 	whe  when are  you two   getting back   
 none 	um  i m
 none 	you on friday or s  on saturday or  
 none 	sunday because it s   it s less expensive  the price   the price the ticket 
 none 	s  oh yeah  sunday  yeah 
 none 	yeah  that s right 
 none 	ah 
 none 	you ve gotta s  have a saturday overnight  right 
 none 	i ll be back on tuesday 
 none 	tuesday 
 none 	where   where s the meeting 
 none 	um
 none 	uh  amsterdam  i think  yeah  yeah 
 none 	yeah  amsterdam 
 none 	uh huh 
 none 	yeah  yeah 
 none 	yep 
 none 	um
 create_calendar_entry 	so   we ll  skip  next week     and  we ll  meet  two weeks from now   
 add_agenda_item 	and  uh  i guess the main topic will be  uh   you telling us what happened   
 none 	yeah 
 none 	yeah 
 none 	uh  so
 none 	yeah  well  if we don t have an  anything else to discuss  we should  uh  turn off the machine and then say the real nasty things 
 none 	should we do digits first 
 none 	oh yeah  digits 
 none 	oh  yeah  digits 
 none 	yeah 
 none 	yeah  good point 
 none 	yeah  good thinking 
 none 	why don t you go ahead 
 none 	o_k 
 none 	transcript three seven nine one three eight one zero nine zero four zero two zero zero seven one one seven o_ four two four o_ nine two two one three six one three five o_ nine four nine five six zero six zero seven eight five six eight zero nine seven
 none 	o_ five o_ five zero seven zero one zero zero nine one two three o_ seven nine eight eight o_ five seven six three nine seven seven one eight eight nine
 none 	transcript three seven five one dash three seven seven zero  eight five five seven three zero six nine six six o_
 none 	o_ zero one two o_ four two five five six six six seven eight two eight nine
 none 	o_ o_ one one two three four three eight six four four eight three five six seven zero four three zero zero seven
 none 	transcript three six seven one dash three six nine zero  four five zero zero four two seven two o_ three eight five three o_ five one o_ nine seven one eight four seven six
 none 	o_ zero nine four five one o_ three two four one one five five four nine nine two six six three seven seven nine eight eight zero zero two eight five nine o_ seven o_
 none 	o_ o_ eight one two two eight six eight three five three seven one zero nine four five
 none 	transcript six nine 
 none 	uh  yeah  i m sorry 
 none 	transcript three six nine one three seven one o_  five six seven o_ six nine four five
 none 	o_ one five zero three two one seven two zero two six two four three o_ four four o_ five five four six one seven o_ o_ seven five eight six two eight three eight eight four nine eight o_
 none 	o_ zero zero one nine eight one zero zero three two eight zero nine four two five four five
 none 	transcript number three seven seven one dash three seven nine o_  nine one o_ eight
 none 	o_ four six nine o_ zero seven one six o_ one two three four zero zero zero six four seven six five nine nine zero eight five seven six seven two eight five six eight three six seven four one three nine eight nine
 none 	o_ zero
 none 	o_
 none 	i m sorry  one o_ three one four o_ four seven five seven three six nine six five seven eight
 none 	o_k 
 none 	 st 
 none 	am i on  i guess so 
 none 	radio two 
 none 	hmm 
 none 	radio two 
 none 	hello 
 none 	video killed the radio star 
 none 	wow 
 none 	mm hmm 
 none 	hi 
 none 	blow into it  it works really well 
 none 	channel b_ 
 none 	people say the strangest things when their microphones are on 
 none 	channel four 
 none 	test 
 none 	o_k 
 none 	uh oh 
 none 	radio four 
 none 	hello 
 none 	today s
 none 	so everybody  everybody s on  yeah 
 find_calendar_entry 	so y   you guys  had a   a  meeting  with uh   with  hynek  which i unfortunately had to miss  
 none 	um
 none 	mmm 
 none 	and uh somebody eh e  and uh i guess  chuck  you weren t there either  so the  uh
 none 	i  was there 
 none 	oh  you  were there 
 none 	with  hynek  
 none 	yeah 
 none 	yeah 
 none 	so everybody knows what happened except me 
 none 	o_k 
 none 	maybe somebody should tell me 
 none 	oh yeah 
 none 	alright 
 find_email 	well   uh first we discussed about some of the points that i was addressing in the mail  i  sent  last week   
 none 	uh huh 
 none 	so 
 none 	yeah 
 none 	about the um  well    the downsampling problem  
 none 	yeah 
 none 	uh and about the f   the length of the filters  and  
 none 	yeah 
 none 	what was the   w  what was the downsampling problem again  i forget 
 none 	so we had  
 none 	so the fact that there   there is no uh low pass filtering before the downsampling 
 none 	well 
 none 	uh huh 
 none 	there is because there is l_d_a filtering but that s perhaps not uh the best w  m  well 
 none 	depends what it s frequency characteristic is  yeah 
 none 	mm hmm 
 none 	system on
 none 	so you could do a   you could do a stricter one 
 none 	maybe  yeah 
 none 	yeah 
 none 	so we discussed about this  about the um  
 none 	was there any conclusion about that 
 none 	uh  try it   yeah 
 none 	i see 
 none 	i guess 
 none 	uh 
 none 	yeah  so again this is th  this is the downsampling uh of the uh   the feature vector stream and um
 none 	yeah i guess the   the uh l_d_a filters they were doing do have um
 none 	uh let s see  so the   the   the feature vectors are calculated every ten milliseconds so uh the question is how far down they are at fifty   fifty hertz  uh 
 none 	yeah 
 none 	mm hmm 
 none 	um 
 none 	sorry at twenty  five hertz since they re downsampling by two 
 none 	so  does anybody know what the frequency characteristic is 
 none 	we don t have yet um
 none 	oh o_k 
 none 	so  yeah 
 none 	o_k 
 none 	we should have a look first at  perhaps  the modulation spectrum 
 none 	yeah 
 none 	um 
 none 	so there is this  there is the um length of the filters 
 none 	um 
 none 	so the i  this idea of trying to find filters with shorter delays 
 none 	um 
 none 	hmm hmm 
 none 	we started to work with this 
 none 	mmm 
 none 	and the third point um was the um  yeah  the on line normalization where  well  the recursion f  recursion for the mean estimation is a filter with some kind of delay and that s not taken into account right now 
 none 	yeah 
 none 	um 
 none 	yeah 
 none 	and there again  yeah 
 none 	for this  the conclusion of hynek was  well 
 none 	 we can try it but   
 none 	uh huh 
 none 	um 
 none 	try   try what 
 none 	so try to um um take into account the delay of the recursion for the mean estimation 
 none 	o_k 
 none 	mmm 
 none 	and this   we ve not uh worked on this yet 
 none 	um  yeah 
 none 	and so while discussing about these   these l_d_a filters  some i  issues appeared  like well  the fact that if we look at the frequency response of these filters it s uh  well  we don t know really what s the important part in the frequency response and there is the fact that in the very low frequency  these filters don t   don t really remove a lot  compared to the   to the uh standard rasta filter 
 none 	uh and that s probably a reason why  yeah  on line normalization helps because it   it  yeah  it removed this mean 
 none 	right 
 none 	um 
 none 	yeah  but perhaps everything could   should be   could be in the filter  i mean  uh the   the mean normalization and  
 none 	yeah  so 
 none 	yeah  so basically that was   that s all we discussed about  we discussed about good things to do also uh well  generally good stuff to do for the research 
 none 	mm hmm 
 none 	and this was this l_d_a uh tuning perhaps and
 none 	hynek proposed again to his uh traps  so 
 none 	o_k 
 none 	yeah  um 
 none 	i mean i g  i guess the key thing for me is   is figuring out how to better coordinate between the two sides cuz   because um uh i was talking with hynek about it later and the   the   sort of had the sense sort of that   that neither group of people wanted to   to bother the other group too much 
 none 	mm hmm 
 none 	and   and i don t think anybody is  you know  closed in in their thinking or are unwilling to talk about things but i think that you were sort of waiting for them to tell you that they had something for you and   and that   and expected that they would do certain things and they were sor  they didn t wanna bother you and they were sort of waiting for you and   and   and uh we ended up with this thing where they   they were filling up all of the possible latency themselves  and they just had  hadn t thought of that  so 
 none 	mm hmm 
 none 	uh 
 none 	yeah  well  but  yeah 
 none 	yeah 
 none 	i mean it s true that maybe   maybe no one really thought about that   that this latency thing would be such a   a strict issue in   in uh   the other  
 none 	well  
 none 	yeah i don t know what happened really  but
 none 	yeah 
 none 	i guess it s   it s also so uh the time constraints  because  well  we discussed about that   about this problem and they told us  well  we will do all that s possible to have enough space for a network  but then  yeah  perhaps they were too short with the time and uh yeah 
 none 	then they couldn t 
 none 	i see 
 none 	but there was also problem   perhaps a problem of communication  so  yeah 
 none 	now we will try to  
 none 	just talk more 
 none 	yeah  slikes and send mails  u  s  o  o 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	uh 
 none 	o_k  
 none 	so there s um  
 none 	alright  well maybe we should just uh i mean you re   you re bus  other than that you folks are busy doing all the   all the things that you re trying that we talked about before right  and this   machines are busy and you re busy and
 none 	yeah 
 none 	basically 
 none 	yeah 
 none 	o_k 
 none 	um 
 none 	oh 
 find_email 	let s   let s  i mean  i think that as   as we said before that one of the things that we re imagining is that uh there   there will be uh in the system we end up with there ll be something to explicitly uh uh do something about noise in addition to the uh other things that we re talking about and that s probably the best thing to do   and there was that one email that said that  it sounded like uh uh things looked very promising up there in terms of uh i think they were using ericsson s approach or something and in addition to  
 none 	mm hmm 
 none 	they re doing some noise removal thing  right 
 none 	yeah  yeah 
 none 	so yeah we re   will start to do this also 
 none 	yeah 
 none 	uh so carmen is just looking at the ericsson   ericsson code 
 none 	yeah  we modif 
 none 	mm hmm 
 none 	yeah  i modified it   well  modifying  
 none 	and
 none 	i studied barry s sim code   more or less  to take  the first step the spectral subtraction  and we have some   the feature for italian database and we will try with this feature with the filter to find the result  but we haven t result until this moment 
 none 	mm hmm 
 none 	mm hmm 
 none 	yeah  sure 
 none 	but well  we are working in this also and maybe try another type of spectral subtraction  i don t  
 none 	yeah 
 none 	when you say you don t have a result yet you mean it s   it s just that it s in process or that you   it finished and it didn t get a good result 
 none 	no 
 none 	no  no n  we have n  we have do the experiment only have the feature   the feature but the experiment have we have not make the experiment and maybe will be good result or bad result  we don t know 
 none 	yeah 
 none 	oh 
 none 	o_k 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	o_k 
 none 	so um i suggest actually now we   we   we sorta move on and   and hear what s   what s   what s happening in   in other areas like what s   what s happening with your investigations about echos and so on 
 none 	oh um
 none 	well um
 find_calendar_entry 	i haven t started writing the test yet   i m  meeting with  adam   today  um and  he s going t  show me the scripts he has for um running recognition on mee  meeting recorder digits   
 none 	mm hmm 
 none 	mm hmm 
 none 	uh
 none 	i also um haven t got the code yet  i haven t asked hynek for   for the   for his code yet 
 none 	cuz i looked at uh avendano s thesis and
 none 	i don t really understand what he s doing yet but it   it   it sounded like um the channel normalization part um of his thesis um was done in a   a bit of
 none 	i don t know what the word is  a   a bit of a rough way um it sounded like he um he   he   it   it wasn t really fleshed out and maybe he did something that was interesting for the test situation but i   i m not sure if it s what i d wanna use so i have to   i have to read it more  i don t really understand what he s doing yet 
 none 	o_k 
 none 	it s my
 none 	yeah i haven t read it in a while so i m not gonna be too much help unless i read it again  so 
 none 	oh yeah 
 none 	i know this is mine here 
 none 	o_k 
 none 	um 
 create_single_reminder 	the um   so you  and then you re also gonna be  doing this echo cancelling between the   the close mounted and the   and the   the   the   what we re calling a cheating experiment uh of sorts between the distant  
 none 	uh i 
 none 	i m ho 
 none 	right  well   or i m hoping  
 send_email 	i m hoping espen will do it 
 none 	um u 
 none 	ah 
 none 	o_k 
 none 	f  um
 none 	delegate 
 none 	that s good 
 none 	it s good to delegate 
 none 	i   i think he s at least planning to do it for the cl  close mike cross talk and so maybe i can just take whatever setup he has and use it 
 none 	great 
 none 	great 
 none 	yeah actually um he should uh
 none 	i wonder who else is
 none 	i think maybe it s dan ellis is going to be doing uh a different cancellation  um 
 none 	one of the things that people working in the meeting task wanna get at is they would like to have cleaner close miked recordings 
 none 	so uh this is especially true for the lapel but even for the close   close miked uh cases um we d like to be able to have um other sounds from other people and so forth removed from   so when someone isn t speaking you d like the part where they re not speaking to actually be  
 none 	so what they re talking about doing is using ec  uh echo cancellation like techniques  it s not really echo but uh just um uh taking the input from other mikes and using uh uh a uh   an adaptive filtering approach to remove the effect of that uh other speech 
 none 	so 
 none 	um what was it  there was   there was some   some   some point where eh uh eric or somebody was   was speaking and he had lots of silence in his channel and i was saying something to somebody else uh which was in the background and it was not   it was recognizing my words  which were the background speech on the close   close mike 
 none 	hmm 
 find_calendar_entry 	oh the   what  we  talked about  yesterday    yeah that was actually my   i was wearing the  
 none 	yes 
 none 	oh you   it was you i was
 none 	i was wearing the lapel and you were sitting next to me  and i only said one thing but you were talking and it was picking up all your words 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	so they would like  clean channels   
 none 	uh and for that   mmm uh   that purpose uh they d like to pull it out 
 none 	so i think  
 search 	i think  dan ellis  or somebody who was working with him was going to uh work on  that   
 none 	so 
 none 	o_k 
 none 	right 
 none 	um 
 none 	and uh i don t know if we ve talked lately about the   the plans you re developing that we talked about this morning uh
 none 	i don t remember if we talked about that last week or not  but maybe just a quick reprise of   of what we were saying this morning  uh 
 none 	yeah 
 none 	o_k 
 none 	um 
 none 	so continuing to um extend uh
 none 	larry saul s work um just reading   reading how   how we can take that as a front end cuz it   it detects these features and they plug it into um back end so i ve been looking at a lot of um back end stuff people have been doing articulatory features and seeing   seeing what i can   what i can pull off the shelf and plug into um larry saul s work 
 none 	what about the stuff that um
 none 	mirjam has been doing 
 none 	oh yeah  sh 
 none 	and   and s  shawn  yeah 
 none 	and shawn 
 none 	yeah  they re   they re doing uh neural nets  just   just training up a whole bunch of neural nets and
 none 	oh 
 none 	i   i think they re trying to understand um what s good about neural nets in   in terms of  you know  their patterns of errors and
 none 	so they re training up nets to try to recognize these acoustic features 
 none 	yeah 
 none 	i see 
 none 	yeah 
 none 	but that s uh uh all   that s   is a   a certainly relevant uh study and  you know  what are the features that they re finding 
 none 	we have this problem with the overloading of the term  feature  so uh what are the variables  what we re calling this one  what are the variables that they re found   finding useful um for  
 none 	yeah 
 none 	hmm 
 none 	and their   their targets are based on canonical mappings of phones to acoustic f  features 
 none 	right  and that s certainly one thing to do and we re gonna try and do something more f  more fine than that but uh um
 none 	so um
 none 	so i guess you know what  i was trying to remember some of the things we were saying  do you ha  still have that    
 none 	oh yeah 
 none 	yeah 
 none 	there s those that uh yeah  some of   some of the issues we were talking about was in j  just getting a good handle on   on uh what  good features  are and  
 search 	what does   what did um  larry saul  use for   it was the  sonorant uh detector   right  
 none 	he di  he did uh yeah 
 none 	how did he  
 none 	h  how did he do that  wh  what was his detector 
 none 	we  oh 
 none 	um yeah  it was uh sonorance and he also had a paper on voicing too 
 none 	mm hmm 
 none 	um and basically um in his variables that he used um or measures of s_n_r at   at sub bands  actually critical bands like um the um measures of correlation and covariance um within the sub bands and um and at the upper level detecting uh sonorance and voicing 
 none 	mm hmm 
 none 	oh  o_k 
 none 	mm hmm 
 none 	so how did he combine all these features  what   what r  mmm classifier did he u 
 none 	oh 
 none 	um he used uh um uh a   a belief net where the lower levels of the belief net are   correspond to individual tests of whether there is sonorance within this critical band and then at an upper level um there s like this soft  or  gate so if   so if yeah  yeah 
 none 	hmm 
 none 	oh right  you were talking about that  yeah 
 none 	i see 
 none 	and the other thing you were talking about is   is   is where we get the targets from 
 none 	so i mean  there s these issues of what are the   what are the variables that you use and do you combine them using the soft  and or  or you do something  you know  more complicated um and then the other thing was so where do you get the targets from 
 none 	the initial thing is just the obvious that we re discussing is starting up with phone labels from somewhere and then uh doing the transformation 
 none 	but then the other thing is to do something better and eh w  why don t you tell us again about this   this database 
 none 	this is the  
 none 	oh o_k  um
 none 	yeah  so there s uh a group at um edinburgh is working on um this mocha database where um they have measurements of um articulatory positions  so you   you put some   some pellets on people s tongues and lips and   and they can tell and they
 none 	hmm 
 none 	and then tell them to talk naturally 
 none 	yeah  yeah 
 none 	well i guess if you got people who had like um you know  tongue rings  
 none 	pierced tongues and
 none 	pierced tongues  or  
 none 	yeah 
 none 	you could just mount it to that and they wouldn t even notice 
 none 	yeah it doesn t matter  
 none 	yeah 
 none 	weld it  zzz 
 none 	but i   i don t   i don t think they re doing that though 
 none 	maybe you could go to these parlors and   and you could  you know   you know have   have  you know  reduced rates if you   if you can do the measurements 
 none 	yeah  i 
 none 	that s right 
 none 	you could   what you could do is you could sell little rings and stuff with embedded you know  transmitters in them and things and
 none 	yeah 
 none 	yeah  be cool and help science 
 none 	yeah 
 none 	ye  cool 
 none 	yeah 
 none 	o_k 
 none 	yeah  so they   they   they have this   they re working on the database  it s still   it s still being   being uh transcribed and produced 
 none 	um where either you have um acoustic features at the same or   or just uh the acoustic waveform s being recorded for frame and then at each frame you have a measurement of   of the different positions of um uh articulators 
 none 	hmm 
 none 	there s a bunch of data that l  around  that   people have done studies like that w  way way back right  i mean
 none 	i can t remember where   uh wisconsin or someplace that used to have a big database of  
 none 	yeah they have a x_   x_ray  
 none 	yeah 
 none 	x_ray database 
 none 	yeah 
 none 	it s
 none 	i remember there was this guy at a_t_and_t  randolph  or r 
 none 	what was his name  do you remember that guy 
 none 	um  researcher at  a_t_and_t  a while back that was studying  trying to do speech recognition from these kinds of features 
 none 	hmm 
 none 	i can t remember what his name was 
 none 	dang  now i ll think of it 
 none 	hmm 
 search 	do you mean eh   but you   i mean   mar  you mean when was   was  mark randolph   there   or    
 none 	that s interesting 
 none 	well he was the guy   the guy that was using  
 none 	mark randolph 
 none 	yeah he s   he s   he s at motorola now 
 none 	oh is he  oh o_k 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	is it the guy that was using the pattern of pressure on the tongue or    
 none 	i can t remember exactly what he was using  now 
 none 	but i know   i just remember it had to do with you know uh positional parameters and trying to m  you know do speech recognition based on them 
 none 	what  
 none 	yeah 
 none 	mm hmm 
 none 	yeah 
 none 	so the only   the only uh hesitation i had about it since  i mean i haven t see the data is it sounds like it s   it s continuous variables and a bunch of them 
 none 	hmm 
 none 	and so
 none 	i don t know how complicated it is to go from there  
 none 	what you really want are these binary labels  and just a few of them 
 none 	and maybe there s a trivial mapping if you wanna do it and it s e  but it  
 create_single_reminder 	i   i   i worry a little bit that this is a research project in itself  whereas um if you did something instead that   like um having some manual annotation by uh you know  linguistics students  this would   there d be a limited s  set of things that you could do a  as per our discussions with   with john before but  the things that you could do  like nasality and voicing and a couple other things you probably could do reasonably well   
 none 	mm hmm 
 none 	mm hmm 
 none 	and then there would   it would really be uh this uh uh binary variable 
 none 	course then  that s the other question is do you want binary variables  so 
 create_single_reminder 	i mean the other thing you could do is  boot trying to   to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there  but
 none 	i   i m not sure  
 none 	could you cluster the   just do some kind of clustering 
 none 	guess you could  yeah 
 none 	bin them up into different categories and  
 none 	yeah 
 none 	so anyway that s   that s uh   that s another whole direction that cou  could be looked at 
 none 	mm hmm 
 none 	um 
 none 	um 
 none 	i mean in general it s gonna be   for new data that you look at  it s gonna be hidden variable because we re not gonna get everybody sitting in these meetings to wear the pellets and  
 none 	right 
 none 	um 
 none 	right 
 none 	so 
 none 	so you re talking about using that data to get uh instead of using canonical mappings of phones  so you d use that data to give you sort of what the   the true mappings are for each phone 
 none 	right 
 none 	mm hmm 
 none 	i see 
 none 	mm hmm 
 none 	yeah 
 none 	so wh  yeah  where this fits into the rest in   in my mind  i guess  is that um we re looking at different ways that we can combine uh different kinds of   of rep  front end representations um in order to get robustness under difficult or even  you know  typical conditions 
 none 	and part of it  this robustness  seems to come from uh multi stream or multi band sorts of things and saul seems to have a reasonable way of looking at it  at least for one   one um articulatory feature 
 none 	the question is is can we learn from that to change some of the other methods we have  since  
 none 	i mean  one of the things that s nice about what he had i thought was that   that it   it um  
 none 	the decision about how strongly to train the different pieces is based on uh a   a reasonable criterion with hidden variables rather than um just assuming that you should train e  e  every detector uh with equal strength towards uh it being this phone or that phone 
 none 	hmm 
 none 	right 
 none 	so it   so um he s got these um uh uh he  and s  between these different features 
 none 	it s a soft  and   i guess but in   in principle you   you wanna get a strong concurrence of all the different things that indicate something and then he  or s  across the different   soft  or s  across the different uh multi band channels 
 none 	and um the weight yeah  the target for the training of the  and     and ed  things is something that s kept uh as a hidden variable  and is learned with e_m 
 none 	so he doesn t have  
 none 	whereas what we were doing is   is uh taking the phone target and then just back propagating from that which means that it s   it s uh i  it could be for instance that for a particular point in the data you don t want to um uh train a particular band   train the detectors for a particular band  you   you wanna ignore that band  cuz that s a   ban  band is a noisy   noisy measure 
 none 	mm hmm 
 none 	and we don t  
 none 	we re   we re still gonna try to train it up 
 none 	in our scheme we re gonna try to train it up to do as well   well as it can at predicting 
 none 	uh  maybe that s not the right thing to do 
 none 	so he doesn t have to have truth marks or   ho 
 none 	f  right  and uh he doesn t have to have hard labels 
 none 	well at the   at the tail end  yeah  he has to know what s   where it s sonorant 
 none 	right  for the full band 
 none 	but he s   but what he s  but what he s not training up   uh what he doesn t depend on as truth is um
 none 	i guess one way of describing would be if   if a sound is sonorant is it sonorant in this band  is it sonorant in that band  is it sonorant in that band  i  it s hard to even answer that what you really mean is that the whole sound is sonorant  so then it comes down to  you know  to what extent should you make use of information from particular band towards making your decision 
 none 	right 
 none 	mm hmm  o_k 
 none 	i see 
 none 	and um uh we re making in a sense sort of this hard decision that you should   you should use everything uh with   with uh equal strength 
 none 	and uh because in the ideal case we would be going for posterior probabilities  if we had uh enough data to really get posterior probabilities and if the   if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can 
 none 	but um this is something that s more built up along an idea of robustness from   from the beginning and so you don t necessarily want to train everything up towards the  
 none 	so where did he get his   uh his tar  his uh high level targets about what s sonorant and what s not 
 none 	from uh canonical mappings um at first and then it s unclear um eh using timit right  right 
 none 	o_k 
 none 	yeah 
 none 	using timit  or using  
 none 	uh huh 
 none 	and then uh he does some fine tuning um for um special cases 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	i mean we ha  we have a kind of iterative training because we do this embedded viterbi  uh so there is some  something that s suggested  based on the data but it s   it s not  
 none 	i think it s  doesn t seem like it s quite the same  cuz of this   cuz then whatever that alignment is  it s that for all   all bands  well no  that s not quite right  we did actually do them separate   tried to do them separately so that would be a little more like what he did 
 none 	mm hmm 
 none 	um 
 none 	but it s still not quite the same because then it s   it s um setting targets based on where you would say the sound begins in a particular band 
 none 	where he s s  this is not a labeling per se 
 none 	mm hmm 
 none 	might be closer i guess if we did a soft   soft target uh uh embedded neural net training like we ve done a few times uh f  the forward um   do the forward calculations to get the gammas and train on those 
 none 	mmm 
 none 	uh what s next 
 none 	i could say a little bit about w  stuff i ve been playing with 
 none 	oh 
 none 	i um
 none 	you re playing 
 none 	huh 
 none 	you re playing 
 none 	yes  i m playing 
 none 	um so i wanted to do this experiment to see um uh what happens if we try to uh improve the performance of the back end recognizer for the aurora task and see how that affects things 
 none 	and so i had this um  
 none 	i think i sent around last week a   this plan i had for an experiment  this matrix where
 none 	i would take the um   the original um the original system  so there s the original system trained on the mel cepstral features and then com  and then uh optimize the b 
 none 	h_t_k system and run that again 
 none 	so look at the difference there and then uh do the same thing for the i_c_s_i o_g_i front end 
 none 	what   which test set was this 
 none 	this is   that i looked at 
 none 	mm hmm 
 none 	uh i m looking at the italian right now 
 none 	mm hmm 
 none 	so as far as i ve gotten is i ve uh been able to go through from beginning to end the um full h_t_k system for the italian data and got the same results that um   that uh
 none 	stephane had 
 none 	so um
 none 	i started looking   to   and now i m  
 none 	i m sort of lookin  at the point where i wanna know what should i change in the h_t_k back end in order to try to   uh to improve it 
 none 	so 
 none 	one of the first things i thought of was the fact that they use the same number of states for all of the models and so i went on line and i uh found a pronunciation dictionary for italian digits and just looked at  you know  the number of phones in each one of the digits 
 none 	mm hmm 
 none 	mm hmm 
 none 	um you know  sort of the canonical way of setting up a   an h_m_m system is that you use um three states per phone and um so then the   the total number of states for a word would just be  you know  the number of phones times three 
 none 	and so when i did that for the
 none 	italian digits  i got a number of states  ranging on the low end from nine to the high end  eighteen 
 none 	um 
 none 	now you have to really add two to that because in h_t_k there s an initial null and a final null so when they use uh models that have eighteen states  there re really sixteen states  they ve got those initial and final null states 
 none 	and so um their guess of eighteen states seems to be pretty well matched to the two longest words of the italian digits  the four and five which um  according to my  you know  sort of off the cuff calculation  should have eighteen states each 
 none 	mm hmm 
 none 	and so they had sixteen  so that s pretty close 
 none 	um but for the   most of the words are sh  much shorter 
 none 	so the majority of them wanna have nine states 
 none 	and so theirs are s  sort of twice as long 
 none 	so my guess   uh
 none 	and then if you  
 none 	i   i printed out a confusion matrix um uh for the well matched case  and it turns out that the longest words are actually the ones that do the best 
 none 	so my guess about what s happening is that you know  if you assume a fixed   the same amount of training data for each of these digits and a fixed length model for all of them but the actual words for some of them are half as long you really um have  you know  half as much training data for those models 
 none 	because if you have a long word and you re training it to eighteen states  uh you ve got   you know  you ve got the same number of
 none 	mm hmm 
 none 	gaussians  you ve gotta train in each case  but for the shorter words  you know  the total number of frames is actually half as many 
 none 	mm hmm 
 none 	so it could be that  you know  for the short words there s   because you have so many states  you just don t have enough data to train all those gaussians 
 none 	so um
 create_single_reminder 	i m going to try to um  create more word specific um uh prototype h_m_ms to start training from   
 none 	yeah  i mean  it s not at all uncommon you do worse on long word  on short words than long words anyway just because you re accumulating more evidence for the   for the longer word  but 
 none 	mm hmm 
 create_single_reminder 	yeah so i ll   i ll  the next experiment i m gonna try is to just um you know  create uh models that seem to be more w  matched to my guess about how long they should be   
 none 	mm hmm 
 none 	and as part of that um
 none 	i wanted to see sort of how the um   how these models were coming out  you know  what w  when we train up uh th  you know  the model for   one    which wants to have nine states  you know  what is the   uh what do the transition probabilities look like   in the self loops  look like in   in those models 
 find_calendar_entry 	and so  i  talked to  andreas  and he explained to me how you can calculate the expected duration of an h_m_m just by looking at the transition matrix and so i wrote a little matlab script that calculates that and so i m gonna sort of print those out for each of the words to see what s happening  you know  how these models are training up  you know  the long ones versus the short ones  
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	i d  i did   quickly  i did the silence model and   and um that s coming out with about one point two seconds as its average duration and the silence model s the one that s used at the beginning and the end of each of the string of digits 
 none 	wow 
 none 	lots of silence 
 none 	yeah  yeah 
 none 	and so the
 none 	s_ p model  which is what they put in between digits  i   i haven t calculated that for that one yet  but um 
 none 	so they basically   their   their model for a whole digit string is silence digit 
 none 	s_p  digit 
 none 	s_p blah blah blah and then silence at the end 
 none 	and so 
 none 	are the s_p s optional  i mean skip them 
 none 	i have to look at that  but i m not sure that they are 
 none 	now the one thing about the s_ p model is really it only has a single s  emitting state to it 
 none 	mm hmm 
 none 	so if it s not optional  you know  it s   it s not gonna hurt a whole lot and it s tied to the center state of the silence model so it s not its own   um
 none 	i see 
 none 	mm hmm 
 none 	it doesn t require its own training data  it just shares that state 
 none 	mm hmm 
 none 	so it  i mean  it s pretty good the way that they have it set up  but um i 
 none 	so i wanna play with that a little bit more 
 none 	i m curious about looking at  you know how these models have trained and looking at the expected durations of the models and i wanna compare that in the   the well matched case f  to the unmatched case  and see if you can get an idea of   just from looking at the durations of these models  you know  what  what s happening 
 none 	yeah  i mean  i think that uh  as much as you can  it s good to d  sort of not do anything really tricky 
 none 	mm hmm 
 none 	not do anything that s really finely tuned  but just sort of eh you know you t  you i  z 
 none 	yeah 
 none 	the premise is kind of you have a   a good person look at this for a few weeks and what do you come up with 
 none 	mm hmm 
 none 	mm hmm 
 none 	and uh
 find_calendar_entry 	and  hynek   when  i  wa  told him about this  he had an interesting point  and that was th  um the   the final models that they end up training up have
 none 	i think probably something on the order of six
 none 	gaussians per state 
 none 	so they re fairly  you know  hefty models  and hynek was saying that well  probably in a real application  you wouldn t have enough compute to handle models that are very big or complicated 
 none 	so in fact what we may want are simpler models 
 none 	could be 
 none 	and compare how they perform to that  but you know  it depends on what the actual application is and it s really hard to know what your limits are in terms of how many gaussians you can have 
 none 	right  and that  i mean  at the moment that s not the limitation  so 
 none 	mm hmm 
 none 	i mean  i   i   i   what i thought you were gonna say i  but which i was thinking was um where did six come from  probably came from the same place eighteen came from  you know  so 
 none 	yeah  right 
 none 	uh that s another parameter  right  that   that maybe  you know  uh   you really want three or nine or  
 none 	yeah  yeah 
 none 	well one thing   i mean  if i   if   if i start um reducing the number of states for some of these shorter models that s gonna reduce the total number of gaussians  so in a sense it ll be a simpler system 
 none 	right 
 none 	yeah 
 none 	yeah 
 none 	but i think right now again the idea is doing just very simple things how much better can you make it  and um since they re only simple things there s nothing that you re gonna do that is going to blow up the amount of computation um so if you found that nine was better than six that would be o_ k  i think  actually 
 none 	yeah 
 none 	mm hmm 
 none 	right 
 none 	right 
 none 	mm hmm 
 none 	yeah 
 none 	doesn t have to go down 
 none 	i really wasn t even gonna play with that part of the system yet  i was just gonna change the   the t  yeah  just look at the length of the models and just see what happens 
 none 	mm hmm  o_k 
 none 	yeah  just work with the models  yeah 
 none 	yeah 
 none 	so 
 none 	cool 
 none 	o_k 
 none 	so uh what s uh
 none 	i guess your plan for  
 none 	you   you   you guys  plan for the next   next week is just continue on these   these same things we ve been talking about for aurora and
 create_single_reminder 	yeah  i guess we can try to  have some kind of new baseline for next week perhaps    with all these minor things modified 
 none 	and then do other things  play with the spectral subtraction  and retry the m_s_g and things like that 
 none 	yeah 
 none 	yeah 
 none 	yeah we   we have a big list 
 none 	big list 
 none 	you have a big list of   of things to do 
 none 	so 
 none 	well that s good  i think that after all of this uh um confusion settles down in another   some point a little later next year there will be some sort of standard and it ll get out there and hopefully it ll have some effect from something that   that has uh been done by our group of people but uh e  even if it doesn t there s   there s go  there ll be standards after that 
 none 	so 
 none 	does anybody know how to um run matlab sort of in batch mode like you c  send it s  a bunch of commands to run and it gives you the output  is it possible to do that 
 none 	i   i think uh mike tried it and he says it s impossible so he went to octave 
 none 	yeah 
 none 	octave is the um unix clone of   of matlab which you can batch 
 none 	octave 
 none 	ah 
 none 	o_k  
 none 	great 
 none 	thanks 
 none 	yeah 
 none 	i was going crazy trying to do that 
 none 	huh 
 none 	yeah 
 search 	what is  octave  so  
 none 	it s a free software 
 none 	what s that 
 none 	uh  octave  yeah it s   it s   it s free  i think we have it here r  running somewhere 
 none 	yeah 
 none 	great 
 none 	yeah 
 none 	and it does the same syntax and everything eh like matlab  or    
 none 	um i  it s a little behind  it s the same syntax but it s a little behind in that
 none 	matlab went to these like um you can have cells and you can   you can uh implement object oriented type things with matlab 
 none 	uh octave doesn t do that yet  so i think you  octave is kinda like matlab um four point something or 
 none 	if it ll do like a lot of the basic matrix and vector stuff that s perfect 
 none 	the basic stuff  right 
 none 	yeah 
 none 	great 
 none 	o_k  guess we re done 
 none 	o_k 
 none 	well   although by the way 
 none 	it s not very significant 
 none 	channel three  channel three 
 none 	uh  channel one  yes  o_k 
 none 	mm hmm 
 none 	ta 
 none 	channel three  alright 
 none 	o_k  did you solve speech recognition last week 
 none 	almost 
 none 	alright  let s do image processing 
 none 	yes  again 
 none 	great 
 none 	we did it again  morgan 
 none 	alright 
 none 	doo doop  doo doo 
 none 	what s wrong with    
 none 	o_k  it s april fifth 
 find_calendar_entry 	actually   hynek  should be  getting back in town   shortly  if he isn t already  
 none 	is he gonna come here 
 none 	uh  well  we ll drag him here  i know where he is 
 none 	so when you said  in town   you mean oregon 
 none 	u  u  u  u  uh  i meant  you know  this end of the world  yeah  is really what i meant  uh  cuz he s been in europe 
 none 	oh 
 none 	doo  doo doo 
 none 	doo doo 
 none 	so 
 none 	i have something just fairly brief to report on 
 none 	mmm  great 
 none 	um  i did some experim  uh  uh  just a few more experiments before i had to  uh  go away for the w  well  that week 
 none 	was it last week or whenever 
 none 	um  so what i was started playing with was the   th  again  this is the h_t_k back end  and  um 
 none 	i was curious because the way that they train up the models  they go through about four sort of rounds of   of training  and in the first round they do   uh  i think it s three iterations  and for the last three rounds e  e  they do seven iterations of re estimation in each of those three 
 none 	and so  you know  that s part of what takes so long to train the   the   the back end for this 
 none 	i m sorry  i didn t quite get that  there s   there s four and there s seven and   i   i m sorry 
 none 	yeah  uh  maybe i should write it on the board  so  there s four rounds of training  um 
 none 	i g  i g  i guess you could say iterations 
 none 	the first one is three  then seven  seven  and seven 
 none 	and what these numbers refer to is the number of times that the  uh  h_m_m re estimation is run  it s this program called h_e_rest 
 none 	but in h_t_k  what s the difference between  uh  a   an inner loop and an outer loop in these iterations 
 none 	o_k  so what happens is  um  at each one of these points  you increase the number of gaussians in the model 
 none 	yeah 
 none 	oh  right  this was the mix up stuff  that s right  i remember now 
 none 	yeah  the mix up  right 
 none 	and so  in the final one here  you end up with  uh   for all of the   the digit words  you end up with  uh  three mixtures per state  eh  in the final thing 
 none 	yeah 
 none 	so i had done some experiments where i was   i   i want to play with the number of mixtures  but  um  uh  i wanted to first test to see if we actually need to do this many iterations early on  and so  um  i   i ran a couple of experiments where i reduced that to l  to be three  two  two  uh  five  i think  and i got almost the exact same results 
 none 	mm hmm 
 none 	uh  one  two 
 none 	mm hmm 
 none 	and   but it runs much much faster 
 none 	mm hmm 
 none 	so  um  i   i think m  it only took something like  uh  three or four hours to do the full training  as opposed to wh  what  sixteen hours or something like that 
 none 	as opposed to    
 none 	good 
 none 	yeah  it depends 
 none 	i mean  it takes   you have to do an overnight basically  the way it is set up now 
 none 	mm hmm 
 none 	mm hmm 
 none 	so  uh  even we don t do anything else  doing something like this could allow us to turn experiments around a lot faster 
 none 	and then when you have your final thing  do a full one  so it s  
 none 	and when you have your final thing  we go back to this 
 none 	yeah 
 none 	so  um  and it s a real simple change to make  i mean  it s like one little text file you edit and change those numbers  and you don t do anything else  and then you just run 
 none 	oh  this is a  
 none 	mm hmm 
 none 	o_k 
 none 	so it s a very simple change to make and it doesn t seem to hurt all that much  so i  
 none 	so you   you run with three  two  two  five  that s a 
 none 	uh  i   i have to look to see what the exact numbers were  i   i thought was  like  three  two  two  five  but i  i ll   i ll double check  it was over a week ago that i did it  so i can t remember exactly  but  uh   um  but it s so much faster 
 none 	yeah 
 none 	mm hmm 
 none 	o_k  mm hmm 
 none 	oh 
 none 	mm hmm 
 none 	hmm 
 none 	i  it makes a big difference  so we could do a lot more experiments and throw a lot more stuff in there 
 none 	yeah 
 none 	that s great 
 none 	um  oh  the other thing that i did was  um  i compiled the h_t_k stuff for the linux boxes 
 none 	so we have this big thing that we got from i_b_m  which is a five processor machine 
 none 	really fast  but it s running linux  so  you can now run your experiments on that machine and you can run five at a time and it runs  uh  as fast as  you know  uh  five different machines 
 none 	mm hmm 
 none 	mm hmm 
 none 	so  um  i ve forgotten now what the name of that machine is but i can  
 send_email 	i  can send email  around  about  it   
 none 	yeah 
 none 	and so we ve got it   now h_t_k s compiled for both the linux and for  um  the sparcs 
 none 	um  you have to make   you have to make sure that in your dot c_s_h_r_c  um  it detects whether you re running on the linux or a   a sparc and points to the right executables 
 none 	uh  and you may not have had that in your dot c_s_h_r_c before  if you were always just running the sparc  so  um  uh  i can   i can tell you exactly what you need to do to get all of that to work 
 none 	mm hmm 
 none 	hmm  cool 
 none 	but it ll   it really increases what we can run on  so  together with the fact that we ve got these faster linux boxes and that it takes less time to do these  um  we should be able to crank through a lot more experiments 
 none 	so 
 none 	mm hmm 
 none 	hmm 
 none 	so after i did that  then what i wanted to do was try increasing the number of mixtures  just to see  um   see how   how that affects performance 
 none 	yeah 
 none 	so 
 none 	yeah  in fact  you could do something like keep exactly the same procedure and then add a fifth thing onto it that had more  yeah 
 none 	mm hmm  exactly 
 none 	right  right 
 none 	so at   at the middle o  where the arrows are showing  that s   you re adding one more mixture per state  or    
 none 	uh huh 
 none 	uh  let s see  uh 
 none 	it goes from this   uh  try to go it backwards   this   at this point it s two mixtures per state 
 none 	so this just adds one 
 none 	except that  uh  actually for the silence model  it s six mixtures per state 
 none 	mm hmm 
 none 	o_k 
 none 	uh  so it goes to two  um 
 none 	and i think what happens here is  
 none 	might be between  uh  shared  uh   shared variances or something  or  
 none 	yeah  i think that s what it is 
 none 	uh  yeah  it s  uh  
 none 	shoot  i   i   i can t remember now what happens at that first one  uh  i have to look it up and see 
 none 	oh  o_k 
 none 	um  there   because they start off with  uh  an initial model which is just this global model  and then they split it to the individuals  and so  it may be that that s what s happening here  i   i   i have to look it up and see  i   i don t exactly remember 
 none 	o_k 
 none 	o_k  alright 
 none 	so  that s it 
 none 	so what else 
 find_calendar_entry 	um  yeah   there was  a conference call   this tuesday   
 none 	um 
 none 	i don t know yet the   what happened tuesday  but the points that they were supposed to discuss is still  uh  things like the weights  uh  
 none 	oh  this is a conference call for  uh  uh  aurora participant sort of thing  i see 
 none 	for  
 none 	yeah  yeah 
 none 	mmm 
 none 	do you know who was   who was   since we weren t in on it  uh  do you know who was in from o_g_i  was   was   was hynek involved or was it sunil or    
 none 	i have no idea  mmm  i just   yeah 
 none 	oh  you don t know  o_k 
 none 	alright 
 none 	um  yeah 
 none 	so the points were the   the weights   how to weight the different error rates that are obtained from different language and   and conditions 
 none 	um  it s not clear that they will keep the same kind of weighting  right now it s a weighting on   on improvement 
 none 	mm hmm 
 none 	some people are arguing that it would be better to have weights on uh   well  to   to combine error rates before computing improvement 
 none 	uh  and the fact is that for   right now for the english  they have weights   they   they combine error rates  but for the other languages they combine improvement 
 none 	so it s not very consistent 
 none 	um  
 none 	mm hmm 
 none 	yeah  the  um  
 none 	yeah 
 none 	and so   well  this is a point 
 none 	and right now actually there is a thing also  uh  that happens with the current weight is that a very non significant improvement on the well matched case result in huge differences in   in the final number 
 none 	mm hmm 
 none 	hmm 
 none 	and so  perhaps they will change the weights to  
 none 	yeah 
 none 	how should that be done  i mean  it   it seems like there s a simple way  
 none 	mm hmm 
 none 	uh  this seems like an obvious mistake or something  th  they re  
 none 	well  i mean  the fact that it s inconsistent is an obvious mistake  but the   but  um  the other thing   i don t know i haven t thought it through  but one   one would think that each   it   it s like if you say what s the   what s the best way to do an average  an arithmetic average or a geometric average 
 none 	in 
 none 	mm hmm 
 none 	it depends what you wanna show 
 none 	mm hmm 
 none 	each   each one is gonna have a different characteristic  so  
 none 	yeah 
 none 	well  it seems like they should do  like  the percentage improvement or something  rather than the absolute improvement 
 none 	tha  that s what they do  yeah 
 none 	well  they are doing that 
 none 	no  that is relative 
 none 	but the question is  do you average the relative improvements or do you average the error rates and take the relative improvement maybe of that 
 none 	yeah 
 none 	yeah 
 none 	and the thing is it s not just a pure average because there are these weightings 
 none 	oh 
 none 	it s a weighted average 
 none 	um 
 none 	yeah  and so when you average the   the relative improvement it tends to   to give a lot of   of  um  importance to the well matched case because the baseline is already very good and  um  i  it s  
 none 	why don t they not look at improvements but just look at your av  your scores  you know  figure out how to combine the scores with a weight or whatever  and then give you a score   here s your score  and then they can do the same thing for the baseline system   and here s its score  and then you can look at  
 none 	mm hmm 
 none 	well  that s what he s seeing as one of the things they could do  it s just when you   when you get all done 
 none 	mm hmm 
 none 	yeah 
 none 	i think that they pro  i m  i   i wasn t there but i think they started off this process with the notion that you should be significantly better than the previous standard 
 none 	mm hmm 
 none 	and  um  so they said  how much is significantly better  what do you      and   and so they said  well  you know  you should have half the errors   or something   that you had before  
 none 	mm hmm  hmm 
 none 	mm hmm 
 none 	yeah 
 none 	so it s  uh 
 none 	hmm 
 none 	but it does seem like i  i  it does seem like it s more logical to combine them first and then do the  
 none 	combine error rates and then   yeah 
 none 	yeah  yeah 
 none 	well  
 none 	but there is this   this   is this still this problem of weights  when   when you combine error rate it tends to give more importance to the difficult cases  and some people think that   well  they have different  um  opinions about this 
 none 	oh  yeah 
 none 	some people think that it s more important to look at   to have ten percent imp  relative improvement on well matched case than to have fifty percent on the m  mismatched  and other people think that it s more important to improve a lot on the mismatch and  
 none 	it sounds like they don t really have a good idea about what the final application is gonna be 
 none 	so  bu  l  de  fff 
 none 	well  you know  the   the thing is that if you look at the numbers on the   on the more difficult cases  um  if you really believe that was gonna be the predominant use  none of this would be good enough  nothing anybody s   whereas you sort of with some reasonable error recovery could imagine in the better cases that these   these systems working 
 none 	mmm  yeah  mmm 
 none 	mm hmm 
 none 	yeah 
 none 	so  um  i think the hope would be that it would   uh  it would work well for the good cases and  uh  it would have reasonable   reas  soft degradation as you got to worse and worse conditions  um 
 none 	yeah  i   i guess what i m  
 none 	i mean  i   i was thinking about it in terms of  if i were building the final product and i was gonna test to see which front end i d  
 none 	i wanted to use  i would try to weight things depending on the exact environment that i was gonna be using the system in  if i  
 none 	but   but   no  well  no   well  no  i mean  it isn t the operating theater  i mean  they don  they   they don t   they don t really know  i think 
 none 	yeah 
 none 	so if   if they don t know  doesn t that suggest the way for them to go 
 none 	i mean  i th 
 none 	uh  you assume everything s equal  i mean  y  y  i mean  you  
 none 	well  i mean  i   i think one thing to do is to just not rely on a single number   to maybe have two or three numbers  you know  and   and   and say here s how much you  uh   you improve the  uh   the   the relatively clean case and here s   or   or well matched case  and here s how   here s how much you  uh  
 none 	yeah  right 
 none 	mm hmm 
 none 	so not  
 none 	so not try to combine them 
 none 	so 
 none 	yeah  uh  actually it s true  uh  i had forgotten this  uh  but  uh  well matched is not actually clean  what it is is just that  u  uh  the training and testing are similar 
 none 	yeah 
 none 	the training and testing 
 none 	mmm 
 none 	so  i guess what you would do in practice is you d try to get as many  uh  examples of similar sort of stuff as you could  and then  uh   so the argument for that being the   the   the more important thing  is that you re gonna try and do that  but you wanna see how badly it deviates from that when   when   when the  uh   it s a little different 
 none 	yeah 
 none 	so   so you should weight those other conditions v  very   you know  really small 
 none 	um 
 none 	but  
 none 	no  that s a   that s a   that s an arg  that s an ar  well  that s an argument for it  but let me give you the opposite argument  the opposite argument is you re never really gonna have a good sample of all these different things 
 none 	i mean  that s more of an information kind of thing 
 none 	uh huh 
 none 	i mean  are you gonna have w  uh  uh  examples with the windows open  half open  full open 
 none 	going seventy  sixty  fifty  forty miles an hour  on what kind of roads  with what passing you  with   uh  i mean 
 none 	mm hmm 
 none 	mm hmm 
 none 	i   i   i think that you could make the opposite argument that the well matched case is a fantasy 
 none 	mm hmm 
 none 	uh huh 
 none 	you know  so  i think the thing is is that if you look at the well matched case versus the po  you know  the   the medium and the   and the fo  and then the mismatched case  um  we re seeing really  really big differences in performance  right 
 none 	and   and y  you wouldn t like that to be the case 
 none 	you wouldn t like that as soon as you step outside  
 none 	you know  a lot of the   the cases it s   is  
 none 	well  that ll teach them to roll their window up 
 none 	i mean  in these cases  if you go from the   the  uh   i mean  i don t remember the numbers right off  but if you   if you go from the well matched case to the medium  it s not an enormous difference in the   in the   the training testing situation  and   and   and it s a really big performance drop  you know  so  um  
 none 	mm hmm 
 none 	yeah  i mean the reference one  for instance   this is back old on  uh   on italian   uh  was like six percent error for the well matched and eighteen for the medium matched and sixty for the   for highly mismatched 
 none 	uh  and  you know  with these other systems we   we helped it out quite a bit  but still there s   there s something like a factor of two or something between well matched and medium matched  and so i think that if what you re   if the goal of this is to come up with robust features  it does mean  
 none 	so you could argue  in fact  that the well matched is something you shouldn t be looking at at all  that   that the goal is to come up with features that will still give you reasonable performance  you know  with again gentle degregra  degradation  um  even though the   the testing condition is not the same as the training 
 none 	hmm 
 none 	so  you know  i   i could argue strongly that something like the medium mismatch  which is you know not compl  pathological but   i mean  what was the   the medium mismatch condition again 
 none 	um  it s   yeah  medium mismatch is everything with the far microphone  but trained on  like  low noisy condition  like low speed and   or stopped car and tested on high speed conditions  i think  like on a highway and  
 none 	so  
 none 	right  so it s still the same   same microphone in both cases  but  uh  it s   there s a mismatch between the car conditions  and that s   uh  you could argue that s a pretty realistic situation and  uh  i d almost argue for weighting that highest  but the way they have it now  it s   i guess it s   it s  
 none 	same microphone but   yeah 
 none 	yeah 
 none 	mm hmm 
 none 	they   they compute the relative improvement first and then average that with a weighting 
 none 	yeah 
 none 	and so then the   that   that makes the highly matched the really big thing 
 none 	mm hmm 
 none 	um  so  u  i  since they have these three categories  it seems like the reasonable thing to do is to go across the languages and to come up with an improvement for each of those 
 none 	mm hmm 
 none 	just say  o_k  in the   in the highly matched case this is what happens  in the   m  the  uh   this other m  medium if this happens  in the highly mismatched that happens  
 none 	mm hmm 
 none 	and  uh  you should see  uh  a gentle degradation through that 
 none 	mmm 
 none 	um 
 none 	but   i don t know 
 none 	yeah 
 none 	i think that   that  
 none 	i   i  
 none 	i gather that in these meetings it s   it s really tricky to make anything ac  make any policy change because everybody has   has  uh  their own opinion and  
 none 	mm hmm 
 none 	i don t know   yeah 
 none 	yeah 
 none 	uh  so   yeah 
 none 	yeah  but there is probably a   a big change that will be made is that the   the baseline   th  they want to have a new baseline  perhaps  which is  um  m_f_c_c but with a voice activity detector 
 none 	and apparently  uh  some people are pushing to still keep this fifty percent number  so they want to have at least fifty percent improvement on the baseline  but w  which would be a much better baseline 
 none 	mm hmm 
 none 	mm hmm 
 none 	and if we look at the result that sunil sent  just putting the v_a_d in the baseline improved  like  more than twenty percent  which would mean then   then   mean that fifty percent on this new baseline is like  well  more than sixty percent improvement on   on   o  e  e  uh  
 none 	mm hmm 
 none 	so nobody would be there  probably  right 
 none 	right now  nobody would be there  but  
 none 	good 
 none 	yeah 
 none 	work to do 
 none 	uh huh 
 none 	so whose v_a_d is   is   is this a    
 none 	uh  they didn t decide yet  i guess i  this was one point of the conference call also  but   mmm  so i don t know  um  but   yeah 
 none 	oh 
 none 	oh  i   i think th  that would be good  i mean  it s not that the design of the v_a_d isn t important  but it s just that it   it   it does seem to be i  uh  a lot of work to do a good job on   on that and as well as being a lot of work to do a good job on the feature design  so if we can cut down on that maybe we can make some progress 
 none 	yeah 
 none 	yeah 
 none 	m 
 none 	yeah 
 none 	hmm 
 none 	but i guess perhaps  
 none 	i don t know w  yeah 
 none 	uh  yeah  per  e  s  s  someone told that perhaps it s not fair to do that because the  um   to make a good v_a_d you don t have enough to   with the   the features that are   the baseline features  so   mmm  you need more features 
 none 	so you really need to put more   more in the   in   in the front end 
 none 	yeah 
 none 	so i 
 none 	um  sure  but i  bu 
 none 	s 
 none 	wait a minute  i   i m confused  wha  what do you mean 
 none 	yeah 
 none 	yeah  if i 
 none 	so y  so you m  s  yeah  but  
 none 	well  let s say for ins  see  m_f_c_c for instance doesn t have anything in it  uh  related to the pitch 
 none 	so just   just for example 
 none 	so suppose you ve   that what you really wanna do is put a good pitch detector on there and if it gets an unambiguous   if it gets an unambiguous result then you re definitely in a   in a   in a voice  in a  uh  s  region with speech 
 none 	oh  oh  i see 
 none 	mm hmm 
 none 	uh 
 none 	so there s this assumption that the v  the voice activity detector can only use the m_f_c_c 
 none 	that s not clear  but this   e 
 none 	well  for the baseline 
 none 	yeah 
 none 	so   so if you use other features then y  but it s just a question of what is your baseline 
 none 	i g  yeah 
 none 	right  what is it that you re supposed to do better than  and so having the baseline be the m_f_c_c s means that people could choose to pour their ener  their effort into trying to do a really good v_a_d or tryi 
 none 	i don t s 
 none 	but they seem like two separate issues  right  i mean  
 none 	they re sort of separate  unfortunately there s coupling between them  which is part of what i think stephane is getting to  is that you can choose your features in such a way as to improve the v_a_d 
 none 	yeah 
 none 	and you also can choose your features in such a way as to prove   improve recognition  they may not be the same thing 
 create_single_reminder 	but it seems like  you  should  do both    right 
 create_single_reminder 	you  should  do both  and   and i   i think that this still makes   i still think this makes sense as a baseline  
 none 	it s just saying  as a baseline  we know   you know  we had the m_f_c_c s before  lots of people have done voice activity detectors  you might as well pick some voice activity detector and make that the baseline  just like you picked some version of h_t_k and made that the baseline 
 none 	mmm 
 none 	mm hmm 
 none 	yeah 
 none 	right 
 none 	and then let s try and make everything better  um  and if one of the ways you make it better is by having your features be better features for the v_a_d then that s   so be it  but  uh  uh  uh  at least you have a starting point that s   um  cuz i  i  some of   the some of the people didn t have a v_a_d at all  i guess  right  and   and then they   they looked pretty bad and   and in fact what they were doing wasn t so bad at all  but  um 
 none 	mm hmm 
 none 	yeah 
 none 	mm hmm 
 none 	mm hmm 
 create_single_reminder 	yeah   it seems like  you  should  try to make your baseline as good as possible   
 none 	and if it turns out that you can t improve on that  well 
 none 	i mean  then  you know  nobody wins and you just use m_f_c_c  right 
 none 	yeah  i mean  it seems like  uh  it should include sort of the current state of the art that you want   are trying to improve  and m_f_c_c s  you know  or p_l_p or something   it seems like reasonable baseline for the features  and anybody doing this task  uh  is gonna have some sort of voice activity detection at some level  in some way  they might use the whole recognizer to do it but   rather than a separate thing  but   but they ll have it on some level 
 none 	so  um 
 none 	it seems like whatever they choose they shouldn t  you know  purposefully brain damage a part of the system to make a worse baseline  or   you know 
 none 	well  i think people just had  it wasn t that they purposely brain damaged it  i think people hadn t really thought through about the  uh   the v_a_d issue 
 none 	mmm 
 none 	mm hmm 
 none 	and   and then when the   the   the proposals actually came in and half of them had v_a_ds and half of them didn t  and the half that did did well and the half that didn t did poorly  so it s  
 none 	mm hmm 
 none 	mm hmm 
 none 	um 
 none 	uh 
 none 	yeah  so we ll see what happen with this 
 none 	and  
 none 	yeah  so what happened since  um  last week is   well  from o_g_i  these experiments on putting v_a_d on the baseline 
 none 	and these experiments also are using  uh  some kind of noise compensation  so spectral subtraction  and putting on line normalization  um  just after this  so i think spectral subtraction  l_d_a filtering  and on line normalization  so which is similar to the pro  proposal one  but with spectral subtraction in addition  and it seems that on line normalization doesn t help further when you have spectral subtraction 
 none 	um 
 find_calendar_entry 	is this related to the issue that you brought up a couple of meetings ago with the   the musical tones and    
 none 	i  
 none 	i have no idea  because the issue i brought up was with a very simple spectral subtraction approach  and the one that they use at o_g_i is one from   from the proposed   the   the   the aurora prop  uh  proposals  which might be much better 
 none 	mmm 
 none 	so  yeah  i asked sunil for more information about that  but  uh  i don t know yet 
 none 	um 
 none 	and what s happened here is that we   so we have this kind of new  um  reference system which use a nice   a   a clean downsampling upsampling  which use a new filter that s much shorter and which also cuts the frequency below sixty four hertz  which was not done on our first proposal 
 none 	right 
 none 	when you say  we have that   does sunil have it now  too  or    
 none 	i 
 none 	no  no 
 none 	o_k 
 none 	because we re still testing  so we have the result for  uh  just the features and we are currently testing with putting the neural network in the k_l_t 
 none 	o_k 
 none 	um  it seems to improve on the well matched case  um  but it s a little bit worse on the mismatch and highly mismatched  
 none 	i mean when we put the neural network 
 none 	and with the current weighting i think it s sh  it will be better because the well matched case is better 
 none 	mmm 
 none 	but how much worse   since the weighting might change   how   how much worse is it on the other conditions  when you say it s a little worse 
 none 	it s like  uh  fff  fff um  ten percent relative 
 none 	yeah 
 none 	o_k 
 none 	um 
 none 	mm hmm 
 none 	but it has the  uh   the latencies are much shorter  that s  
 none 	uh  y  w  when i say it s worse  it s not   it s when i   i   uh  compare proposal two to proposal one  so  r  uh  y  putting neural network compared to n  not having any neural network 
 none 	uh huh 
 none 	i mean  this new system is   is   is better  because it has um  this sixty four hertz cut off  uh  clean downsampling  and  um   what else 
 none 	uh  yeah  a good v_a_d  we put the good v_a_d 
 none 	so 
 none 	yeah  i don t know  i   i   j  uh  uh   pr 
 none 	but the latencies   but you ve got the latency shorter now  yeah 
 none 	latency is short   is   yeah 
 none 	isn t it
 none 	and so 
 none 	so it s better than the system that we had before 
 none 	yeah  mainly because of the sixty four hertz and the good v_a_d 
 none 	o_k 
 none 	and then i took this system and  mmm  w  uh  i p  we put the old filters also 
 none 	so we have this good system  with good v_a_d  with the short filter and with the long filter  and  um  with the short filter it s not worse  so   well  is it  
 none 	o_k  so that s   that s all fine  but what you re saying is that when you do these   so let me try to understand  when   when you do these same improvements to proposal one 
 none 	it s in  
 none 	yes  uh  
 none 	mm hmm 
 none 	that  uh  on the   i  things are somewhat better  uh  in proposal two for the well matched case and somewhat worse for the other two cases 
 none 	yeah 
 none 	so does  uh   when you say  uh   so  
 none 	the th  now that these other things are in there  is it the case maybe that the additions of proposal two over proposal one are less im  important 
 none 	yeah  probably  yeah 
 none 	i get it 
 none 	um  
 none 	so  yeah 
 none 	uh  yeah  but it s a good thing anyway to have shorter delay 
 none 	then we tried  um  to do something like proposal two but having  um  e  using also m_s_g features 
 none 	so there is this k_l_t part  which use just the standard features  and then two neura  two neural networks 
 none 	mm hmm 
 none 	right 
 none 	mm hmm 
 none 	mmm  and it doesn t seem to help 
 none 	um  however  we just have one result  which is the italian mismatch  so 
 none 	uh 
 none 	we have to wait for that to fill the whole table  but  
 none 	o_k 
 none 	there was a start of some effort on something related to voicing or something  is that    
 none 	yeah 
 none 	um  yeah  so basically we try to  uh  find good features that could be used for voicing detection  uh  but it s still  uh   on the  um   t  we   w  basically we are still playing with matlab to   to look at   at what happened  and  
 none 	oh  well  i have the picture 
 none 	what sorts of   what sorts of features are you looking at 
 none 	yeah 
 none 	we have some  
 none 	so we would be looking at  um  the variance of the spectrum of the excitation  something like this  which is   should be high for voiced sounds 
 none 	uh  um  this  this  and this 
 none 	uh  we  
 none 	wait a minute  i   what does that mean  the variance of the spectrum of excitation 
 none 	yeah  so the  
 none 	so basically the spectrum of the excitation for a purely periodic sig  signal shou  sh  e 
 none 	o_k  yeah  w  what yo  what you re calling the excitation  as i recall  is you re subtracting the   the  um   the mel   mel   mel filter  uh  spectrum from the f_f_t spectrum  right 
 none 	that s right  yeah  so  
 none 	mm hmm 
 none 	yeah  so we have the mel f  filter bank  we have the f_f_t  so we just  
 none 	so it s   it s not really an excitation  but it s something that hopefully tells you something about the excitation 
 none 	no 
 none 	yeah  that s right  um  
 none 	yeah  yeah 
 none 	yeah 
 none 	we have here some histogram  but they have a lot of overlap 
 none 	e  yeah  but it s   it s still  
 none 	yeah  so  well  for unvoiced portion we have something tha  that has a mean around o_ point three  and for voiced portion the mean is o_ point fifty nine 
 none 	but the variance seem quite high  so   mmm 
 none 	how do you know    
 none 	how did you get your voiced and unvoiced truth data 
 none 	we used  uh  timit and we used canonical mappings between the phones and th  yeah 
 none 	yeah  we  uh  use timit on this  for  
 none 	but if we look at it in one sentence  it   apparently it s good  i think  
 none 	yeah  but   yeah 
 none 	uh  so it s noisy timit  that s right  yeah 
 none 	it s noisy timit 
 none 	yeah 
 none 	it seems quite robust to noise  so when we take   we draw its parameters across time for a clean sentence and then nois  the same noisy sentence  it s very close 
 none 	mm hmm 
 none 	yeah  so there are   there is this  there could be also the  um   something like the maximum of the auto correlation function or   which  
 none 	is this a   a s  a trained system  or is it a system where you just pick some thresholds 
 none 	ho  how does it work 
 none 	right now we just are trying to find some features 
 none 	mm hmm 
 none 	and  uh   yeah  hopefully  i think what we want to have is to put these features in s  some kind of  um   well  to   to obtain a statistical model on these features and to   or just to use a neural network and hopefully these features w  would help  
 none 	because it seems like what you said about the mean of the   the voiced and the unvoiced   that seemed pretty encouraging  right 
 none 	mm hmm 
 none 	well  yeah  except the variance was big  right 
 none 	yeah 
 none 	except the variance is quite high  yeah 
 none 	well  y 
 none 	well  y  i   i don t know that i would trust that so much because you re doing these canonical mappings from timit labelings  right  so  really that s sort of a cartoon picture about what s voiced and unvoiced  so that could be giving you a lot of variance 
 none 	uh huh 
 none 	yeah 
 none 	i mean  i  it   it may be that   that you re finding something good and that the variance is sort of artificial because of how you re getting your truth 
 none 	yeah  but another way of looking at it might be that   i mean  what w  we  we are coming up with feature sets after all 
 none 	mm hmm 
 none 	so another way of looking at it is that um  the mel cepstru  mel spectrum  mel cepstrum  any of these variants  um  give you the smooth spectrum  it s the spectral envelope 
 none 	by going back to the f_f_t  you re getting something that is more like the raw data 
 none 	so the question is  what characterization   and you re playing around with this   another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you re missing that could help 
 none 	so  i mean  looking at different statistical measures of that difference  coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise  where you re really just i  i  the way i m looking at it is not so much you re trying to f  find the best   the world s best voiced unvoiced  uh  uh  classifier  but it s more that  you know  uh  uh  try some different statistical characterizations of that difference back to the raw data and   and m  maybe there s something there that the system can use 
 none 	mm hmm 
 none 	mmm 
 none 	right 
 none 	right 
 none 	yeah 
 none 	yeah  but ther  more obvious is that   yeah  the   the more obvious is that   that   well  using the   th  the f_f_t  um  you just   it gives you just information about if it s voiced or not voiced  ma  mainly  i mean  but   so 
 none 	yeah 
 none 	this is why we   we started to look by having sort of voiced phonemes and  
 none 	well  that s the rea  w  w  what i m arguing is that s 
 none 	yeah  i mean  uh  what i m arguing is that that   that s givi  you   gives you your intuition 
 none 	but in   in reality  it s   you know  there s all of this   this overlap and so forth  and   but what i m saying is that may be o_k  because what you re really getting is not actually voiced versus unvoiced  both for the fac  the reason of the overlap and   and then  uh  th  you know  structural reasons  uh  uh  like the one that chuck said  that   that in fact  well  the data itself is   that you re working with is not perfect 
 none 	mm hmm 
 none 	oh  sorry 
 none 	yeah  mm hmm 
 none 	so  what i m saying is maybe that s not a killer because you re just getting some characterization  one that s driven by your intuition about voiced unvoiced certainly  but it s just some characterization of something back in the   in the   in the almost raw data  rather than the smooth version 
 none 	mm hmm 
 none 	mm hmm 
 none 	and your intuition is driving you towards particular kinds of  uh  statistical characterizations of  um  what s missing from the spectral envelope 
 none 	mm hmm 
 none 	um  obviously you have something about the excitation  um  and what is it about the excitation  and  you know   and you re not getting the excitation anyway  you know  so   so i   i would almost take a   uh  especially if   if these trainings and so forth are faster  i would almost just take a uh  a scattershot at a few different ways of look  of characterizing that difference and  uh  you could have one of them but   and   and see  you know  which of them helps 
 none 	mm hmm 
 none 	so i  is the idea that you re going to take whatever features you develop and   and just add them onto the future vector 
 none 	o_k 
 none 	or  what s the use of the   the voiced unvoiced detector 
 none 	uh  i guess we don t know exactly yet  but  um  
 none 	yeah 
 none 	th 
 none 	it s not part of a v_a_d system that you re doing 
 none 	no 
 none 	uh  no  no  no  the idea was  i guess  to   to use them as   as features 
 none 	oh  o_k 
 none 	features  i see 
 none 	uh  
 none 	yeah  it could be  uh   it could be a neural network that does voiced and unvoiced detection  but it could be in the   also the big neural network that does phoneme classification 
 none 	mm hmm 
 none 	mm hmm 
 none 	mmm  yeah 
 none 	but each one of the mixture components   i mean  you have  uh  uh  variance only  so it s kind of like you re just multiplying together these  um  probabilities from the individual features within each mixture  so it s   so  uh  it seems l  you know  
 none 	i think it s a neat thing  uh  it seems like a good idea 
 none 	yeah 
 none 	um 
 none 	yeah  i mean  i know that  um  people doing some robustness things a ways back were   were just doing   just being gross and just throwing in the f_f_t and actually it wasn t   wasn t   wasn t so bad 
 none 	uh  so it would s  and   and you know that i  it s gotta hurt you a little bit to not have a   a spectral  uh   a s  a smooth spectral envelope  so there must be something else that you get in return for that   that  uh   uh  
 none 	mm hmm 
 none 	so 
 none 	so how does   uh  maybe i m going in too much detail  but how exactly do you make the difference between the f_f_t and the smoothed spectral envelope 
 none 	wha  wh  i  i  uh  how is that  uh    
 none 	um  we just   how did we do it up again 
 none 	uh  we distend the   we have the twenty three coefficient af  after the mel f  filter  and we extend these coefficient between the   all the frequency range 
 none 	mm hmm 
 none 	mm hmm 
 none 	and i  the interpolation i  between the point is   give for the triang  triangular filter  the value of the triangular filter and of this way we obtained this mode  this model speech 
 none 	so you essentially take the values that   th  that you get from the triangular filter and extend them to sor  sort of like a rectangle  that s at that m  value 
 none 	s 
 none 	yeah 
 none 	mm hmm  mmm yeah  it s linear 
 none 	yeah  i think we have linear interpolation  so we have   we have one point for   one energy for each filter bank  which is the energy that s centered on   on   on the triangle  
 none 	mmm 
 none 	oh 
 none 	yeah 
 none 	at the n  at the center of the filter  
 none 	so you   you end up with a vector that s the same length as the f_f_t vector  and then you just  uh  compute differences and  uh  sum the differences 
 none 	yeah  that s right 
 none 	yeah 
 none 	yeah 
 none 	i have here one example if you   if you want see something like that 
 none 	then we compute the difference  yeah  uh huh 
 none 	o_k 
 none 	so 
 none 	and i think the variance is computed only from  like  two hundred hertz to one   to fifteen hundred 
 none 	oh  o_k 
 none 	mm hmm 
 none 	two thou  two   fifteen hundred  no 
 none 	mm hmm 
 none 	because  
 none 	right 
 none 	two hundred and fifty thousand 
 none 	fifteen hundred  because   yeah 
 none 	yeah 
 none 	two thousand and fifteen hundred 
 none 	above  um   it seems that  
 none 	well  some voiced sound can have also  like  a noisy part on high frequencies  and  
 none 	yeah  no  it s   makes sense to look at low frequencies 
 none 	but   well  it s just  
 none 	so this is   uh  basically this is comparing an original version of the signal to a smoothed version of the same signal 
 none 	yeah 
 none 	right  so i  so i  i  this is  
 none 	i mean  i  you could argue about whether it should be linear interpolation or   or   or   or zeroeth order  but   but at any rate something like this is what you re feeding your recognizer  typically 
 none 	uh huh 
 none 	like which of the    
 none 	no  uh  so the mel cepstrum is the   is the   is the cepstrum of this   this  uh  spectrum or log spectrum  whatever it   you  you re subtracting in   in   in power domain or log domain 
 none 	so this is   yeah 
 none 	yeah 
 none 	right  right 
 none 	in log domain  yeah 
 none 	log domain 
 none 	o_k  so it s sort of like division  when you do the   yeah  the spectra 
 none 	yeah 
 none 	uh  yeah 
 none 	um 
 none 	it s the ratio 
 none 	yeah  but  anyway  um   and that s  
 none 	so what s th  uh  what s the intuition behind this kind of a thing  i   i don t know really know the signal processing well enough to understand what   what is that doing 
 none 	so 
 none 	yeah  what happen if   what we have   have   what we would like to have is some spectrum of the excitation signal  which is for voiced sound ideally a   a pulse train and for unvoiced it s something that s more flat 
 none 	yeah  i guess that makes sense  yeah 
 none 	uh huh 
 none 	uh huh  right 
 none 	and the way to do this is that   well  we have the   we have the f_f_t because it s computed in   in the   in the system  and we have the mel filter banks  and so if we   if we  like  remove the mel filter bank from the f_f_t  we have something that s close to the excitation signal 
 none 	mm hmm 
 none 	mm hmm 
 none 	oh 
 none 	o_k 
 none 	it s something that s like a   a  a train of p  a pulse train for voiced sound and that s   that should be flat for  
 none 	oh  o_k 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	i see 
 none 	so do you have a picture that sh    is this for a voiced segment  this picture 
 none 	so  it s   y  yeah 
 none 	yeah 
 none 	what does it look like for unvoiced 
 none 	you have several   some unvoiced 
 none 	the dif  no  unvoiced  i don t have for unvoiced  i m sorry 
 none 	oh 
 none 	yeah  so  you know  all   yeah 
 none 	but  
 none 	yeah 
 none 	yeah  this is the   between  
 none 	this is another voiced example  yeah 
 none 	no  but it s this  but between the frequency that we are considered for the excitation   for the difference and this is the difference 
 none 	oh  yeah  this is  
 none 	right 
 none 	mm hmm 
 none 	this is the difference  o_k 
 none 	yeah 
 none 	yeah 
 none 	so  of course  it s around zero  but   well  no  it is  
 none 	sure looks  
 none 	hmm 
 none 	hmm 
 none 	yeah  because we begin  uh  in fifteen point   the fifteen point 
 none 	so  does   does the periodicity of this signal say something about the   the   the pitch  o_k 
 none 	fifteen p 
 none 	so it s  
 none 	pitch 
 none 	yeah  it s the pitch  yeah  mm hmm 
 none 	yeah  that s like fundamental frequency 
 none 	mm hmm 
 none 	so  i mean  i  t  t  i mean  to first order what you d   what you re doing  
 none 	o_k  i see 
 none 	i mean  ignore all the details and all the ways which is   that these are complete lies 
 none 	mm hmm 
 none 	uh  the   the   you know  what you re doing in feature extraction for speech recognition is you have  uh  in your head a   a   a   a simplified production model for speech  in which you have a periodic or aperiodic source that s driving some filters 
 none 	yeah 
 none 	mm hmm 
 none 	this is the   the auto correlation   the r_zero energy 
 none 	do you have the mean   do you have the mean for the auto correlation    
 none 	uh  first order for speech recognition  you say  i don t care about the source   right 
 none 	for  
 none 	yeah  i have the mean 
 none 	well  i mean for the   the energy 
 none 	right  right 
 none 	and so you just want to find out what the filters are  the filters roughly act like a  um   a  uh   a  an overall resonant   you know  f  some resonances and so forth that th  that s processing excitation 
 none 	yeah  here 
 none 	they should be more close 
 none 	ah  no  this is this  more close  is this 
 none 	and this 
 none 	mm hmm  mm hmm 
 none 	yeah  so they are   this is   there is less difference 
 none 	mm hmm 
 none 	so if you look at the spectral envelope  just the very smooth properties of it  you get something closer to that 
 none 	this is less   it s less robust 
 none 	less robust  yeah 
 none 	oh  yeah 
 none 	and the notion is if you have the full spectrum  with all the little nitty gritty details  that that has the effect of both  and it would be a multiplication in   in frequency domain so that would be like an addition in log   power spectrum domain 
 none 	yeah 
 none 	mm hmm 
 none 	mm hmm  mm hmm 
 none 	and so this is saying  well  if you really do have that sort of vocal tract envelope  and you subtract that off  what you get is the excitation 
 none 	and i call that lies because you don t really have that  you just have some kind of signal processing trickery to get something that s kind of smooth 
 none 	it s not really what s happening in the vocal tract so you re not really getting the vocal excitation 
 none 	yeah  right 
 none 	that s why i was going to the   why i was referring to it in a more   a more  uh  uh  conservative way  when i was saying  well  it s   yeah  it s the excitation   but it s not really the excitation  it s whatever it is that s different between  
 none 	oh  this moved in the   yeah 
 none 	so   so  stand  standing back from that  you sort of say there s this very detailed representation 
 none 	mm hmm 
 none 	you go to a smooth representation  you go to a smooth representation cuz this typically generalizes better 
 none 	mm hmm 
 none 	um  but whenever you smooth you lose something  so the question is have you lost something you can you use 
 none 	right 
 none 	um  probably you wouldn t want to go to the extreme of just ta  saying  o_k  our feature set will be the f_f_t   cuz we really think we do gain something in robustness from going to something smoother  but maybe there s something that we missed 
 none 	mm hmm 
 none 	yeah 
 none 	so what is it  and then you go back to the intuition that  well  you don t really get the excitation  but you get something related to it 
 none 	mm hmm  mm hmm 
 none 	and it   and as you can see from those pictures  you do get something that shows some periodicity  uh  in frequency  you know  and   and   and also in time  so   so 
 none 	hmm 
 none 	that s   that s really neat 
 none 	so you don t have one for unvoiced picture 
 none 	uh  not here  no  i have s  but not here 
 none 	oh 
 none 	mm hmm 
 none 	yeah 
 none 	but presumably you ll see something that won t have this kind of  uh  uh  uh  regularity in frequency  uh  in the  
 none 	but  
 none 	yeah  well 
 none 	not here 
 none 	i would li  i would like to see those pictures  yeah 
 none 	well  so 
 none 	yeah 
 none 	i can t see you now 
 none 	yeah 
 none 	yeah 
 none 	i don t have 
 none 	mm hmm 
 none 	and so you said this is pretty   doing this kind of thing is pretty robust to noise 
 none 	it seems  yeah  um 
 none 	pfft 
 none 	huh 
 none 	oops  the mean is different with it  because the   the histogram for the   the classifica  oh 
 none 	no  no  no  but th  the kind of robustness to noise   so if   if you take this frame  uh  from the noisy utterance and the same frame from the clean utterance  
 none 	hmm 
 none 	you end up with a similar difference over here 
 none 	y  y  y  yeah  we end up with  
 none 	yeah 
 none 	o_k  cool 
 none 	i have here the same frame for the clean speech   the same cle  but they are a difference  because here the f_f_t is only with two hundred fifty six point and this is with five hundred twelve 
 none 	oh  that s clean  oh  o_k 
 none 	yeah  that s  
 none 	oh 
 none 	o_k 
 none 	yeah  this is kind of inter  interesting also because if we use the standard  uh  frame length of   of  like  twenty five milliseconds  um  what happens is that for low pitched voiced  because of the frame length  y  you don t really have   you don t clearly see this periodic structure 
 none 	mm hmm 
 none 	because of the first lobe of   of each   each of the harmonics 
 none 	so this one inclu  is a longer   ah 
 none 	so  this is like   yeah  fifty milliseconds or something like that 
 none 	fifty millis  yeah 
 none 	yeah  but it s the same frame and  
 none 	oh  it s that time frequency trade off thing  right 
 none 	yeah 
 none 	i see 
 none 	yeah 
 none 	mm hmm 
 none 	oh  oh  so this i  is this the difference here  for that 
 none 	so  yeah 
 none 	no  this is the signal  this is the signal 
 none 	i see that  oh  yeah 
 none 	the frame 
 none 	oh  that s the f  the original 
 none 	this is the fra  the original frame 
 none 	yeah  so with a short frame basically you have only two periods and it s not   not enough to   to have this kind of neat things  but  
 none 	yeah  mm hmm  yeah 
 none 	mm hmm 
 none 	and here   no  well 
 none 	yeah  so probably we ll have to use  like  long f  long frames  mm hmm 
 none 	mm hmm 
 none 	hmm 
 none 	oh  that s interesting 
 none 	mmm 
 none 	yeah  maybe 
 none 	well  i mean it looks better  but  i mean  the thing is if   if  uh   if you re actually asking   you know  if you actually j  uh  need to do   place along an f_f_t  it may be   it may be pushing things 
 none 	yeah 
 none 	and   and  uh  
 none 	would you   would you wanna do this kind of  uh  difference thing after you do spectral subtraction 
 none 	uh  maybe 
 none 	no 
 none 	maybe we can do that 
 none 	mmm 
 none 	hmm 
 none 	the spectral subtraction is being done at what level  is it being done at the level of f_f_t bins or at the level of  uh  mel spectrum or something 
 none 	um 
 none 	i guess it depends 
 none 	i mean  how are they doing it 
 none 	how they re doing it  yeah 
 none 	um 
 none 	i guess ericsson is on the  um  filter bank  no 
 none 	f_f_t  filter bank  yeah 
 none 	it s on the filter bank  so  so  yeah  probably  
 none 	so in that case  it might not make much difference at all 
 none 	i  i  it   yeah 
 none 	seems like you d wanna do it on the f_f_t bins 
 none 	maybe  i mean  certainly it d be better 
 none 	i  i mean  if you were gonna   uh  for   for this purpose  that is 
 none 	mm hmm 
 none 	yeah 
 none 	yeah 
 none 	mm hmm 
 none 	o_k 
 none 	mmm 
 none 	what else 
 none 	uh  yeah  that s all 
 none 	so we ll perhaps try to convince o_g_i people to use the new   the new filters and   yeah 
 none 	o_k 
 none 	uh  has   has anything happened yet on this business of having some sort of standard  uh  source  or    
 none 	uh  not yet but i wi  i will call them and   now they are   i think they have more time because they have this   well  eurospeech deadline is over and  
 none 	o_k 
 find_calendar_entry 	when is the  next  um  aurora deadline   
 none 	it s  um  in  june  
 none 	june 
 none 	yeah 
 none 	early june  late june  middle june 
 none 	i don t know w 
 none 	hmm 
 none 	hmm 
 none 	o_k 
 none 	um  and he s been doing all the talking but   but these   he s   he s  uh  
 none 	yeah 
 none 	this is   this by the way a bad thing  we re trying to get  um  m  more female voices in this record as well  so 
 none 	make sur  make sure carmen talks as well 
 none 	uh  but has he pretty much been talking about what you re doing also  and    
 none 	oh  i   i am doing this 
 none 	yeah  yeah  i don t know  i m sorry  but
 none 	yes 
 none 	i think that for the recognizer for the meeting recorder that it s better that i don t speak 
 none 	yeah  well  you know  uh  we ll get   we ll get to  uh  spanish voices sometime  and we do   we want to recognize  uh  you too 
 none 	because  
 none 	after the   after  uh  the result for the t_i digits on the meeting record there will be foreigns people 
 none 	y 
 none 	yeah  but  
 none 	oh  no  we like   we   we re   we re   w  we are   we re in the  uh 
 none 	bourlard hermansky morgan  uh  frame of mind  yeah  we like high error rates  it s   that way there s lots of work to do  so it s  
 none 	yeah 
 none 	uh  anything to talk about 
 none 	n  um  not  not  not much is new  so when i talked about what i m planning to do last time 
 none 	i said i was  um  going to use avendano s method of  um  using a transformation  um  to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation 
 none 	he has a trick for doing that involving viewing the d_f_t as a matrix  um  but  uh  um  i decided not to do that after all because
 none 	i   i realized to use it i d need to have these short analysis frames get plugged directly into the feature computation somehow and right now i think our feature computation is set to up to  um  take  um  audio as input  in general 
 none 	mm hmm 
 none 	so i decided that i   i ll do the reverberation removal on the long analysis windows and then just re synthesize audio and then send that 
 none 	this is in order to use the s_r_i system or something  right 
 none 	um  or   or even if i m using our system  i was thinking it might be easier to just re synthesize the audio  because then i could just feacalc as is and i wouldn t have to change the code 
 none 	yeah 
 none 	oh  o_k 
 none 	yeah  i mean  it s   um  certainly in a short   short term this just sounds easier 
 none 	uh huh 
 none 	yeah  i mean  longer term if it s   if it turns out to be useful  one   one might want to do something else  but  
 none 	right  that s true 
 none 	uh  uh  i mean  in   in other words  you   you may be putting other kinds of errors in from the re synthesis process 
 none 	but   e  u 
 none 	from the re synthesis  um  o_  o_k  i don t know anything about re synthesis  uh  how likely do you think that is 
 none 	yeah 
 none 	uh  it depends what you   what you do 
 none 	i mean  it s   it s   it s  uh  um  
 none 	don t know  but anyway it sounds like a reasonable way to go for a   for an initial thing  and we can look at   at exactly what you end up doing and   and then figure out if there s some   something that could be   be hurt by the end part of the process 
 none 	o_k 
 none 	o_k 
 none 	so that s  
 none 	that   yeah  e  that s it  that s it  uh huh 
 none 	that was it  huh  o_k 
 none 	o_k 
 none 	um  anything to add 
 none 	um 
 search 	well  i ve been continuing reading  i went off on a little tangent this past week  um  looking at  uh  uh   modulation s  spectrum stuff   um  and   and learning a bit about what   what  um   what it is  and  uh  the importance of it in speech recognition   and i found some   some  uh  neat papers  um  historical papers from  um   kanedera  hermansky  and arai   
 none 	and they   they did a lot of experiments where th  where  um  they take speech and  um  e  they modify the  uh   they   they   they measure the relative importance of having different  um  portions of the modulation spectrum intact 
 none 	yeah 
 none 	and they find that the   the spectrum between one and sixteen hertz in the modulation is  uh   is im  important for speech recognition 
 none 	yeah 
 none 	um 
 none 	sure  i mean  this sort of goes back to earlier stuff by drullman 
 none 	yeah 
 none 	and   and  uh  the   the m_s_g features were sort of built up with this notion   but  i guess  i thought you had brought this up in the context of  um  targets somehow 
 none 	right 
 none 	right  um  
 none 	but i  m  i  it s not   i mean  they re sort of not in the same kind of category as  say  a phonetic target or a syllabic target or a   or a feature or something 
 none 	mmm 
 none 	mm hmm 
 none 	um  i was thinking more like using them as   as the inputs to   to the detectors 
 none 	oh  i see 
 none 	yeah 
 none 	well  that s sort of what m_s_g does 
 none 	yeah 
 none 	right  so it s  
 none 	mm hmm 
 none 	but   but  uh  
 none 	s 
 none 	yeah 
 none 	yeah 
 none 	anyway  we ll talk more about it later  yeah 
 none 	o_k  we can talk more about it later 
 none 	yeah  yeah 
 none 	yeah 
 none 	so maybe  le  let s do digits 
 none 	should we do digits 
 none 	let you   you start 
 none 	oh  o_k 
 none 	reading transcript l_ dash five six 
 none 	one seven six eight  six six nine one  seven nine two one 
 none 	two o_ three  five o_  o_ one two five 
 none 	four zero five six  four  three three four 
 none 	nine two nine zero  three one one four  eight six two nine 
 none 	four one three  six two five  six six nine zero 
 none 	four three  six seven  six one  five two  nine eight 
 none 	seven six  three three  three seven  seven eight  two three 
 none 	eight four two  six one  four six two seven 
 none 	transcript l_ fifty five  or transcript l_ five five 
 none 	six eight seven  seven one five  zero seven five 
 none 	eight nine six zero  three  eight six five 
 none 	five six six  two zero  zero two nine six 
 none 	eight four two eight  nine  one six four 
 none 	one six eight  six two  four zero one three 
 none 	three one  two six  six one  nine nine  six zero 
 none 	eight three seven zero  eight  zero eight zero 
 none 	six two three six  four zero zero six  nine seven four three 
 none 	transcript l_ dash four nine 
 none 	eight eight four  two five nine  seven four five zero 
 none 	seven eight seven  zero one zero  six one five eight 
 none 	seven four  two two  five zero  three nine  seven zero 
 none 	eight five eight  zero three  four seven one four 
 none 	zero six zero  four four  two  zero zero one 
 none 	two two nine three  three  one two eight 
 none 	eight  five five eight  five five  eight six nine  one 
 none 	three five eight  two nine  four o_ one seven 
 none 	transcript l_ fifty 
 none 	um  nine o_ six seven  three  nine three three 
 none 	o_  eight three o_  o_ eight  three four eight  one 
 none 	two one three  six five  three one five nine 
 none 	four o_  eight four  three o_  five two  one one 
 none 	nine two four  five eight four  five five zero four 
 none 	two two  two six  one six  eight one  five five 
 none 	seven o_ seven  o_ eight seven  eight four o_ two eight o_ three  one six o_  five o_  seven four 
 none 	transcript l_ dash fifty three 
 none 	five nine  five four  eight eight  three nine  one four 
 none 	eight six zero  three one zero  nine seven five three 
 none 	five five  five two  nine nine  three three  six five 
 none 	three three seven  zero seven  four seven one zero 
 none 	six four one eight  three  one six six 
 none 	five seven six  eight nine five  nine one six 
 none 	two two  eight three  three zero  five five  nine five 
 none 	zero five nine  six one five  zero two five 
 none 	transcript l_ dash f  fifty four 
 none 	one four three one seven seven one o_ three two 
 none 	nine eight two four eight eight eight one two 
 none 	one three one  zero five seven  six eight one two 
 none 	six two eight eight  seven five  nine one  two zero 
 none 	five two seven two  eight  six one seven 
 none 	four nine eight  o_ o_ o_  seven zero nine 
 none 	eight six two  four five  eight eight  nine two 
 none 	two two one  one nine  six seven eight three 
 none 	right 
 none 	o_k  so uh  he s not here  so you get to  
 none 	so 
 none 	yeah  i will try to explain the thing that i did this   this week   during this week 
 none 	yeah 
 none 	well eh you know that i work   i begin to work with a new feature to detect voice unvoice 
 none 	mm hmm 
 none 	what i trying two m_l_p to   to the   with this new feature and the fifteen feature uh from the eh bus  base system
 none 	the   the mel cepstrum 
 none 	no  satly the mes  the mel cepstrum  the new base system   the new base system 
 none 	oh the   o_k  the aurora system 
 none 	yeah  we   yeah the aurora system with the new filter 
 none 	o_k 
 none 	v_a_d or something like that  and i m trying two m_l_p  one one that only have t  three output  voice  unvoice  and silence  and other one that have fifty six output 
 none 	mm hmm 
 none 	the probabilities of the allophone   and
 none 	i tried to do some experiment of recognition with that and only have result with   with the m_l_p with the three output 
 none 	and i put together the fifteen features and the three m_l_p output 
 none 	and  well  the result are li  a little bit better  but more or less similar 
 none 	uh  i   i m   i m slightly confused  what   what feeds the uh   the three output net 
 none 	hmm 
 none 	voice  unvoice  and si 
 none 	no no  what feeds it  what features does it see 
 none 	the feature   the input 
 none 	the inputs are the fifteen   the fifteen uh bases feature  the   with the new code 
 none 	uh huh 
 none 	and the other three features are r_  the variance of the difference between the two spectrum  the variance of the auto correlation function  except the   the first point  because half the height value is r_zero and also r_zero  the first coefficient of the auto correlation function  that is like the energy with these three feature  also these three feature 
 none 	uh huh 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	right 
 none 	you wouldn t do like r_one over r_zero or something like that 
 none 	i mean usually for voiced unvoiced you d do   yeah  you d do something   you d do energy but then you have something like spectral slope  which is you get like r_one ov  over r_zero or something like that 
 none 	yeah 
 none 	uh yeah 
 none 	what are the r_ s 
 none 	i m sorry i missed it 
 none 	r_ correlations 
 none 	no  r_ c  no 
 none 	oh 
 none 	auto correlation  yes  yes  the variance of the auto correlation function that uses that
 none 	ye 
 none 	well that s the variance  but if you just say  what is    i mean  to first order  um yeah one of the differences between voiced  unvoiced and silence is energy 
 none 	another one is   but the other one is the spectral shape 
 none 	yeah  i  i ll  
 none 	the spectral shape  yeah 
 none 	yeah  and so r_one over r_zero is what you typically use for that 
 none 	no  i don t use that   i can t use  
 none 	no  i m saying that s what people us  typically use 
 none 	mmm 
 none 	see  because it   because this is   this is just like a single number to tell you um
 none 	 does the spectrum look like that or does it look like that   
 none 	mm hmm 
 none 	oh  r_   r_zero 
 none 	right 
 none 	mm hmm 
 none 	so if it s   if it s um   if it s low energy uh but the   but the spectrum looks like that or like that  it s probably silence 
 none 	mm hmm 
 none 	uh but if it s low energy and the spectrum looks like that  it s probably unvoiced 
 none 	yeah 
 none 	so if you just   if you just had to pick two features to determine voiced unvoiced  you d pick something about the spectrum like uh r_one over r_zero  um and r_zero or i  i  you know you d have some other energy measure and like in the old days people did like uh zero crossing counts 
 none 	mm hmm  o_k 
 none 	yeah  yeah 
 none 	right  s  yeah  um 
 none 	well  i can also th  use this 
 none 	bec  because the result are a little bit better but we have in a point that everything is more or less the similar   more or less similar 
 none 	yeah 
 none 	but um
 none 	it s not quite better 
 none 	right  but it seemed to me that what you were what you were getting at before was that there is something about the difference between the original signal or the original f_f_t and with the filter which is what   and the variance was one take uh on it 
 none 	yeah  i used this too 
 none 	right  but it   it could be something else  suppose you didn t have anything like that  then in that case  if you have two nets 
 none 	alright  and this one has three outputs  and this one has f  whatever  fifty six  or something  if you were to sum up the probabilities for the voiced and for the unvoiced and for the silence here  we ve found in the past you ll do better at voiced unvoiced silence than you do with this one 
 none 	mm hmm 
 none 	mm hmm 
 none 	so just having the three output thing doesn t   doesn t really buy you anything 
 none 	yeah 
 none 	the issue is what you feed it 
 none 	yeah  i have   yeah 
 none 	so uh
 none 	so you re saying take the features that go into the voiced unvoiced  silence net and feed those into the other one  as additional inputs  rather than having a separate  
 none 	no  
 none 	w 
 none 	w  well that s another way  that wasn t what i was saying but yeah that s certainly another thing to do  no i was just trying to say if you b  if you bring this into the picture over this  what more does it buy you 
 none 	yeah 
 none 	mmm 
 none 	and what i was saying is that the only thing i think that it buys you is um based on whether you feed it something different 
 none 	and something different in some fundamental way  and so the kind of thing that   that she was talking about before  was looking at something uh ab  um   something uh about the difference between the   the uh um log f_f_t uh log power uh and the log magnitude uh f_f_  spectrum uh and the um uh filter bank 
 none 	yeah 
 none 	and so the filter bank is chosen in fact to sort of integrate out the effects of pitch and she s saying you know trying   so the particular measure that she chose was the variance of this m  of this difference  but that might not be the right number 
 none 	mm hmm 
 none 	maybe 
 none 	right  i mean maybe there s something about the variance that s   that s not enough or maybe there s something else that   that one could use  but
 create_single_reminder 	i think that  for me  the thing that   that struck me was that uh you wanna get something back here  so here s   here s an idea   uh what about it  you   skip all the   all the really clever things  and just fed the log magnitude spectrum into this   
 none 	ah   i m sorry 
 none 	this is f 
 none 	you have the log magnitude spectrum  and you were looking at that and the difference between the filter bank and   and c  c  computing the variance 
 none 	yeah  mm hmm 
 none 	mm hmm 
 none 	that s a clever thing to do  what if you stopped being clever 
 none 	mm hmm 
 none 	and you just took this thing in here because it s a neural net and neural nets are wonderful and figure out what they can   what they most need from things  and
 none 	yeah 
 none 	i mean that s what they re good at 
 none 	so i mean you re   you re   you re trying to be clever and say what s the statistic that should   we should get about this difference but uh in fact  you know maybe just feeding this in or   or feeding both of them in you know  another way  saying let it figure out what s the   what is the interaction  especially if you do this over multiple frames 
 none 	hmm 
 none 	mm hmm 
 none 	then you have this over time  and   and both kinds of measures and uh you might get uh something better 
 none 	mm hmm 
 none 	um 
 create_single_reminder 	so   so  don t uh   don t do the division  but let the net have everything   
 none 	that s another thing you could do yeah  yeah 
 none 	yeah 
 none 	um 
 none 	i mean  it seems to me  if you have exactly the right thing then it s better to do it without the net because otherwise you re asking the net to learn this   you know  say if you wanted to learn how to do multiplication 
 none 	mm hmm 
 none 	i mean you could feed it a bunch of s  you could feed two numbers that you wanted to multiply into a net and have a bunch of nonlinearities in the middle and train it to get the product of the output and it would work 
 none 	but  it s kind of crazy  cuz we know how to multiply and you   you d be you know much lower error usually if you just multiplied it out 
 none 	but suppose you don t really know what the right thing is  and that s what these sort of dumb machine learning methods are good at  so 
 none 	um  anyway  it s just a thought 
 none 	how long does it take  carmen  to train up one of these nets 
 none 	oh  not too much 
 none 	yeah 
 none 	mmm  one day or less 
 none 	hmm 
 none 	yeah  it s probably worth it 
 none 	what are   what are your f  uh frame error rates for   for this 
 none 	eh fifty f  six uh no  the frame error rate  fifty six i think 
 none 	o 
 none 	is that   maybe that s accuracy 
 none 	percent 
 none 	the accuracy 
 none 	fif  fifty six percent accurate for v  voice unvoice
 none 	mm hmm 
 none 	no for  yes f 
 none 	i don t remember for voice unvoice  maybe for the other one  for voiced  i don t reme 
 none 	oh  o_k 
 none 	yeah  voiced unvoiced hopefully would be a lot better 
 none 	o_k 
 none 	should be in nineties somewhere 
 none 	better  maybe for voice unvoice  this is for the other one  i should  
 none 	right 
 none 	i can t show that 
 none 	o_k 
 none 	but i think that fifty five was for the   when the output are the fifty six phone 
 none 	mm hmm 
 none 	that i look in the   with the other   nnn the other m_l_p that we have are more or less the same number 
 none 	silence will be better but more or less the same 
 none 	i think at the frame level for fifty six that was the kind of number we were getting for   for uh um reduced band width uh stuff 
 none 	i think that   i   i   i think that for the other one  for the three output  is sixty  sixty two  sixty  three more or less  it s  
 none 	mm hmm 
 none 	that s all 
 none 	yeah 
 none 	that s pretty bad 
 none 	yeah  because it s noise also 
 none 	aha 
 none 	oh yeah 
 none 	and we have 
 none 	aha 
 none 	yeah  yeah  o_k 
 none 	i know 
 none 	but even i  in  
 none 	oh yeah  in training  still 
 none 	uh 
 create_single_reminder 	well actually  so  this is a test that you should do then   
 none 	um  if you re getting fifty six percent over here  uh that s in noise also  right 
 none 	yeah  yeah  yeah 
 none 	oh o_k 
 create_single_reminder 	if you re getting fifty six here  try adding together the probabilities of all of the voiced phones here and all of the unvoiced phones and see what you get then   
 none 	will be  
 none 	yeah 
 none 	i bet you get better than sixty  three 
 none 	well i don t know  but  
 none 	i th  i   i think that we   i have the result more or less  maybe  i don t know 
 none 	i don t   i m not sure but
 none 	i remember  that i can t show that 
 none 	o_k  but that s a  
 create_single_reminder 	that is a   a good check point  you should do that anyway   o_k  
 none 	yeah 
 none 	given this   this uh regular old net that s just for choosing for other purposes  uh add up the probabilities of the different subclasses and see   see how well you do 
 none 	uh and that   you know anything that you do over here should be at least as good as that 
 none 	mm hmm 
 none 	o_k 
 none 	i will do that 
 none 	the targets for the neural net  uh  they come from forced alignments 
 none 	but  
 none 	uh  no 
 none 	timit canonical ma  mappings 
 none 	timit 
 none 	ah 
 none 	oh  so  this is trained on timit 
 none 	o_k 
 none 	yeah 
 none 	yeah  noisy timit 
 none 	o_k 
 none 	yeah this for timit 
 none 	but noisy timit 
 none 	right 
 none 	noisy timit  we have noisy timit with the noise of the   the
 none 	t_i digits  and now we have another noisy timit also with the noise of uh italian database 
 none 	i see 
 none 	yeah 
 none 	well there s gonna be   it looks like there s gonna be a noisy uh   some large vocabulary noisy stuff too  somebody s preparing 
 none 	really 
 none 	yeah 
 search 	i forget what it ll be  resource management  wall street journal  something  some   some read task actually  that they re   preparing 
 none 	hmm 
 none 	for what  
 none 	for aurora 
 none 	yeah 
 none 	oh 
 none 	yeah  so the uh  
 none 	uh  the issue is whether people make a decision now based on what they ve already seen  or they make it later  and one of the arguments for making it later is let s make sure that whatever techniques that we re using work for something more than   than connected digits 
 none 	hmm 
 none 	so 
 find_calendar_entry 	when are they planning  
 find_calendar_entry 	when would they do that 
 none 	mmm  i think late   uh i think in the summer sometime 
 none 	hmm 
 none 	so 
 none 	o_k  thanks 
 none 	this is the work that i did during this date and also mmm
 none 	uh huh 
 none 	i   h  hynek last week say that if i have time i can to begin to   to study well seriously the france telecom proposal to look at the code and something like that to know exactly what they are doing because maybe that we can have some ideas but not only to read the proposal  look insi  look i  carefully what they are doing with the program  and i begin to   to work also in that 
 none 	mm hmm 
 none 	mm hmm 
 none 	but the first thing that i don t understand is that they are using r_  the uh log energy that this quite   i don t know why they have some constant in the expression of the lower energy  i don t know what that means 
 none 	they have a constant in there  you said 
 none 	yeah 
 none 	oh  at the front it says uh  log energy is equal to the rounded version of sixteen over the log of two 
 none 	this  
 none 	yeah 
 none 	uh  uh times the   well  this is natural log  and maybe it has something to do with the fact that this is  
 none 	then maybe i can understand 
 none 	is that some kind of base conversion  or    
 none 	i   i have no idea 
 none 	yeah  that s what i was thinking  but   but um  then there s the sixty four 
 none 	uh 
 none 	i don t know 
 none 	because maybe they re   the threshold that they are using on the basis of this value   i don t know exactly  because well th  i thought maybe they have a meaning  but i don t know what is the meaning of take exactly this value 
 none 	experimental results 
 none 	mc  mcdonald s constant 
 none 	yeah  it s pretty funny looking 
 none 	so they re taking the number inside the log and raising it to sixteen over log base two 
 none 	i don t know 
 none 	yeah  i   um
 none 	right 
 none 	sixteen over
 none 	does it have to do with those sixty fours  or    
 none 	two 
 none 	um 
 none 	if we ignore the sixteen  the natural log of t  one over the natural log of two times the natu 
 none 	i don t know 
 none 	hmm 
 none 	well   maybe somebody ll think of something  but this is uh  
 none 	it may just be that they   they want to have   for very small energies  they want to have some kind of a  
 none 	yeah  the e 
 none 	the effect i don t  
 none 	i can understand the effect of this  no  because it s to   to do something like that 
 none 	no 
 none 	well  it says  since you re taking a natural log  it says that when   when you get down to essentially zero energy  this is gonna be the natural log of one  which is zero 
 none 	mm hmm 
 none 	so it ll go down to uh to the natural log being  
 none 	so the lowest value for this would be zero  so y  you re restricted to being positive 
 none 	and this sort of smooths it for very small energies 
 none 	uh  why they chose sixty  four and something else  that was probably just experimental 
 none 	yeah 
 none 	and the   the   the constant in front of it  i have no idea  um
 create_single_reminder 	well    i   i  will look to  try if i move this parameter in their code what happens   maybe everything is  
 none 	uh  
 none 	maybe they tres hole are on basis of this 
 none 	i mean   it   they   they probably have some fi  particular s  fixed point arithmetic that they re using  and then it just  
 none 	i don t know 
 none 	yeah  i was just gonna say maybe it has something to do with hardware  something they were doing 
 none 	yeah 
 none 	yeah 
 none 	i mean that   they re s  probably working with fixed point or integer or something  i think you re supposed to on this stuff anyway  and   and so maybe that puts it in the right realm somewhere 
 none 	well it just  yeah  puts it in the right range  or  
 none 	yeah 
 none 	i think  given at the level you re doing things in floating point on the computer  i don t think it matters  would be my guess  but 
 none 	mm hmm 
 none 	i   this more or less anything
 none 	yeah 
 find_calendar_entry 	o_k  and wh  when did  stephane   take off    he took off  
 find_calendar_entry 	i think that  stephane  will  arrive   today or tomorrow   
 none 	oh  he was gone these first few days  and then he s here for a couple days before he goes to salt lake city  o_k 
 none 	mm hmm 
 none 	he s   i think that he is in las vegas or something like that 
 none 	yeah 
 none 	yeah 
 find_calendar_entry 	so  he s   he s   going to i_cassp  which is good    i   i don t know if there are many people who are  going to i_cassp  so   so i thought  make sure somebody go  
 none 	yeah 
 none 	yeah 
 none 	do   have  
 none 	have people sort of stopped going to i_cassp in recent years 
 none 	um  people are less consistent about going to i_cassp and i think it s still   it s still a reasonable forum for students to   to present things 
 none 	uh  it s  
 none 	i think for engineering students of any kind  i think it s   it s if you haven t been there much  it s good to go to  uh to get a feel for things  a range of things  not just speech  uh 
 none 	hmm 
 none 	but i think for   for sort of dyed in the wool speech people  um i think that i_c_s_l_p and eurospeech are much more targeted 
 none 	mm hmm 
 none 	uh  and then there s these other meetings  like h_l_t and   and uh
 none 	mmm 
 none 	a_s_r_u   so there s   there s actually plenty of meetings that are really relevant to   to uh computational uh speech processing of one sort or another 
 none 	mm hmm 
 none 	um 
 none 	so  i mean  i mostly just ignored it because i was too busy and didn t get to it 
 none 	so uh
 find_calendar_entry 	wanna talk a little bit about what  we  were talking about  this morning    just briefly  or
 none 	oh  um uh
 none 	or anything else 
 none 	yeah  so  i   i guess some of the progress  i   i ve been getting a   getting my committee members for the quals 
 none 	and um so far i have morgan and hynek 
 none 	mike jordan  and i asked john ohala and he agreed 
 none 	cool 
 none 	yeah  yeah 
 send_email 	so  i m   i   i  just need to ask um  malek   
 none 	one more 
 none 	um 
 none 	tsk 
 none 	then uh i talked a little bit about um continuing with these dynamic ev  um acoustic events  and um we re   we re   we re thinking about a way to test the completeness of a   a set of um dynamic uh events 
 none 	uh  completeness in the   in the sense that um if we   if we pick these x_ number of acoustic events  do they provide sufficient coverage for the phones that we re trying to recognize or   or the f  the words that we re gonna try to recognize later on 
 none 	and so morgan and i were uh discussing um s  uh s  a form of a cheating experiment where we get   um we have uh um a chosen set of features  or acoustic events  and we train up a hybrid um system to do phone recognition on timit 
 none 	so i  i  the idea is if we get good phone recognition results  using um these set of acoustic events  then um that   that says that these acoustic events are g  sufficient to cover a set of phones  at least found in timit 
 none 	um so i  it would be a   a measure of
 none 	 are we on the right track with   with the   the choices of our acoustic events  
 none 	um 
 none 	so that s going on  and also  just uh working on my uh final project for jordan s class  uh which is  
 none 	actually  let me   hold that thought  let me back up while we re still on it  the   the other thing i was suggesting  though  is that given that you re talking about binary features  uh  maybe the first thing to do is just to count and uh count co occurrences and get probabilities for a discrete h_m_m cuz that d be pretty simple because it s just   say  if you had ten   ten events  uh that you were counting  uh each frame would only have a thousand possible values for these ten bits  and uh so you could make a table that would   say  if you had thirty nine phone categories  that would be a thousand by thirty nine  and just count the co occurrences and divide them by the   the uh   uh uh occ  uh count the co occurrences between the event and the phone and divide them by the number of occurrences of the phone  and that would give you the likelihood of the   of the event given the phone  and um then just use that in a very simple h_m_m and uh you could uh do phone recognition then and uh wouldn t have any of the issues of the uh training of the net or   i mean  it d be on the simple side  but uh um
 none 	yeah 
 none 	o_k  sure 
 none 	mm hmm 
 none 	you know  if   uh uh the example i was giving was that if   if you had um onset of voicing and   and end of voicing as being two kinds of events  then if you had those a  all marked correctly  and you counted co occurrences  you should get it completely right 
 none 	mm hmm 
 none 	so  um  
 none 	but you d get all the other distinctions  you know  randomly wrong  i mean there d be nothing to tell you that 
 none 	so um uh
 none 	if you just do this by counting  then you should be able to find out in a pretty straightforward way whether you have a sufficient uh set of events to   to do the kind of level of   of uh classification of phones that you d like 
 none 	so that was   that was the idea  and then the other thing that we were discussing was   was um
 none 	o_k  how do you get the   your training data 
 none 	mm hmm 
 none 	cuz uh the switchboard transcription project uh uh you know was half a dozen people  or so working off and on over a couple years  and uh similar   similar amount of data to what you re talking about with timit training  so  it seems to me that the only reasonable starting point is uh to automatically translate the uh current timit markings into the markings you want 
 none 	and uh it won t have the kind of characteristic that you d like  of catching funny kind of things that maybe aren t there from these automatic markings  but   but uh it s uh  
 none 	mm hmm 
 none 	it s probably a good place to start 
 none 	yeah 
 none 	yeah 
 none 	yeah and a short   short amount of time  just to   again  just to see if that information is sufficient to uh determine the phones 
 none 	mm hmm 
 none 	hmm 
 none 	so 
 none 	yeah  you could even then   to   to get an idea about how different it is  you could maybe take some subset and you know  go through a few sentences  mark them by hand and then see how different it is from you know  the canonical ones  just to get an idea   a rough idea of h  if it really even makes a difference 
 none 	right 
 none 	you can get a little feeling for it that way  yeah that is probably right 
 none 	yeah 
 none 	i mean uh my   my guess would be that this is   since timit s read speech that this would be less of a big deal  if you went and looked at spontaneous speech it d be more   more of one 
 none 	mm hmm 
 none 	right 
 none 	right 
 none 	and the other thing would be  say  if you had these ten events  you d wanna see  well what if you took two events or four events or ten events or t  and you know  and   and hopefully there should be some point at which having more information doesn t tell you really all that much more about what the phones are 
 none 	mm hmm 
 none 	you could define other events as being sequences of these events too 
 none 	uh  you could  but the thing is  what he s talking about here is a uh   a translation to a per frame feature vector 
 none 	so there s no sequence in that  i think  i think it s just a  
 none 	unless you did like a second pass over it or something after you ve got your  
 none 	yeah  but we re just talking about something simple here  yeah  to see if  
 none 	yeah  yeah  yeah 
 none 	yeah 
 none 	i m adding complexity 
 none 	yeah  just   you know  the idea is with a   with a very simple statistical structure  could you   could you uh at least verify that you ve chosen features that are sufficient 
 none 	yeah 
 none 	o_k  and you were saying something   starting to say something else about your   your class project  or    
 none 	oh 
 none 	yeah th  um 
 none 	yeah 
 none 	so for my class project i m um
 none 	i m tinkering with uh support vector machines  something that we learned in class  and uh um basically just another method for doing classification 
 none 	and so i m gonna apply that to um compare it with the results by um king and taylor who did um these um using recurrent neural nets  they recognized um a set of phonological features um and made a mapping from the m_f_c_c s to these phonological features  so i m gonna do a similar thing with   with support vector machines and see if  
 search 	so  what s the advantage of support vector machines    what  
 none 	um  so  support vector machines are   are good with dealing with a less amount of data and um so if you   if you give it less data it still does a reasonable job in learning the   the patterns 
 none 	hmm 
 none 	hmm 
 none 	um and um
 none 	i guess it   yeah  they re sort of succinct  and   and they uh
 none 	yeah 
 none 	does there some kind of a distance metric that they use or how do they   for cla  what do they do for classification 
 none 	um  right  so  the   the simple idea behind a support vector machine is um  you have   you have this feature space  right  and then it finds the optimal separating plane  um between these two different um classes  and um and so um  what it   i  at the end of the day  what it actually does is it picks those examples of the features that are closest to the separating boundary  and remembers those and   and uses them to recreate the boundary for the test set 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	so  given these um these features  or   or these   these examples  um  critical examples  which they call support f  support vectors  then um given a new example  if the new example falls um away from the boundary in one direction then it s classified as being a part of this particular class and otherwise it s the other class 
 none 	oh 
 none 	so why save the examples  why not just save what the boundary itself is 
 none 	mm hmm 
 none 	um  hmm  let s see 
 none 	uh 
 none 	yeah  that s a good question  i   yeah 
 none 	that s another way of doing it 
 none 	mmm 
 none 	right  so   so it   i mean i   i guess it s  
 none 	sort of an equivalent 
 none 	you know  it   it goes back to nearest neighbor sort of thing  right  um  i  i  if   is it eh w 
 none 	mm hmm 
 none 	when is nearest neighbor good  well  nearest neighbor good   is good if you have lots and lots of examples 
 none 	um but of course if you have lots and lots of examples  then it can take a while to   to use nearest neighbor  there s lots of look ups 
 none 	so a long time ago people talked about things where you would have uh a condensed nearest neighbor  where you would   you would   you would pick out uh some representative examples which would uh be sufficient to represent   to   to correctly classify everything that came in 
 none 	oh 
 none 	mm hmm 
 none 	i   i think s  i think support vector stuff sort of goes back to   to that kind of thing 
 none 	i see 
 none 	um 
 none 	so rather than doing nearest neighbor where you compare to every single one  you just pick a few critical ones  and  
 none 	yeah 
 none 	hmm 
 none 	and th  the
 none 	you know  um neural net approach uh or gaussian mixtures for that matter are sort of   fairly brute force kinds of things  where you sort of   you predefine that there is this big bunch of parameters and then you   you place them as you best can to define the boundaries  and in fact  as you know  these things do take a lot of parameters and   and uh if you have uh only a modest amount of data  you have trouble uh learning them 
 none 	um  so i   i guess the idea to this is that it   it is reputed to uh be somewhat better in that regard 
 none 	mm hmm 
 none 	right  i  it can be a   a reduced um parameterization of   of the   the model by just keeping certain selected examples 
 none 	hmm 
 none 	yeah 
 none 	so 
 none 	but i don t know if people have done sort of careful comparisons of this on large tasks or anything 
 none 	maybe   maybe they have 
 none 	i don t know 
 none 	yeah  i don t know either 
 none 	yeah 
 none 	s  do you get some kind of number between zero and one at the output 
 none 	actually you don t get a   you don t get a nice number between zero and one  you get   you get either a zero or a one 
 none 	um  uh there are   there are pap 
 none 	well  basically  it s   it s um you   you get a distance measure at the end of the day  and then that distance measure is   is um   is translated to a zero or one 
 none 	um 
 none 	but that s looking at it for   for classification   for binary classification  right 
 none 	that s for classification  right 
 none 	and you get that for each class  you get a zero or a one 
 none 	right 
 none 	but you have the distances to work with 
 none 	you have the distances to work with  yeah 
 none 	cuz actually mississippi state people did use support vector machines for uh uh speech recognition and they were using it to estimate probabilities 
 none 	yeah 
 none 	yeah  they   they had a   had a way to translate the distances into   into probabilities with the   with the simple um uh sigmoidal function 
 none 	yeah  and d  did they use sigmoid or a softmax type thing  and didn t they like exponentiate or something and then divide by the sum of them  or    
 none 	um
 none 	yeah  there s some   there s like one over one plus the exponential or something like that 
 none 	oh it   i 
 none 	oh  so it is a sigmoidal 
 none 	yeah 
 none 	o_k 
 none 	alright 
 none 	did the   did they get good results with that 
 none 	i mean   they re o_k  i   i don t   i don t think they were earth   earth shattering  but i think that uh this was a couple years ago  i remember them doing it at some meeting  and   and um
 none 	hmm 
 none 	i don t think people were very critical because it was interesting just to   to try this and you know  it was the first time they tried it  so   so the   you know  the numbers were not incredibly good but there s you know  it was th  reasonable 
 none 	hmm 
 none 	mm hmm 
 none 	i   i don t remember anymore 
 none 	i don t even remember what the task was  it was broadcast news  or something  i don t know 
 none 	hmm 
 none 	uh s  so barry  if you just have zero and ones  how are you doing the speech recognition 
 none 	right 
 none 	oh i m not do  i m not planning on doing speech recognition with it  i m just doing detection of phonological features 
 none 	oh  o_k  
 none 	so uh for example  this   this uh feature set called the uh sound patterns of english um is just a bunch of um binary valued features 
 none 	let s say  is this voicing  or is this not voicing  is this sonorants  not sonorants  and stuff like that  so 
 none 	o_k 
 none 	did you find any more mistakes in their tables 
 none 	oh  uh i haven t gone through the entire table  yet  yeah  yesterday i brought chuck the table and i was like   wait  this   is  
 none 	is the mapping from n_ to   to this phonological feature called um  coronal    is   is   should it be   shouldn t it be a one  or should it   should it be you know coronal instead of not coronal as it was labeled in the paper  
 none 	so i ha  haven t hunted down all the   all the mistakes yet  but  
 none 	uh huh 
 none 	but a  as i was saying  people do get probabilities from these things  and   and uh we were just trying to remember how they do  but people have used it for speech recognition  and they have gotten probabilities  so they have some conversion from these distances to probabilities 
 none 	o_k 
 none 	o_k  o_k  o_k 
 none 	right  yeah 
 search 	there s   you have   you have the paper  right    the mississippi state paper   
 none 	mm hmm  mm hmm 
 none 	yeah  if you re interested y  you could look  yeah 
 none 	and   o_k  o_k 
 none 	yeah  i can   i can show you   i   yeah  our  
 none 	so in your   in   in the thing that you re doing  uh you have a vector of ones and zeros for each phone 
 none 	mm hmm 
 none 	uh  is this the class project  or    
 none 	yeah 
 none 	o_k  um
 none 	is that what you re  
 none 	right 
 none 	right  right f  so for every phone there is   there is a um   a vector of ones and zeros f  uh corresponding to whether it exhibits a particular phonological feature or not 
 none 	mm hmm 
 none 	mm hmm 
 none 	and so when you do your wh  i m   what is the task for the class project  to come up with the phones  or to come up with these vectors to see how closely they match the phones  or    
 none 	um
 none 	oh 
 none 	right  um to come up with a mapping from um m_f_c_c s or s  some feature set  um to uh w  to whether there s existence of a particular phonological feature 
 none 	mm hmm 
 none 	and um yeah  basically it s to learn a mapping from   from the m_f_c_c s to uh phonological features 
 none 	is it   did that answer your question 
 none 	i think so 
 none 	o_k 
 none 	c 
 none 	i guess  
 none 	i mean  uh  
 none 	i m not sure what you   what you re   what you get out of your system  do you get out a uh   a vector of these ones and zeros and then try to find the closest matching phoneme to that vector  or    
 none 	mm hmm 
 none 	oh  no  no  i m not   i m not planning to do any   any phoneme mapping yet  just   it s   it s basically   it s   it s really simple  basically a detection of phonological features 
 none 	uh huh 
 none 	i see 
 none 	yeah  and um cuz the uh  
 none 	so king and   and taylor um did this with uh recurrent neural nets  and this i  their   their idea was to first find a mapping from m_f_c_c s to uh phonological features and then later on  once you have these phonological features  then uh map that to phones  so i m   i m sort of reproducing phase one of their stuff 
 none 	yeah 
 none 	mm hmm 
 none 	mm hmm 
 none 	mmm 
 none 	so they had one recurrent net for each particular feature 
 none 	right 
 none 	right 
 none 	i see 
 none 	right 
 none 	right 
 none 	i wo  did they compare that   i mean  what if you just did phone recognition and did the reverse lookup 
 none 	uh 
 none 	so you recognize a phone and which ever phone was recognized  you spit out it s vector of ones and zeros 
 none 	mm hmm 
 none 	i mean uh  
 none 	i expect you could do that  that s probably not what he s going to do on his class project 
 none 	uh 
 none 	yeah  no 
 none 	yeah 
 none 	so um have you had a chance to do this um thing we talked about yet with the uh   um
 none 	yeah 
 none 	insertion penalty 
 none 	uh  no actually i was going a different   that s a good question  too  but i was gonna ask about the   the um changes to the data in comparing p_l_p and mel cepstrum for the s_r_i system 
 none 	uh 
 none 	well what i ve been  
 none 	 changes to the data   i m not sure i  
 none 	right 
 none 	so we talked on the phone about this  that   that there was still a difference of a   of a few percent and you told me that there was a difference in how the normalization was done 
 none 	yeah 
 none 	right 
 none 	and i was asking if you were going to do   redo it uh for p_l_p with the normalization done as it had been done for the mel cepstrum 
 none 	mm hmm 
 none 	uh right  no i haven t had a chance to do that 
 none 	what i ve been doing is uh trying to figure out   it just seems to me like there s a um   well it seems like there s a bug  because the difference in performance is   it s not gigantic but it s big enough that it   it seems wrong  and  
 none 	o_k 
 none 	yeah  i agree  but i thought that the normalization difference was one of the possibilities  right 
 none 	yeah  but i don t   i m not  
 none 	yeah  i guess i don t think that the normalization difference is gonna account for everything 
 none 	so what i was working on is um just going through and checking the headers of the wavefiles  to see if maybe there was a um   a certain type of compression or something that was done that my script wasn t catching  so that for some subset of the training data  uh the   the   the features i was computing were junk 
 none 	o_k 
 none 	o_k 
 none 	which would you know cause it to perform o_k  but uh  you know  the   the models would be all messed up  so i was going through and just double checking that kind of think first  to see if there was just some kind of obvious bug in the way that i was computing the features 
 none 	mm hmm 
 none 	i see 
 none 	o_k 
 none 	looking at all the sampling rates to make sure all the sampling rates were what   eight k_  what i was assuming they were  um  
 none 	yeah 
 none 	yeah  that makes sense  to check all that 
 none 	yeah  so i was doing that first  before i did these other things  just to make sure there wasn t something  
 none 	although really  uh uh  a couple three percent uh difference in word error rate uh could easily come from some difference in normalization  i would think 
 none 	but
 none 	yeah  and i think  hhh   i m trying to remember but i think i recall that  andreas  was saying that he was gonna run sort of the reverse experiment 
 none 	uh which is to try to emulate the normalization that we did but with the mel cepstral features 
 none 	sort of  you know  back up from the system that he had 
 find_email 	i thought he said he was gonna   i have to look back through  my   my  email from  him   
 none 	yeah  he s probably off at   at uh his meeting now  yeah 
 none 	yeah  he s gone now 
 none 	um 
 none 	yeah 
 none 	but yeah the   i sh  think they should be roughly equivalent  um
 none 	but  
 none 	i mean again the cambridge folk found the p_l_p actually to be a little better 
 none 	right 
 none 	uh
 none 	so it s   um
 none 	i mean the other thing i wonder about was whether there was something just in the   the bootstrapping of their system which was based on   but maybe not  since they  
 none 	yeah see one thing that s a little bit um  
 none 	i was looking   i ve been studying and going through the logs for the system that um andreas created 
 none 	and um his uh   the way that the  
 none 	s_r_ i system looks like it works is that it reads the wavefiles directly  uh and does all of the cepstral computation stuff on the fly 
 none 	right 
 none 	right 
 none 	and  so there s no place where these   where the cepstral files are stored  anywhere that i can go look at and compare to the p_l_p ones  so whereas with our features  he s actually storing the cepstrum on disk  and he reads those in  but it looked like he had to give it   uh even though the cepstrum is already computed  he has to give it uh a front end parameter file  which talks about the kind of uh com  computation that his mel cepstrum thing does  so i 
 none 	right 
 none 	uh huh 
 none 	i   i don t know if that   it probably doesn t mess it up  it probably just ignores it if it determines that it s already in the right format or something but   the   the   the two processes that happen are a little different 
 none 	so 
 none 	yeah 
 none 	so anyway  there s stuff there to sort out 
 none 	yeah 
 none 	yeah 
 none 	so  o_k  let s go back to what you thought i was asking you 
 none 	yeah no and i didn t have a chance to do that 
 none 	ha 
 none 	oh  you had the sa  same answer anyway 
 none 	yeah 
 none 	yeah  i ve been um   
 none 	i ve been working with um
 none 	jeremy on his project and then i ve been trying to track down this bug in uh the icsi front end features 
 none 	uh huh 
 none 	so one thing that i did notice  yesterday i was studying the um   the uh rasta code and it looks like we don t have any way to um control the frequency range that we use in our analysis  we basically   it looks to me like we do the f_f_t  um and then we just take all the bins and we use everything 
 none 	uh huh 
 none 	we don t have any set of parameters where we can say you know   only process from you know a hundred and ten hertz to thirty seven fifty  
 none 	um  
 none 	at least i couldn t see any kind of control for that 
 none 	yeah  i don t think it s in there  i think it s in the uh uh uh the filters 
 none 	so  the f_f_ t is on everything  but the filters um  for instance  ignore the   the lowest bins and the highest bins 
 none 	and what it does is it   it copies um
 none 	the   the filters  which filters 
 none 	the filter bank which is created by integrating over f_f_ t bins  um
 none 	mm hmm 
 none 	when you get the mel  
 none 	when you go to the mel scale 
 none 	right 
 none 	yeah  it s bark scale  and it s   it   it um   it actually copies the uh um   the second filters over to the first  so the first filters are always   and you can s  you can specify a different number of uh features   different number of filters  i think  as i recall 
 none 	so you can specify a different number of filters  and whatever um uh you specify  the last ones are gonna be ignored  so that   that s a way that you sort of change what the   what the bandwidth is 
 none 	y  you can t do it without i think changing the number of filters  but  
 none 	i saw something about uh   that looked like it was doing something like that  but i didn t quite understand it 
 none 	so maybe  
 none 	yeah  so the idea is that the very lowest frequencies and   and typically the veriest highest frequencies are kind of junk 
 none 	uh huh 
 none 	and so um you just   for continuity you just approximate them by   by the second to highest and second to lowest 
 none 	mm hmm 
 none 	it s just a simple thing we put in 
 none 	and   and so if you h 
 none 	but   so the   but that s a fixed uh thing  there s nothing that lets you  
 none 	yeah 
 none 	i think that s a fixed thing  but see   see my point  if you had  
 none 	if you had ten filters  then you would be throwing away a lot at the two ends 
 none 	mm hmm 
 none 	and if you had   if you had fifty filters  you d be throwing away hardly anything 
 none 	mm hmm 
 none 	um  i don t remember there being an independent way of saying  we re just gonna make them from here to here  
 none 	use this analysis bandwidth or something 
 none 	but i   i   i don t know  it s actually been awhile since i ve looked at it 
 none 	yeah  i went through the feacalc code and then looked at you know just calling the rasta libs and thing like that  and i didn t   i couldn t see any wh  place where that kind of thing was done 
 none 	but um
 none 	i didn t quite understand everything that i saw  so  
 none 	yeah  see i don t know feacalc at all 
 none 	mm hmm 
 none 	but it calls rasta with some options  and um
 none 	right 
 none 	but i   i think in  
 none 	i don t know  i guess for some particular database you might find that you could tune that and tweak that to get that a little better  but i think that in general it s not that critical  i mean there s  
 none 	yeah 
 none 	you can  
 none 	you can throw away stuff below a hundred hertz or so and it s just not going to affect phonetic classification at all 
 none 	another thing i was thinking about was um is there a  
 none 	i was wondering if there s maybe um certain settings of the parameters when you compute p_l_p which would basically cause it to output mel cepstrum 
 none 	so that  in effect  what i could do is use our code but produce mel cepstrum and compare that directly to  
 none 	well  it s not precisely 
 none 	yeah  i mean  um  um what you can do is um
 none 	hmm 
 none 	you can definitely change the   the filter bank from being uh a uh trapezoidal integration to a   a   a triangular one  which is what the typical mel   mel cepstral uh filter bank does 
 none 	mm hmm 
 none 	mm hmm 
 none 	and some people have claimed that they got some better performance doing that  so you certainly could do that easily 
 none 	but the fundamental difference  i mean  there s other small differences  
 none 	there s a cubic root that happens  right 
 none 	yeah  but  you know  as opposed to the log in the other case  i mean the fundamental d  d  difference that we ve seen any kind of difference from before  which is actually an advantage for the p_l_ p i  uh  i think  is that the   the smoothing at the end is auto regressive instead of being cepstral   uh  from cepstral truncation 
 none 	so um it s a little more noise robust 
 none 	hmm 
 none 	um  and that s   that s why when people started getting databases that had a little more noise in it  like   like uh um
 none 	broadcast news and so on  that s why c  cambridge switched to p_l_p i think 
 none 	mm hmm 
 none 	so um
 none 	that s a difference that i don t think we put any way to get around  since it was an advantage  um uh but we did   eh we did hear this comment from people at some point  that um it uh they got some better results with the triangular filters rather than the trapezoidal  so that is an option in rasta 
 none 	mm hmm 
 none 	hmm 
 none 	uh and you can certainly play with that 
 none 	but i think you re probably doing the right thing to look for bugs first 
 none 	yeah just   it just seems like this kind of behavior could be caused by you know s  some of the training data being messed up 
 none 	i don t know 
 none 	could be 
 none 	you know  you re sort of getting most of the way there  but there s a  
 none 	so i started going through and looking  
 none 	one of the things that i did notice was that the um log likelihoods coming out of the log recognizer from the p_l_p data were much lower  much smaller  than for the mel cepstral stuff  and that the average amount of pruning that was happening was therefore a little bit higher for the p_l_p features 
 none 	oh huh 
 none 	so  since he used the same exact pruning thresholds for both 
 none 	i was wondering if it could be that we re getting more pruning 
 none 	oh 
 none 	he   he  
 none 	he used the identical pruning thresholds even though the s  the range of p  of the likeli 
 none 	yeah 
 none 	oh well that s  
 none 	right 
 none 	right 
 none 	that s a pretty good point right there  yeah 
 none 	yeah  so  
 none 	i would think that you might wanna do something like uh you know  look at a few points to see where you are starting to get significant search errors 
 none 	that s  
 none 	right 
 none 	well  what i was gonna do is i was gonna take um a couple of the utterances that he had run through  then run them through again but modify the pruning threshold and see if it you know  affects the score 
 none 	yeah 
 none 	yeah 
 none 	so 
 none 	but i mean you could   uh if   if   if that looks promising you could  you know  r  uh run the overall test set with a   with a few different uh pruning thresholds for both  and presumably he s running at some pruning threshold that s   that s uh  you know   gets very few search errors but is   is relatively fast and  
 none 	mm hmm 
 none 	right 
 none 	mm hmm 
 none 	right  i mean  yeah  generally in these things you   you turn back pruning really far  so
 none 	i   i didn t think it would be that big a deal because i was figuring well you have it turned back so far that you know it  
 none 	but you may be in the wrong range for the p_l_ p features for some reason 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	and the uh the   the run time of the recognizer on the p_l_p features is longer which sort of implies that the networks are bushier  you know  there s more things it s considering which goes along with the fact that the matches aren t as good 
 none 	so uh  you know  it could be that we re just pruning too much 
 none 	so 
 none 	yeah 
 none 	yeah  maybe just be different kind of distributions and   and yeah so that s another possible thing 
 none 	mm hmm 
 none 	mm hmm 
 none 	they   they should   really shouldn t   there s no particular reason why they would be exactly   behave exactly the same 
 none 	mm hmm 
 none 	right 
 none 	right 
 none 	so 
 none 	so 
 none 	there s lots of little differences  so 
 none 	yeah 
 none 	uh 
 none 	yeah 
 none 	trying to track it down 
 none 	yeah 
 none 	i guess this was a little bit off topic  i guess  because i was   i was thinking in terms of th  this as being a   a   a   a core item that once we   once we had it going we would use for a number of the front end things also 
 none 	yeah
 none 	mm hmm 
 none 	so 
 none 	um
 none 	wanna  
 none 	that s   as far as my stuff goes  yeah  well i tried this mean subtraction method  um  due to avendano 
 none 	what s   what s on  
 none 	yeah 
 none 	i m taking s  um six seconds of speech  um
 none 	i m using two second
 none 	f_f_t analysis frames  stepped by a half second so it s a quarter length step and i  
 none 	i take that frame and four f  the four   i take   sorry  i take the current frame and the four past frames and the four future frames and that adds up to six seconds of speech 
 none 	and i calculate um the spectral mean  of the log magnitude spectrum over that n_ 
 none 	i use that to normalize the s  the current center frame by mean subtraction 
 none 	and i then   then i move to the next frame and i  
 none 	i do it again 
 none 	well  actually i calculate all the means first and then i do the subtraction 
 none 	and um the   i tried that with h_d_k  the aurora setup of h_d_k training on clean t_i digits  and um it   it helped um in a phony reverberation case um where i just used the simulated impulse response um the error rate went from something like eighty it was from something like eighteen percent to um four percent 
 none 	and on meeting rec  recorder far mike digits  mike   on channel f_  it went from um forty one percent error to eight percent error 
 none 	on   on the real data  not with artificial reverb 
 none 	right 
 none 	uh huh 
 none 	and that   that was um trained on clean speech only  which i m guessing is the reason why the baseline was so bad 
 none 	uh huh  
 none 	and  
 none 	that s ac  actually a little side point is i think that s the first results that we have uh uh uh of any sort on the far field uh   on   on the far field data uh for   recorded in   in meetings 
 none 	oh um actually um
 none 	adam ran the s_r_i recognizer 
 none 	did he  
 none 	on the near field  on the ne 
 none 	on the far field also  he did one p_z_m channel and one p_d_a channel 
 none 	oh did he 
 none 	oh  i didn t recall that 
 none 	what kind of numbers was he getting with that 
 none 	i  
 none 	i m not sure  i think it was about five percent error for the p_z_m channel 
 none 	five 
 none 	f  i think  yeah 
 none 	so why were you getting forty  one here  is this  
 none 	um 
 none 	i   i m g  i m guessing it was the   the training data 
 none 	uh  clean t_i digits is  like  pretty pristine training data  and if they trained the s_r_i system on this
 none 	t_v broadcast type stuff  i think it s a much wider range of channels and it  
 none 	no  but wait a minute  i  
 none 	i   i th  
 none 	i think he  
 none 	what am i saying here  yeah  so that was the s_r_i system 
 none 	maybe you re right  yeah  cuz it was getting like one percent  
 none 	so it s still this kind of ratio  it was   it was getting one percent or something on the near field  wasn t it 
 none 	mm hmm  or it wa a  it was around one  yeah 
 none 	yeah  yeah  i think it was getting around one percent for the near   for the n  for the close mike 
 none 	huh 
 none 	o_k 
 none 	so it was like one to five   so it s still this kind of ratio  it s just   yeah  it s a lot more training data 
 none 	so
 none 	so probably it should be something we should try then is to   is to see if   is at some point just to take   i  to transform the data and then   and then uh use th  use it for the s_r_i system 
 none 	b  you me  you mean um ta 
 none 	so you re   so you have a system which for one reason or another is relatively poor  and   and uh you have something like forty one percent error uh and then you transform it to eight by doing   doing this   this work 
 none 	yeah 
 none 	um 
 none 	so here s this other system  which is a lot better  but there s still this kind of ratio  it s something like five percent error with the   the distant mike  and one percent with the close mike 
 none 	o_k 
 none 	so the question is how close to that one can you get if you transform the data using that system 
 none 	r  right  so   so i guess this s_r_i system is trained on a lot of s  broadcast news or switchboard data 
 none 	yeah 
 none 	is that right  do you know which one it is 
 none 	it s trained on a lot of different things  um 
 none 	it s trained on uh a lot of switchboard  call home  um a bunch of different sources  some digits  there s some digits training in there 
 none 	uh huh 
 none 	o_k  
 none 	o  one thing i m wondering about is what this mean subtraction method um will do if it s faced with additive noise 
 none 	hmm 
 none 	cuz i   i   it s cuz i don t know what log magnitude spectral subtraction is gonna do to additive noise 
 none 	yeah  well  it s   it s not exactly the right thing but uh but you ve already seen that cuz there is added noise here 
 none 	that s   that s the  
 none 	uh huh 
 none 	that s   that s   yeah  that s true 
 none 	yeah 
 none 	that s a good point 
 none 	so um  
 none 	o_k  so it s then   then it s   it s   it s reasonable to expect it would be helpful if we used it with the s_r_i system and
 none 	yeah  i mean  as helpful   i mean  so that s the question 
 none 	yeah  w  we re often asked this when we work with a system that   that isn t   isn t sort of industry   industry standard great  uh and we see some reduction in error using some clever method  then  you know  will it work on a   on a   on a good system 
 none 	uh huh 
 none 	so uh you know  this other one s   it was a pretty good system  i think  you know  one   one percent word error rate on digits is   uh digit strings is not uh you know stellar  but   but given that this is real digits  as opposed to uh sort of laboratory  
 none 	mm hmm 
 none 	well 
 none 	and it wasn t trained on this task either 
 none 	and it wasn t trained on this task  actually one percent is sort of   you know  sort of in a reasonable range  people would say  yeah  i could   i can imagine getting that  
 none 	mm hmm 
 none 	and uh so the   the four or five percent or something is   is   is quite poor 
 none 	mm hmm 
 none 	uh  you know  if you re doing a uh   a sixteen digit uh credit card number you ll basically get it wrong almost all the time 
 none 	hmm 
 none 	so  so  uh  um a significant reduction in the error for that would be great 
 none 	huh  o_k 
 none 	and   and then  uh yeah  so 
 none 	yeah 
 none 	cool 
 none 	sounds good 
 none 	yeah 
 none 	alright  um 
 none 	i actually have to run 
 none 	so i don t think i can do the digits  but um 
 none 	i guess i ll leave my microphone on 
 none 	uh  yeah 
 none 	yeah  thank you  
 none 	yep 
 none 	actually  i could just go first  come to think of it 
 none 	then i can be out of here quickly 
 none 	yeah  that ll work 
 none 	that s alright  i just have to run for another appointment 
 none 	o_k  did i t  yeah  i left it on 
 none 	o_k 
 none 	o_k  this is transcript l_ dash one one zero  nine zero two five seven three two six six one six six six seven four two zero eight five one six nine four seven seven nine five zero five six zero two two five seven seven six zero eight nine zero seven two six four five two one nine two eight nine five five eight eight three two five zero two nine three four four six one two zero eight eight five
 none 	um transcript l_ one one one  three six two eight three three two two o_ seven one six six five four two six eight nine zero zero six three nine three three four seven five four seven nine six zero nine nine zero three seven four three two seven five four two four nine three five one nine seven eight one eight five o_ four nine four zero seven five three seven five eight four four one seven zero one eight five five three two five o_ three eight
 none 	transcript l_ dash one one two  zero seven eight seven six two one six four six five three one two five eight four seven seven two seven zero six three six three four seven nine seven six five two nine nine three two seven three two nine nine nine three eight nine one four one seven six o_ four four zero zero eight six seven four five eight zero six six three five nine seven seven seven seven three five five three two four five zero eight
 none 	r  i m reading transcript l_ dash one one three  six five six nine seven two eight four four o_ eight seven five one eight seven four zero five seven zero two four two five o_ three seven six eight one seven seven nine two one seven nine zero nine zero six zero five six eight eight five nine five two two two five five six six two nine one one seven two zero six seven one six two zero two three zero one nine zero two three
 none 	transcript l_ dash w  one one five  zero six four seven three two two seven one zero eight seven five eight six seven three seven five seven five five one one nine one four nine eight four one nine three one zero zero two four one zero three six eight two one nine six two eight nine six nine one eight six five six five zero three one one six six three nine eight seven eight three nine eight nine
 none 	o_k 
 none 	uh 
 none 	somebody else should run this 
 none 	i m sick of being the one to sort of go through and say   well  what do you think about this  
 none 	you wanna    
 none 	should we take turns  you want me to run it today 
 none 	yeah 
 none 	yeah  why don t you run it today  o_k 
 none 	o_k 
 none 	o_k  um 
 open_agenda 	let s see  maybe we should just get a list of items   things that we should talk about  
 none 	um 
 none 	i guess there s the usual updates  everybody going around and saying  uh  you know  what they re working on  the things that happened the last week 
 none 	but aside from that is there anything in particular that anybody wants to bring up for today 
 none 	mmm 
 none 	no  o_k  so why don t we just around and people can give updates  uh  do you want to start  stephane 
 none 	oh 
 search 	alright  um   well  the first thing maybe is that the p   eurospeech paper  is  uh  accepted  
 none 	um  yeah 
 none 	this is   what   what do you  uh   what s in the paper there 
 none 	so it s the paper that describe basically the  um  system that were proposed for the aurora 
 none 	the one that we s  we submitted the last round 
 none 	right  yeah 
 none 	uh huh 
 none 	yeah 
 none 	um   yeah  so and the  fff comments seems   from the reviewer are good  so 
 none 	hmm 
 none 	mmm  
 none 	yeah 
 none 	where   where s it gonna be this year 
 none 	it s  uh  aalborg in denmark  and it s  yeah 
 none 	oh  o_k 
 none 	september 
 none 	mmm 
 none 	mmm  
 none 	yeah  then  uh  whhh well  i ve been working on   on t  mainly on on line normalization this week 
 none 	uh  i ve been trying different   slightly   slightly different approaches 
 none 	um  the first thing is trying to play a little bit again with the  um  time constant 
 none 	uh  second thing is  uh  the training of  uh  on line normalization with two different means  one mean for the silence and one for the speech 
 none 	um  and so i have two recursions which are controlled by the  um  probability of the voice activity detector 
 none 	mmm 
 none 	this actually don t s  doesn t seem to help  although it doesn t hurt  so 
 none 	but   well  both on line normalization approach seems equivalent 
 none 	are the means pretty different for the two 
 none 	well  they  
 none 	yeah  they can be very different  yeah  mm hmm 
 none 	hmm 
 none 	so do you maybe make errors in different places  different kinds of errors 
 none 	i didn t look  uh  more closely  um  it might be  yeah  mm hmm 
 none 	um 
 none 	well  eh  there is one thing that we can observe  is that the mean are more different for   for c_zero and c_one than for the other coefficients 
 none 	and  
 none 	yeah 
 none 	and   yeah  it   the c_one is  
 none 	there are strange   strange thing happening with c_one  is that when you have different kind of noises  the mean for the   the silence portion is   can be different 
 none 	hmm 
 none 	and  
 none 	so when you look at the trajectory of c_one  it s   has a strange shape and
 none 	i was expecting th  the s  that these two mean helps  especially because of the   the strange
 none 	c_ze  c_one shape  uh  which can   like  yo  you can have  um  a trajectory for the speech and then when you are in the silence it goes somewhere  but if the noise is different it goes somewhere else 
 none 	oh 
 none 	so which would mean that if we estimate the mean based on all the signal  even though we have frame dropping  but we don t frame ev  uh  drop everything  but   uh  this can   hurts the estimation of the mean for speech  and  
 none 	mmm  but i still have to investigate further  i think 
 none 	um  a third thing is  um  that instead of t  having a fixed time constant 
 none 	i try to have a time constant that s smaller at the beginning of the utterances to adapt more quickly to the r  something that s closer to the right mean 
 none 	t  t  um  
 none 	yeah  and then this time constant increases and i have a threshold that   well  if it s higher than a certain threshold  i keep it to this threshold to still  uh  adapt  um  the mean when   if the utterance is  uh  long enough to   to continue to adapt after  like  one second or  
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	mmm 
 none 	uh  well  this doesn t help neither  but this doesn t hurt  so  well 
 none 	it seems pretty  
 none 	wasn t there some experiment you were gonna try where you did something differently for each  um  uh   i don t know whether it was each mel band or each  uh  um  f_f_t bin or someth  there was something you were gonna   uh  some parameter you were gonna vary depending on the frequency 
 none 	i don t know if that was  
 none 	i guess it was  
 none 	i don t know  no  u  maybe it s this   this idea of having different on line normalization  um  tunings for the different m_f_c_c s 
 none 	for each  uh  
 none 	mm hmm 
 none 	but  
 none 	mm hmm 
 find_calendar_entry 	yeah  i   i thought  morgan  you brought it up a couple meetings ago  and then it was something about  uh  some  and then somebody said  yeah  it does seem like  you know  c_zero is the one that s  you know  the major one  or  uh  s  i can t remember exactly what it was now 
 none 	mmm 
 none 	yeah  there   uh  actually  yeah 
 none 	s  um  it s very important to normalize c_zero and much less to normalize the other coefficients  and  um  actu  uh  well  at least with the current on line normalization scheme  and we   i think  we kind of know that normalizing c_one doesn t help with the current scheme  and   and   yeah 
 none 	in my idea  i  
 none 	i was thinking that the   the   the reason is maybe because of these funny things that happen between speech and silence which have different means 
 none 	um   yeah 
 none 	but maybe it s not so   so easy to  
 none 	um 
 none 	i  i really would like to suggest looking  um  a little bit at the kinds of errors  i know you can get lost in that and go forever and not see too much  but   sometimes  but   but  um  just seeing that each of these things didn t make things better may not be enough  it may be that they re making them better in some ways and worse in others  or increasing insertions and decreasing deletions  or   or  um  um  you know  helping with noisy case but hurting in quiet case  and if you saw that then maybe you   it would   something would occur to you of how to deal with that 
 none 	mm hmm 
 none 	yeah 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	hmm 
 none 	alright 
 none 	mmm 
 none 	yeah  w  um 
 none 	so that s it  i think  for the on line normalization 
 none 	um  
 none 	yeah  i ve been playing a little bit with some kind of thresholding  and  mmm 
 none 	as a first experiment  i think i 
 none 	yeah  well  what i did is t  is to take  um   to measure the average   no  the maximum energy of s  each utterance and then put a threshold  
 none 	well  this for each mel band 
 none 	then put a threshold that s fifteen d_b below   well  uh  a couple of d_b below this maximum  and  
 none 	mm hmm 
 none 	mmm 
 none 	actually it was not a threshold  it was just adding noise 
 none 	mm hmm 
 none 	so i was adding a white noise energy  uh  that s fifteen d_b below the maximum energy of the utterance 
 none 	and  
 none 	yeah  when we look at   at the  um  m_f_c_c that result from this  they are a lot more smoother 
 none 	um  when we compare  like  a channel zero and channel one utterance   um  so a clean and  uh  the same noisy utterance   well  there is almost no difference between the cepstral coefficients of the two 
 none 	hmm 
 none 	um 
 none 	and   yeah  and the result that we have in term of speech recognition  actually it s not   it s not worse  it s not better neither  but it s  um  kind of surprising that it s not worse because basically you add noise that s fifteen d_b   just fifteen d_b below the maximum energy  and at least  
 none 	hmm 
 none 	sorry 
 none 	so why does that m  smooth things out  i don t   i don t understand that 
 none 	well  there s less difference  right  cuz it s  
 none 	it s   i think  it s whitening  
 none 	this   the portion that are more silent  as you add a white noise that are   has a very high energy  it whitens everything and   and the high energy portion of the speech don t get much affected anyway by the other noise  and as the noise you add is the same is   the shape  it s also the same 
 none 	huh  oh  o_k 
 none 	hmm 
 none 	yeah 
 none 	so they have   the trajectory are very  very similar  and   and  
 none 	so  i mean  again  if you trained in one kind of noise and tested in the same kind of noise  you d   you know  given enough training data you don t do b  do badly 
 none 	the reason that we d  that we have the problems we have is because it s different in training and test  even if the general kind is the same  the exact instances are different  and   and so when you whiten it  then it s like you   the   the only noise   to   to first order  the only th  noise that you have is white noise and you ve added the same thing to training and test  so it s  uh  
 none 	mm hmm 
 none 	mm hmm 
 none 	hmm 
 none 	so would that be similar to  like  doing the smoothing  then  over time or    
 none 	mm hmm 
 none 	well  it s a kind of smoothing  but  
 none 	i think it s   i think it s different  it s   it s something that   yeah  that affects more or less the silence portions because  
 none 	mm hmm 
 none 	well  anyway  the sp  the portion of speech that ha  have high energy are not ch  a lot affected by the noises in the aurora database  if   if you compare th  the two shut channels of speechdat car during speech portion  it s n  n  n  the m_f_c_c are not very different 
 none 	mm hmm 
 none 	they are very different when energy s lower  like during fricatives or during speech pauses 
 none 	and  uh  
 none 	yeah  but you re still getting more recognition errors  which means that the differences  even though they look like they re not so big  are   are hurting your recognition  right 
 none 	ye 
 none 	yeah  so it distort the speech  right  um 
 none 	yeah 
 none 	so performance went down 
 none 	no  it didn t  but  
 none 	oh 
 none 	yeah  so  but in this case i   i really expect that maybe the   the two   these two stream of features  they are very different  i mean  and maybe we could gain something by combining them or  
 none 	well  the other thing is that you just picked one particular way of doing it  uh  i mean  first place it s fifteen d_b  uh  down across the utterance  and maybe you d want to have something that was a little more adaptive  secondly  you happened to pick fifteen d_b and maybe twenty d be better  or   or twelve 
 none 	mmm 
 none 	yeah 
 none 	yeah  right 
 none 	so what was the   what was the threshold part of it  was the threshold  uh  how far down    
 none 	yeah  well  he   yeah  he had to figure out how much to add 
 none 	so he was looking   he was looking at the peak value 
 none 	uh huh 
 none 	right  and then  
 none 	uh huh 
 none 	and   and so what s   ho  i don t understand  how does it go  if it   if   if the peak value s above some threshold  then you add the noise  or if it s below s 
 none 	i systematically add the noise  but the  um  noise level is just some kind of threshold below the peak 
 none 	oh  oh  i see  i see 
 none 	mmm 
 none 	um 
 none 	yeah 
 none 	yeah  which is not really noise  actually  it s just adding a constant to each of the mel  uh  energy 
 none 	mm hmm 
 none 	to each of the mel filter bank  yeah 
 none 	i see 
 none 	so  yeah  it s really  uh  white noise  i th 
 none 	mm hmm 
 none 	yeah 
 none 	so then afterwards a log is taken  and that s so  sort of why the   the little variation tends to go away 
 none 	mm hmm 
 none 	um 
 none 	yeah  so may  well  the   this threshold is still a factor that we have to look at  and
 none 	i don t know  maybe a constant noise addition would   would be fine also  or  
 none 	um  
 none 	or   or not constant but   but  uh  varying over time in fact is another way to go 
 none 	mm hmm 
 none 	mm hmm 
 none 	um 
 none 	yeah 
 none 	um  
 none 	were you using the   the normalization in addition to this  i mean  what was the rest of the system 
 none 	um  
 none 	yeah  it was   it was  uh  the same system 
 none 	mm hmm 
 none 	o_k 
 none 	it was the same system 
 none 	mmm 
 none 	oh  yeah 
 none 	a third thing is that  um 
 none 	i play a little bit with the  um   finding what was different between  um 
 none 	and there were a couple of differences  like the l_d_a filters were not the same 
 none 	um  he had the france telecom blind equalization in the system 
 none 	um  the number o  of m_f_c_c that was   were used was different  you used thirteen and we used fifteen 
 none 	well  a bunch of differences  and  um  actually the result that he   he got were much better on t_i digits especially 
 none 	so i m kind of investigated to see what was the main factor for this difference  and it seems that the l_d_a filter is   is   was hurting 
 none 	um  so when we put s  some noise compensation the  um  l_d_a filter that   that s derived from noisy speech is not more   anymore optimal 
 none 	and it makes a big difference  um  on t_i digits trained on clean 
 none 	uh  if we use the   the old l_d_a filter  i mean the l_d_a filter that was in the proposal  we have  like  eighty two point seven percent recognition rate  um  on noisy speech when the system is trained on clean speech 
 none 	but   and when we use the filter that s derived from clean speech we jumped   so from eighty two point seven to eighty five point one  which is a huge leap 
 none 	mm hmm 
 none 	um 
 none 	yeah  so now the results are more similar  and
 none 	i don t   i will not  i think  investigate on the other differences  which is like the number of m_f_c_c that we keep and other small things that we can i think optimize later on anyway 
 none 	sure  but on the other hand if everybody is trying different kinds of noise suppression things and so forth  it might be good to standardize on the piece that we re not changing  right  so if there s any particular reason to ha  pick one or the other  i mean  
 none 	which   which one is closer to what the proposal was that was submitted to aurora  are they   they both     well  i mean  
 none 	i think  
 none 	yeah  i think th  th  uh  the new system that i tested is  i guess  closer because it doesn t have   it have less of   of france telecom stuff  i  
 none 	you mean the  
 none 	the   whatever you  uh  tested with recently  right 
 none 	mmm 
 none 	yeah 
 none 	yeah 
 none 	well  no  i   i m   i  
 none 	yeah  you re trying to add in france telecom  tell them about the rest of it  like you said the number of filters might be different or something  right  or  
 none 	but  we  
 none 	the number of cepstral coefficients is what 
 none 	cep 
 none 	mm hmm 
 create_single_reminder 	yeah   so  i mean  i think  we d  wanna  standardize  there  wouldn t we  
 none 	yeah  yeah 
 none 	so  sh  you guys should pick something and  
 none 	yeah 
 none 	yeah 
 none 	well  all th  all three of you 
 none 	i think we were gonna work with   with this or this new system  or with  
 none 	uh  so the   the   right now  the   the system that is there in the   what we have in the repositories  with   uses fifteen 
 none 	so  
 none 	right  yeah 
 none 	yeah  so   yeah  so   yep 
 none 	but we will use the   the l_d_a filters f  derived from clean speech 
 none 	yeah  yeah  so  
 none 	well  yeah  actually it s   it s not the   the l_d_a filter  it s something that s also short enough in   in latency  so 
 none 	yeah  well  yeah 
 none 	so  we haven t   w  we have been always using  uh  fifteen coefficients  not thirteen  yeah 
 none 	yeah  mm hmm 
 none 	well  uh  that s   something s  
 none 	um  yeah 
 none 	then   mmm  
 none 	i think as long as you guys agree on it  it doesn t matter  i think we have a maximum of sixty  uh  features that we re allowed  so 
 none 	yeah 
 none 	yeah  ma  maybe we can   i mean  at least  um  i ll t  s  run some experiments to see whether   once i have this noise compensation to see whether thirteen and fifteen really matters or not 
 none 	mm hmm  mm hmm 
 none 	never tested it with the compensation  but without  uh  compensation it was like fifteen was s  slightly better than thirteen  so that s why we stuck to thirteen 
 none 	yeah 
 none 	yeah  and there is   there is also this log energy versus c_zero 
 none 	sorry  fifteen 
 none 	yeah  the log energy versus c_zero 
 none 	well 
 none 	uh  that s   that s the other thing  i mean  without noise compensation certainly c_zero is better than log energy 
 none 	w  w  if   if  
 none 	be  i mean  because the   there are more  uh  mismatched conditions than the matching conditions for testing 
 none 	mm hmm 
 none 	you know  always for the matched condition  you always get a slightly better performance for log energy than c_zero 
 none 	mm hmm 
 none 	but not for   i mean  for matched and the clean condition both  you get log energy  
 none 	i mean you get a better performance with log energy 
 none 	mm hmm 
 create_single_reminder 	well  um   maybe once we have this noise compensation  i don t know  we have to try that also  whether we want to go for c_zero or log energy   
 none 	mm hmm 
 none 	we can see that 
 none 	yeah 
 none 	hmm 
 none 	mmm 
 none 	so do you have more  stephane  or    
 none 	uh  that s it  i think  mmm 
 none 	do you have anything  morgan  or    
 none 	uh  no  i m just  you know  being a manager this week  so 
 none 	how about you  barry 
 none 	um  still working on my   my quals preparation stuff 
 none 	um  so i m   i m thinking about  um  starting some  uh  cheating experiments to  uh  determine the  um   the relative effectiveness of  um  some intermediate categories that i want to classify 
 none 	so  for example  um  if i know where voicing occurs and everything  um 
 none 	i would do a phone   um  phone recognition experiment  um  somehow putting in the   the  uh   the perfect knowledge that i have about voicing 
 none 	so  um  in particular i was thinking  um  in   in the hybrid framework  just taking those l_n_a files  and  um  setting to zero those probabilities that  um   that these phones are not voicing 
 none 	so say  like  i know this particular segment is voicing  um  i would say  uh  go into the corresponding l_n_a file and zonk out the   the posteriors for  um  those phonemes that  um  are not voiced  and then see what kinds of improvements i get 
 none 	mm hmm 
 none 	mm hmm 
 none 	and so this would be a useful thing  um  to know in terms of  like  which   which  um   which of these categories are   are good for  um  speech recognition 
 none 	hmm 
 none 	mm hmm 
 none 	so  that s  
 none 	i hope to get those  uh   those experiments done by   by the time quals come   come around in july 
 none 	so do you just take the probabilities of the other ones and spread them out evenly among the   the remaining ones 
 none 	yeah  i   i   i was thinking   o_k  so just set to   set to some really low number  the   the non voiced  um  phones  right  and then renormalize 
 none 	mm hmm 
 none 	mmm 
 none 	right 
 none 	cool 
 none 	mm hmm 
 none 	yeah 
 none 	that will be really interesting to see  you know 
 none 	so then you re gonna feed the   those into some standard recognizer  uh  wh  are you gonna do digits or    
 none 	mm hmm 
 none 	yeah  m  um  well  i m gonna f  work with timit  
 none 	with timit  o_k 
 none 	timit   uh  phone recognition with timit  and  um  
 none 	mm hmm 
 none 	oh  so then you ll feed those  
 none 	sorry  so where do the outputs of the net go into if you re doing phone recognition 
 none 	oh  um  the outputs of the net go into the standard  h  um  icsi hybrid  um  recognizer 
 none 	so maybe  um  chronos or  
 none 	an  and you re gonna   the   you re gonna do phone recognition with that  o_k  o_k 
 none 	phone recognition  right  right 
 none 	i see 
 create_single_reminder 	so   and  uh  another thing would be to  extend this to  uh  digits or something where i can look at whole words   
 none 	mm hmm 
 none 	and i would be able to see  uh  not just  like  phoneme events  but  um  inter phoneme events 
 none 	mm hmm 
 none 	so  like  this is from a stop to   to a vo  a vocalic segment  you know  so  something that is transitional in nature 
 none 	right 
 none 	cool 
 none 	yeah 
 none 	great  uh  
 none 	so that s   that s it 
 none 	o_k  um  
 none 	yeah 
 none 	let s see  i haven t done a whole lot on anything related to this this week  i ve been focusing mainly on meeting recorder stuff 
 none 	oh 
 none 	so  um  i guess i ll just pass it on to dave 
 find_calendar_entry 	uh  o_k   well  in  my   lunch talk   last week  i   i said i d tried phase normalization and gotten garbage results using that l  um  long term mean subtraction approach  
 none 	it turned out there was a bug in my matlab code 
 none 	so i tried it again  um  and  um  the results were   were better  i got intelligible speech back  but they still weren t as good as just subtracting the magnitude   the log magnitude means 
 create_single_reminder 	and also i ve been talking to  um  andreas and thilo about the  um  smartkom language model and about coming up with a good model for  um  far mike use of the smartkom system   so  i m  gonna be working on  um   implementing this mean subtraction approach in the far mike system   for the smartkom system   i mean   and  um  one of the experiments we re gonna do is  um  we re gonna  um  train the   a broadcast news net  which is because that s what we ve been using so far  and  um  adapt it on some other data  um  an  andreas wants to use  um  data that resembles read speech  like these digit readings  because he feels that the smartkom system interaction is not gonna be exactly conversational 
 none 	mm hmm 
 none 	s  so actually i was wondering  how long does it take to train that broadcast news net 
 none 	the big one takes a while  yeah  that takes two  three weeks 
 none 	two  three weeks 
 none 	so   but  you know  uh  you can get  
 none 	i don t know if you even want to run the big one  uh  um  in the   in the final system  cuz  you know  it takes a little while to run it  so  um  you can scale it down by  
 none 	i m sorry  it was two  three weeks for training up for the large broadcast news test set   training set 
 none 	oh 
 none 	i don t know how much you d be training on 
 none 	o_k 
 none 	the full  uh  i  so if you trained on half as much and made the net  uh  uh  half as big  then it would be one fourth the amount of time and it d be nearly as good 
 none 	o_k 
 none 	so 
 none 	o_k 
 none 	yeah 
 none 	also  i guess we had   we ve had these  uh  little di  discussions   i guess you ha  haven t had a chance to work with it too much   about   about  uh   uh  uh m  other ways of taking care of the phase 
 none 	mm hmm 
 none 	so  i mean  i   i guess that was something i could say would be that we ve talked a little bit about you just doing it all with complex arithmetic and  uh   and not   not  uh  doing the polar representation with magnitude and phase  but it looks like there s ways that one could potentially just work with the complex numbers and   and   and in principle get rid of the effects of the average complex spectrum 
 none 	but  
 none 	and  um  actually  regarding the phase normalization   so i did two experiments  and one is  
 none 	so  phases get added  modulo two pi  and   because you only know the phase of the complex number t  t  to a value modulo two pi  and so i thought at first  um  that  uh  what i should do is unwrap the phase because that will undo that 
 none 	um  but i actually got worse results doing that unwrapping using the simple phase unwrapper that s in matlab than i did not unwrapping at all 
 none 	hmm 
 none 	mm hmm 
 none 	yeah 
 none 	p  so 
 none 	and that s all i have to say 
 none 	hmm 
 none 	yeah  so i m   i m still hopeful that   that   i mean  we   we don t even know if the phase is something   the average phase is something that we do want to remove  i mean  maybe there s some deeper reason why it isn t the right thing to do  but  um  at least in principle it looks like there s   there s  uh  a couple potential ways to do it  one   one being to just work with the complex numbers  um  and  uh   in rectangular kind of coordinates  and the other is to  uh  do a taylor series  
 none 	well  so you work with the complex numbers and then when you get the spectrum   the average complex spectrum   um  actually divide it out  um  as opposed to taking the log and subtracting 
 none 	so then  um  um  you know  there might be some numerical issues  we don t really know that 
 none 	the other thing we talked a little bit about was taylor series expansion 
 none 	and  um  uh  actually i was talking to dick karp about it a little bit  and   and   and  since i got thinking about it  and   and  uh  so one thing is that y  you d have to do  i think  uh   we may have to do this on a whiteboard  but i think you have to be a little careful about scaling the numbers that you re taking   the complex numbers that you re taking the log of because the taylor expansion for it has  you know  a square and a cube  and   and so forth  and   and so if   if you have a   a number that is modulus  you know  uh  very different from one  
 none 	it should be right around one  if it s   cuz it s a expansion of log one   one minus epsilon or o  is   is one plus epsilon  or is it one plus     well  there s an epsilon squared over two and an epsilon cubed over three  and so forth  so if epsilon is bigger than one  then it diverges 
 none 	o_k 
 none 	oh 
 none 	so you have to do some scaling  but that s not a big deal cuz it s the log of   of k_ times a complex number  then you can just   that s the same as log of k_ plus log of the complex number 
 none 	oh 
 none 	o_k 
 none 	uh  so there s   converges  but 
 none 	hmm 
 none 	o_k  how about you  sunil 
 none 	so  um  i ve been  uh  implementing this  uh  wiener filtering for this aurora task 
 none 	and  uh 
 none 	i   i actually thought it was   it was doing fine when i tested it once  i  it s  like  using a small section of the code  and then i ran the whole recognition experiment with italian and i got  like  worse results than not using it 
 none 	then i  
 none 	so  i ve been trying to find where the problem came from  and then it looks like i have some problem in the way   there is some   some very silly bug somewhere  and  ugh 
 none 	i   i mean  i  uh  it actually   i  it actually made the whole thing worse  i was looking at the spectrograms that i got and it s  like   w  it s   it s very horrible  like  when i  
 none 	i   i missed the v  i m sorry  i was   i was distracted  i missed the very first sentence  so then  i m a little lost on the rest  what   what   what    
 none 	oh  i mean  
 none 	oh  yeah  i actually implemented the wiener f  f  fil  filtering as a module and then tested it out separately  and it   it   it gave  like   i just got the signal out and it   it was o_k 
 none 	yeah  i see 
 none 	oh  o_k 
 none 	so  i plugged it in somewhere and then   i mean  it s like i had to remove some part and then plugging it in somewhere  and then i   in that process i messed it up somewhere 
 none 	so 
 none 	o_k 
 none 	so  it was real 
 none 	i mean  i thought it was all fine and then i ran it  and i got something worse than not using it 
 none 	so  i was like   i m trying to find where the m  m  problem came  and it seems to be  like  somewhere   some silly stuff 
 none 	uh huh 
 none 	o_k 
 none 	and  um  the other thing  uh  was  uh  uh  
 none 	well  hynek showed up one   suddenly on one day and then i was t  talking wi 
 none 	right 
 none 	yeah  as   as he is wont to do  yeah 
 none 	uh  yeah  so i was actually   that day i was thinking about d  doing something about the wiener filtering  and then carlos matter of stuff  and then he showed up and then i told him  and then he gave me a whole bunch of filters   what carlos used for his  uh  uh  thesis and then that was something which came up  and then  um  
 none 	so  uh  i m actually  uh  thinking of using that also in this  uh 
 none 	w  wiener filtering because that is a m  modified wiener filtering approach  where instead of using the current frame  it uses adjacent frames also in designing the wiener filter 
 none 	so instead of designing our own new wiener filters  i may just use one of those carlos filters in   in this implementation and see whether it   it actually gives me something better than using just the current f  current frame  which is in a way  uh  something like the smoothing   the wiener filter   but   
 none 	mm hmm 
 none 	mm hmm 
 none 	s  so  i don t know  i was h  i m   i m   i m  like   that   so that is the next thing  once this   i   once i sort this pro  uh  problem out maybe i ll just go into that also 
 none 	and the   the other thing was about the subspace approach 
 none 	so  um 
 none 	i  like  plugged some groupings for computing this eigen  uh  uh  uh  s  values and eigenvectors  so just  
 none 	i just  some small block of things which i needed to put together for the subspace approach  and i m in the process of  like  building up that stuff 
 none 	and  um  uh   yeah 
 none 	i guess   yep  i guess that s it  and  uh  th  th  that s where i am right now 
 none 	so 
 none 	oh  how about you  carmen 
 none 	mmm  i m working with v_t_s 
 none 	um  i do several experiment with the spanish database first  only with v_t_s and nothing more  not v_a_d  no l_d_a  nothing more 
 search 	what   what is  v_t_s  again  
 none 	eh   vectorial taylor series  
 none 	new  
 none 	oh  yes  right  right 
 none 	to remove the noise too 
 none 	i think i ask you that every single meeting  don t i  i ask you that question every meeting 
 none 	what 
 none 	yeah  if   well  
 none 	so  that d be good from   for analysis  it s good to have some  uh  cases of the same utterance at different   different times  yeah 
 none 	yeah   what is v_t_s  
 none 	v_t_s  i m sor 
 none 	well  um  the question is that   well 
 none 	remove some noise but not too much 
 none 	and when we put the   m  m  the  em 
 none 	v_a_d  the result is better  and we put everything  the result is better  but it s not better than the result that we have without v_t_s 
 none 	no  no 
 none 	i see  so that given that you re using the v_a_d also  the effect of the v_t_s is not so far  
 none 	is not 
 none 	do you   how much of that do you think is due to just the particular implementation and how much you re adjusting it  or how much do you think is intrinsic to    
 none 	pfft  i don t know because  
 none 	hhh 
 none 	are you still using only the ten first frame for noise estimation or    
 none 	uh  i do the experiment using only the f  onl  eh  to use on  only one fair estimation of the noise 
 none 	or i   
 none 	yeah 
 none 	hmm 
 none 	and also i did some experiment  uh  doing  um  a lying estimation of the noise 
 none 	and  well  it s a little bit better but not   n 
 create_single_reminder 	maybe  you  have to  standardize this thing also  noise estimation   because all the thing that you are testing use a different  
 none 	mmm 
 none 	mmm 
 none 	they all need some   some noise   noise spectra but they use   every   all use a different one 
 none 	no  i do that two   t  did two time 
 none 	i have an idea 
 none 	if   if  uh  uh  y  you re right  i mean  each of these require this 
 none 	um  given that we re going to have for this test at least of   uh  boundaries  what if initially we start off by using known sections of nonspeech for the estimation 
 none 	mm hmm 
 none 	mm hmm 
 none 	right 
 none 	s  so  e  um  first place  i mean even if ultimately we wouldn t be given the boundaries  uh  this would be a good initial experiment to separate out the effects of things  i mean  how much is the poor   you know  relatively  uh  unhelpful result that you re getting in this or this or this is due to some inherent limitation to the method for these tasks and how much of it is just due to the fact that you re not accurately finding enough regions that   that are really n  noise 
 none 	yeah  mm hmm 
 none 	mmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	um 
 create_single_reminder 	so maybe if  you   tested it using that  you d have more reliable stretches of nonspeech to do the estimation from and see if that helps   
 none 	yeah  another thing is the  em   the codebook  the initial codebook 
 none 	that maybe  well  it s too clean and  
 none 	mm hmm 
 none 	cuz it s a   i don t know  the methods  
 none 	if you want  you c  i can say something about the method 
 none 	mm hmm 
 none 	yeah  in the  
 none 	because it s a little bit different of the other method 
 none 	well  we have  
 none 	if this   if this is the noise signal 
 none 	uh  in the log domain  we have something like this 
 none 	now  we have something like this 
 none 	and the idea of these methods is to   n  given a  um   how do you say 
 none 	mm  hmm 
 none 	i will read because it s better for my english 
 none 	i  i  given is the estimate of the p_d_f of the noise signal when we have a  um  a statistic of the clean speech and an statistic of the noisy speech 
 none 	and the clean speech   the statistic of the clean speech is from a codebook 
 none 	mmm  this is the idea 
 none 	well  like  this relation is not linear 
 none 	the methods propose to develop this in a vectorial taylor series approximation 
 none 	i  i m actually just confused about the equations you have up there  so  uh  the top equation is   is   is  
 none 	no  this in the   it s   this is the log domain  i   i must to say that 
 none 	which is   which is the log domain 
 none 	is the t_   is egual   is equal to  uh  log of  
 none 	and   but y_ is what  y_ of   the spectrum or    
 none 	uh  this   this is this and this is this 
 none 	no  no  the top y_ is what 
 none 	mm hmm 
 none 	is that power spectrum  no  is that power spectrum  is it    
 none 	uh  this is the noisy speech 
 none 	p  s  this  
 none 	yeah  i guess it s the power spectrum of noisy speech  yeah  and  
 none 	yeah  it s the power spectrum 
 none 	oh  o_k 
 none 	so that s uh  
 none 	this is the noisy   yeah  it s   of the value  
 none 	o_k 
 none 	yeah  o_k  so this   it s the magnitude squared or something  o_k  so you have power spectrum added there and down here you have   you   you put the   depends on t_   but   b  all of this is just   you just mean   you just mean the log of the   of the one up above 
 none 	yeah 
 none 	w  o 
 none 	yeah  it s the same 
 none 	yeah 
 none 	mm hmm 
 none 	and  uh  so that is
 none 	x_ times  uh  o 
 none 	yeah  maybe  
 none 	one   one plus n_ by x_ 
 none 	but  n 
 none 	well  y  we can expre  we can put this expression  
 none 	x_ times one plus  uh 
 none 	the  
 none 	n_   uh  n_   n_   n_ minus x_ 
 none 	yeah 
 none 	and then  uh   so that s log of x_ plus log of one plus  uh  
 none 	and the noise signal 
 none 	well 
 none 	is that right  log of  
 none 	one plus n_ by x_ 
 none 	well  mmm  
 none 	i actually don t see how you get that 
 none 	well  if we apply the log  we have e_ is n  uh  log  
 none 	uh 
 none 	mmm 
 none 	uh  and  
 none 	e_ is equal  oh  to log of
 none 	x_ plus n_ 
 none 	yeah 
 none 	and  well  uh  we can say that e_
 none 	and  log of  
 none 	is equal to log of  um  exponential of x_ plus exponential of n_ 
 none 	uh  
 none 	mm hmm 
 none 	no 
 none 	no 
 none 	that doesn t follow 
 none 	well  if e_ restricts  
 none 	well  this is   this is in the ti  the time domain  well  we have that  um  
 none 	it is y 
 none 	we have first that  for example  x_ is equal  uh   well 
 none 	this is the frequency domain and we can put u  that n  the log domain   log of x_ omega  but  well  in the time domain we have an exponential 
 none 	yeah 
 none 	no 
 none 	no 
 none 	oh  maybe it s i am   i m problem 
 none 	yeah  i mean  just never mind what they are  uh  it s just if x_ and n_ are variables  
 none 	right 
 none 	what is  uh    
 none 	the   the   the log of x_ plus n_ is not the same as the log of e_ to the x_ plus e_ to the n_ 
 none 	yeah  but this i 
 none 	well  i don t  
 none 	well  uh  maybe  
 none 	maybe we can take it off line  but i   i don t know 
 none 	i   i can do this incorrectly 
 none 	well  the expression that appear in the   in the paper  is  uh  
 none 	the log   the taylor series expansion for log one plus n_ by x_ is  
 none 	is x_  
 none 	is it the first order expansion  yeah  i guess  yeah  uh huh 
 none 	o_k  i  i 
 none 	yeah  the first one  yeah 
 none 	yeah 
 none 	o_k  yeah  cuz it doesn t just follow what s there  it has to be some  uh  taylor series  
 none 	y  yeah  if   if you take log x_ into log one plus n_ by x_  and then expand the log one plus n_ by x_ into taylor series  
 none 	yeah 
 none 	now  this is the   and then  
 none 	yeah  but the   the second expression that you put is the first order expansion of the nonlinear relation between  
 none 	not exactly 
 none 	no 
 none 	no  no  no  it s not the first space   well  we have   pfft  uh  em  
 none 	well  we can put that
 none 	x_ is equal   i_ is equal to log of  uh  mmm  
 none 	that doesn t follow 
 none 	well  we can put  uh  this 
 none 	mmm 
 none 	no 
 none 	that   i mean  that   the f  top one does not imply the second one 
 none 	the top 
 none 	because   cuz the log of a sum is not the same as th  i mean  as   yeah 
 none 	yeah  yeah  yeah  yeah  yeah  but we can   uh  we   we know that  for example  the log of
 none 	e_ plus b_ is equal to log of e_ plus log to b_  and we can say here  it i 
 none 	right 
 none 	right  so you could s 
 none 	what is that 
 none 	and we can  uh  put this inside 
 none 	yeah 
 none 	and then we can  uh  you know  
 none 	n  no  but  
 none 	yeah 
 none 	uh 
 none 	i don t see how you get the second expression from the top one 
 none 	the   i mean  just more generally here  if you say  log of  um  a_ plus b_   the log of   log of a_ plus b_ is not   or a_ plus b_ is not the  um  log of e_ to the a_ plus e_ to the b_ 
 none 	no  no  no  no  no  no  no  this not  no 
 none 	right  and that s what you seem to be saying 
 none 	no  it s not  but this is the same   oh 
 none 	right  cuz you   cuz you   up here you have the a_ plus b_  
 none 	no  i say if i apply log  i have  uh  log of e_ is equal to log of  uh   in this side  is equal to log of x_ plus n_ 
 none 	plus n_ 
 none 	right 
 none 	no  right  this is right 
 none 	right  and then how do you go from there to the    
 none 	and then if i apply exponential  to have here
 none 	look  o_k  so let s   i mean  c_ equals a_ plus b_  and then  
 none 	e_  
 none 	it s log o  of capital y_  yeah  right  capital y_ 
 none 	yeah 
 none 	x_  x_  this is x_  inside 
 none 	mm hmm 
 none 	we have this  no 
 none 	right  yeah  that one s right 
 none 	mm hmm 
 none 	one and  
 none 	s  uh  i  th  we can put here the set transformation 
 none 	oh 
 none 	i see 
 none 	no 
 none 	i see 
 none 	o_k  i understand now  alright  thanks 
 none 	yeah  in this case  well  we can put here a y_ 
 none 	o_k  so  yeah  it s just by definition that the individual   that the  uh   so  capital x_ is by definition the same as e_ to the little x_ because she s saying that the little x_ is   is the  uh   is the log 
 none 	alright 
 none 	now we can put this  no 
 none 	yeah 
 none 	and here we can multiply by x_ 
 none 	alright  i think these things are a lot clearer when you can use fonts   different fonts there so you know which is which  but i   i under  i understand what you mean now  o_k 
 none 	oh  yes 
 none 	yeah  yeah  that s true  that s true 
 none 	but this   this is correct  and now i can do it  uh   pfff 
 none 	sure 
 none 	i can put log of e_x plus log  
 none 	oh 
 none 	yes  i understand now 
 none 	and that s where it comes from  yeah 
 none 	and this is  
 none 	yeah  right 
 none 	right 
 none 	now it s correct 
 none 	right 
 none 	o_k  thanks 
 none 	well  the idea   well  we have fixed this equa 
 none 	o_k  so now once you get that   that one  then you   then you do a first  or second order  or something  taylor series expansion of this 
 none 	yeah  this is another linear relation that this   to develop this in vector s taylor series 
 none 	yeah  sure 
 none 	right 
 none 	mm hmm  and for that  well  the goal is to obtain  um   est  estimate a p_d_f for the noisy speech when we have a   a statistic for clean speech and for the noisy speech 
 none 	mmm 
 none 	and when w  the way to obtain the p_d_f for the noisy speech is   well  we know this statistic and we know the noisy st  well  we can apply first order of the vector st  taylor series of the   of the   of   well  the order that we want  increase the complexity of the problem  and then when we have a expression  uh  for the mean and variance of the noisy speech  we apply a technique of minimum mean square estimation to obtain the expected value of the clean speech given the   this statistic for the noisy speech   the statistic for clean speech and the statistic of the noisy speech 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	this only that 
 none 	but the idea is that   u 
 none 	and the   the model of clean speech is a codebook  right 
 none 	yeah  we have our codebook with different density gaussian 
 none 	mm hmm 
 none 	we can expre  we can put that the
 none 	p_d_f for the clean test  probability of the clean speech is equal to  
 none 	yeah 
 none 	mm hmm 
 none 	so  um  how   h  how much   in   in the work they reported  how much noisy speech did you need to get  uh  good enough statistics for the   to get this mapping 
 none 	i don t know exactly 
 none 	yeah 
 none 	i   i need to s  i don t know exactly 
 none 	yeah 
 none 	cuz i think what s certainly characteristic of a lot of the data in this test is that  um  you don t have   the   the training set may not be a   a great estimator for the noise in the test set  sometimes it is and sometimes it s not 
 none 	yeah  i   the clean speech   the codebook for clean speech  i am using timit 
 none 	and i have now  uh  sixty four
 none 	gaus  gaussian 
 none 	uh huh 
 none 	and what are you using for the noisy     y  y  doing that strictly  
 none 	of the noise   i estimate the noises wi  well  for the noises i only use one gaussian 
 none 	mm hmm 
 none 	and   and you   and you train it up entirely from  uh  nonspeech sections in the test 
 none 	hmm 
 none 	uh  yes  the first experiment that i do it is solely to calculate the  mmm   well  this value   uh  the compensation of the dictionary o  one time using the   the noise at the f  beginning of the sentence  this is the first experiment  and i fix this for all the   all the sentences 
 none 	yeah 
 none 	mm hmm 
 none 	yeah 
 none 	uh  because   well  the v_t_s methods  
 none 	in fact the first thing that i do is to   to obtain  uh  an expression for e_   probability e  expression of   of e_  that mean that the v_t_s   mmm  with the v_t_s we obtain  uh  
 none 	well  we   we obtain the means for each gaussian and the variance 
 none 	mm hmm 
 none 	this is one  eh  this is the composition of the dictionary 
 none 	mm hmm 
 none 	this one thing  and the other thing that this   with these methods is to  uh  obtain   to calculate this value 
 none 	mm hmm 
 none 	because we can write  
 none 	uh  we can write that the estimation of the clean speech is equal at an expected value of the clean speech conditional to  uh  the noise signal   the probability f  of the   the statistic of the clean speech and the statistic of the noise 
 none 	mm hmm 
 none 	mm hmm 
 none 	this is the methods that say that we re going obtain this 
 none 	mm hmm 
 none 	and we can put that this is equal to the estimated value of e_ minus a function that conditional to e_ to the t_   to the noise signal  well  this is   this function is the the term   after develop this  the term that we   we take 
 none 	give p_x and  uh  p_ the noise 
 none 	x_ k_ c_ noise 
 none 	mmm 
 none 	and i can put that this is equal to the noise signal minus  
 none 	well  i put before this name  uh  
 none 	and i can calculate this 
 none 	what is the first variable in that probability 
 none 	uh  this is the gaussian  v 
 none 	no  no  i m sorry  in   in the one you pointed at  what s that variable 
 none 	uh  this is the   like this  but conditional  no  it s condition  it s not exactly this  it s modify 
 none 	weak  so probably it   it would do that 
 none 	it s one mixture of the model  right 
 none 	uh  if we have clean speech   we have the dictionary for the clean speech  we have a probability f  of   our   our weight for each gaussian 
 none 	no   and now  this weight is different now because it s conditional  and this i need to   to calcu  i know this and i know this because this is from the dictionary that you have 
 none 	o_k 
 none 	yes 
 none 	uh huh 
 none 	uh huh 
 none 	i need to calculate this  and for calculate this 
 none 	yes 
 none 	i have an   i   i can develop an expression that is
 none 	it s overlapping 
 none 	that 
 none 	i can calculate   i can   i calculated this value  uh  with the statistic of the noisy speech that i calculated before with the v_t_s approximation 
 none 	mm hmm 
 none 	and   well  normalizing 
 none 	and i know everything 
 none 	uh  with the  nnn   when i develop this in s  taylor   taylor series  i can t  um  calculate the mean and the variance of the   for each of the gaussian of the dictionary for the noisy speech 
 none 	now 
 none 	and this is fixed 
 none 	mm hmm 
 none 	if i never do an estimat  a newer estimation of the noise  this mean as   mean and the variance are fixed 
 none 	mm hmm 
 none 	and for each s  uh  frame of the speech the only thing that i need to do is to calculate this in order to calculate the estimation of the clean speech given our noisy speech 
 none 	so  i m   i m not following this perfectly but  um  i  
 none 	are you saying that all of these estimates are done using  um  estimates of the probability density for the noise that are calculated only from the first ten frames 
 none 	yeah 
 none 	and never change throughout anything else 
 none 	never cha  this is one of the approximations that i am doing 
 none 	per   per   per utterance  or per    
 none 	per utterance  yes  per utterance  yes  and th 
 none 	per utterance  o_k 
 none 	so it s done   it s done new for each new utterance  so this changes the whole mapping for every utterance 
 none 	yeah  it s not  
 none 	yeah 
 none 	yeah  it s fixed  the dictionary  and the other estimation is when i do the uh on line estimation  i change the means and variance of th  for the noisy speech each time that i detect noise 
 none 	o_k 
 none 	o_k 
 none 	yeah 
 none 	mm hmm 
 none 	i do it uh again this develop 
 none 	estimate the new mean and the variance of the noisy speech  and with th  with this new s  new mean and variance i estimate again this 
 none 	so you estimated  uh  f  completely forgetting what you had before 
 none 	um  no  no  no  it s not completely   no  it s   i am doing something like an adaptation of the noise 
 none 	uh  or is there some adaptation 
 none 	o_k 
 none 	now do we know  either from their experience or from yours  that  uh  just having  uh  two parameters  the   the mean and variance  is enough 
 none 	yeah  i mean  i know you don t have a lot of data to estimate with  but   but  uh  um  
 none 	i estimate mean and variance for each one of the gaussian of the codebook 
 none 	no  i m talking about the noise 
 none 	oh  um  well  only one   i am only   using only one  i don t know i 
 none 	there s only one gaussian 
 none 	right 
 none 	and you   and   and it s  uh  uh   right  it s only   it s only one  
 none 	wait a minute  this is   what s the dimensionality of the gaussian  this is  
 none 	uh  it s in   after the mel filter bank 
 none 	so this is twenty or something  twenty 
 none 	twenty three 
 none 	so it s   yeah  so it s actually forty numbers that you re getting 
 none 	yeah  maybe   maybe you don t have a  
 search 	uh  the  original paper  say that  only one gaussian for the noise   
 none 	well  yeah  but  i mean  no   no paper is   is a bible  you know  this is   this is  uh  
 none 	yeah  maybe isn t the right thing 
 none 	yeah  yeah  yeah 
 none 	the question is  um  whether it would be helpful  i  particularly if you used   if you had more  
 none 	so  suppose you did   this is almost cheating  it certainly isn t real time  but if y  suppose you use the real boundaries that   that you were   in fact were given by the v_a_d and so forth  th  th   or i   i guess we re gonna be given even better boundaries than that 
 none 	and you look   you take all o  all of the nonspeech components in an utterance  so you have a fair amount 
 none 	do you benefit from having a better model for the noise  that would be another question 
 none 	maybe 
 none 	so first question would be to what extent i  are the errors that you re still seeing based on the fact that you have poor boundaries for the  uh  uh  nonspeech 
 none 	and the second question might be  given that you have good boundaries  could you do better if you used more parameters to characterize the noise 
 none 	um 
 none 	also another question might be  
 none 	um  they are doing   they re using first term only of the vector taylor series 
 none 	yeah 
 none 	um  if you do a second term does it get too complicated cuz of the nonlinearity 
 none 	yeah  it s quite complicated 
 none 	yeah  o_k 
 none 	no  i won t ask the next question then 
 none 	oh  it s   it s the   for me it s the first time that i am working with v_t_s  uh  
 none 	yeah  no  it s interesting  uh  w  we haven t had anybody work with it before  so it s interesting to get your   get your feedback about it 
 none 	it s another type of approximation because i  because it s a statistic   statistic approximation to remove the noise 
 none 	i don t know 
 none 	right 
 none 	great 
 none 	o_k  well  i guess we re about done  um  so some of the digit forms don t have digits 
 none 	uh  we ran out there were some blanks in there  so not everybody will be reading digits  but  um 
 none 	i guess you ve got some  right  morgan 
 none 	i have some 
 none 	so  why don t you go ahead and start  and i think it s just us down here at this end that have them  so 
 none 	um
 none 	s 
 none 	uh  o_k 
 none 	s  so  we switch off with this or n   
 none 	whenever you re ready 
 none 	uh  leave it on  uh  and the  
 none 	no  o_k 
 none 	they prefer to have them on just so that they re continuing to get the distant  uh  information 
 none 	yeah 
 none 	o_k  o_k 
 none 	transcript l_ dash one six nine 
 none 	three nine three  zero nine five  seven nine eight 
 none 	two seven  six zero  five six  five eight  six seven 
 none 	six one one  one eight  two four s  two six 
 none 	one nine zero zero  two  seven eight three 
 none 	eight eight one  two two six  seven four one nine 
 none 	seven nine four nine s  e  e 
 none 	eight five seven eight  seven nine zero nine 
 none 	two  three seven five  four one  seven six one  two 
 none 	three seven six two  six three six seven  two nine four two 
 none 	transcript l_ dash one sixty seven 
 none 	seven five six zero  five  three seven three 
 none 	one four seven  four four  nine two seven eight 
 none 	one one  six seven  three eight  eight five  five seven 
 none 	eight  one six four  six four  eight two o_  three 
 none 	three seven seven  five  two six three 
 none 	two  eight five seven  nine five  six seven two  two 
 none 	nine o_  one eight  three two  two six  two three 
 none 	three two  five two  seven seven  nine four  nine six 
 none 	transcript l_ dash one six eight 
 none 	seven nine  nine nine  nine two  four eight  eight zero 
 none 	six nine eight  seven zero  one eight four eight 
 none 	zero three one  seven eight four  one seven eight two 
 none 	five  two three two  six five  nine eight three  six 
 none 	six five four zero  four one five zero  five eight eight two 
 none 	zero  three five seven  two six  zero six five  nine 
 none 	seven six two  eight one  nine five nine eight 
 none 	one one  four two  zero eight  six seven  nine eight 
 none 	transcript l_ dash one seven four 
 none 	four nine one one  eight  four seven nine 
 none 	two four one two  seven  eight nine two 
 none 	five one six six  three six seven seven  three two eight nine 
 none 	seven six two  seven nine  three six one zero 
 none 	five nine three five  seven  five six zero 
 none 	four eight eight  eight eight two  nine eight eight 
 none 	five nine  six seven  two five  zero six  nine four 
 none 	eight two  two zero  one nine  two six  nine one 
 none 	o_k 
 none 	o_k  s 
 none 	and we re on 
 none 	o_k  might wanna close the door so that   uh  stephane will  
 none 	i ll get it 
 none 	yeah
 none 	hey dave 
 none 	could you go ahead and turn on  uh  stephane s  
 none 	mm hmm 
 none 	so that s the virtual stephane over there 
 none 	o_k 
 none 	do you use a p_c for recording  or  
 none 	uh  yeah  a linux box  yeah  it s got  uh  like sixteen channels going into it 
 none 	uh huh 
 none 	uh huh 
 none 	the quality is quite good  or    
 none 	mm hmm 
 none 	yeah  so far  it s been pretty good 
 none 	mm hmm 
 none 	yeah 
 none 	so  uh  yeah   the suggestion was to have these guys start to  
 none 	o_k 
 none 	why don t you go ahead  dave 
 none 	o_k  um  so  yeah  the   this past week i ve been main  mainly occupied with  um  getting some results  u  from the s_r_i system trained on this short hub five training set for the mean subtraction method  and  um 
 none 	i ran some tests last night  but  um  c  the results are suspicious  um  it s  um  cuz they re   the baseline results are worse than  um  andreas   than results andreas got previously  and it could have something to do with  um  
 none 	that s on digits 
 none 	that s on digits  it c  it   it could h  it could have something to do with  um  downsampling  that s   that s worth looking into 
 none 	hmm 
 none 	um  d  and  um  ap  ap  apart from that  i guess the   the main thing i have t  ta  i have to talk is  um  where i m planning to go over the next week  um 
 none 	so i ve been working on integrating this mean subtraction approach into the smartkom system 
 none 	and there s this question of  well  so  um  in my tests before with h_t_k i found it worked   it worked the best with about twelve seconds of data used to estimate the mean  but  we ll often have less in the smartkom system  um 
 none 	so i think we ll use as much data as we have at a particular time  and we ll   we ll concatenate utterances together  um  to get as much data as we possibly can from the user  but  um  there s a question of how to set up the models  so um  we could train the models  if we think twelve seconds is ideal we could train the models using twelve seconds to calculate the mean  to mean subtract the training data  or we could  um  use some other amount  so   like i did an experiment where i  um  was using six seconds in test  um  but  for   i tried twelve seconds in train  and i tried  um  um  the same in train   i m a  i tried six seconds in train  and six seconds in train was about point three percent better 
 none 	um  and   um  it s not clear to me yet whether that s something significant 
 none 	so i wanna do some tests and  um  actually make some plots of  um   for a particular amount of data and test what happens if you vary the amount of data in train 
 none 	mm hmm 
 none 	uh  guenter  i don t know if you t  followed this stuff but this is  uh  a uh  uh  long term   long term window f_f_ts 
 none 	yeah  we   we spoke about it already  yeah 
 none 	yeah  yeah  he   you talked about it  oh  o_k  so you know what he s doing  alright 
 none 	y  s  so i was   i actually ran the experiments mostly and i   i was   i was hoping to have the plots with me today  i just didn t get to it  but  um   yeah  i wou  i would be curious about people s feedback on this cuz i m  
 none 	i p  i think there are some
 none 	i think it s   it s kind of like a   a bit of a tricky engineering problem  i m trying to figure out what s the optimal way to set this up  so  um  i ll try to make the plots and then put some postscript up on my   on my web page 
 none 	and i ll mention it in my status report if people wanna take a look 
 none 	you could clarify something for me  you re saying point three percent  you take a point three percent hit  when the training and testing links are   don t match or something  is that what it is  or    
 none 	hello 
 none 	w  well  it c 
 none 	i   i don t think it   it s just for any mismatch you take a hit  i  in some cases it might be u  better to have a mismatch  like i think i saw something like   like if you only have two seconds in test  or  um  maybe it was something like four seconds  you actually do a little better if you  um  train on six seconds than if you train on four seconds  um  but the case  uh   with the point three percent hit was using six seconds in test  um  comparing train on twelve seconds versus train on six seconds 
 none 	yeah 
 none 	yeah 
 none 	right 
 none 	and which was worse 
 none 	the train on twelve seconds 
 none 	o_k  but point three percent  uh  w  from what to what 
 none 	that s point three percent  
 none 	on   the   the   the accuracies w  went from   it was something vaguely like ninety five point six accuracy  um  improved to ninety five point nine wh  when i  
 none 	so four point four to four point one 
 none 	o_k 
 none 	so   yeah  so about a   about an eight percent  uh  seven or eight percent relative 
 none 	o_k 
 none 	uh 
 none 	yeah  well  i think in a p  you know  if   if you were going for an evaluation system you d care  but if you were doing a live system that people were actually using nobody would notice  it s   uh  i think the thing is to get something that s practical  that   that you could really use 
 none 	huh  that s   that s interesting  alright  the e  uh  i see your point  i guess i was thinking of it as  um  an interesting research problem 
 none 	yeah 
 none 	the   how to g  i was thinking that for the a_s_r_u paper we could have a section saying   for smartkom  we   we d  in   we tried this approach in  uh  interactive system   which i don t think has been done before 
 none 	mm hmm 
 none 	mm hmm 
 none 	and   and then there was two research questions from that  and one is the k  does it still work if you just use the past history 
 none 	mm hmm 
 none 	alright  and the other was this question of  um what i was just talking about now  so i guess that s why i thought it was interesting 
 none 	i mean  a short time f_f_t   short time cepstrum calculation  uh  mean   u  mean calculation work that people have in commercial systems  they do this all the time  they   the   they calculate it from previous utterances and then use it  you know  but   but  uh  as you say  there hasn t been that much with this long   long time  uh  spectra work  uh 
 none 	yeah  um 
 none 	oh  o  oh  o_k   so that s   that s   that s standard  um  
 none 	yeah  pretty common  yeah 
 none 	o_k 
 none 	um  but  u  uh  yes  no  it is interesting  and the other thing is  i mean  there s two sides to these really small  uh  gradations in performance  um 
 none 	i mean  on the one hand in a practical system if something is  uh  four point four percent error  four point one percent error  people won t really tell   be able to tell the difference 
 none 	on the other hand  when you re doing  uh  research  you may  eh   you might find that the way that you build up a change from a ninety five percent accurate system to a ninety eight percent accurate system is through ten or twelve little things that you do that each are point three percent  so   so the   they   they   it s   i don t mean to say that they re   they re irrelevant 
 none 	uh  they are relevant  but  um  i  for a demo  you won t see it 
 none 	mm hmm 
 none 	right  o_k 
 none 	yeah 
 none 	and  um 
 none 	let s   l  let s see  um 
 none 	o_k  and then there s um  another thing i wanna start looking at  um  wi  is  um  the choice of the analysis window length  so i ve just been using two seconds just because that s what carlos did before  uh  i wrote to him asking about he chose the two seconds 
 none 	and it seemed like he chose it a bit informally  so  um  with the   with the h_t_k set up i should be able to do some experiments  on just varying that length  say between one and three seconds  in a few different reverberation conditions  um  say this room and also a few of the artificial impulse responses we have for reverberation  just  um  making some plots and seeing how they look 
 none 	and  um  so  with the   the sampling rate i was using  one second or two seconds or four seconds is at a power of two um  number of samples and  um  i ll   i ll jus  f  for the ones in between i guess i ll just zero pad 
 none 	mm hmm 
 none 	i guess one thing that might also be an issue  uh  cuz part of what you re doing is you re getting a   a spectrum over a bunch of different kinds of speech sounds 
 none 	um  and so it might matter how fast someone was talking for instance 
 none 	oh 
 none 	you know  if you   if   if   if there s a lot of phones in one second maybe you ll get a   a really good sampling of all these different things  and   and  uh  on the other hand if someone s talking slowly maybe you d need more  so  
 none 	huh 
 none 	i don t know if you have some samples of faster or slower speech but it might make a difference  i don t know 
 none 	uh  yeah  i don t   i don t think the t_i digits data that i have  um  i  is   would be appropriate for that 
 none 	yeah  probably not  yeah 
 none 	but what do you   what about if i w  i fed it through some kind of  um  speech processing algorithm that changed the speech rate 
 none 	yeah  but then you ll have the degradation of   of  uh  whatever you do uh  added onto that  but maybe  yeah  maybe if you get something that sounds   that   that s   does a pretty job at that 
 none 	yeah  well  uh  just if you think it s worth looking into  i mean  it   it is getting a little away from reverberation 
 none 	you could imagine that 
 none 	um  yeah  it s just that you re making a choice   uh  i was thinking more from the system aspect  if you re making a choice for smartkom  that   that   that it might be that it s   it c  the optimal number could be different  depending on  
 none 	yeah 
 none 	right 
 none 	could be  i don t know 
 find_calendar_entry 	and   and th  the third thing  um  uh  is  um   barry  explained  l_d_a filtering  to me  yesterday   
 search 	and so  um   mike shire  in his  thesis  um  did a    a series of experiments  um  training l_d_a filters in d  on different conditions    and you were interested in having me repeat this for   for this mean subtraction approach  is   is that right  or for these long analysis windows  i guess  is the right way to put it 
 none 	i guess  the   the   the issue i was   the general issue i was bringing up was that if you re   have a moving   moving window  uh  a wa  a   a set of weights times things that  uh  move along  shift along in time  that you have in fact a linear time invariant filter 
 none 	and you just happened to have picked a particular one by setting all the weights to be equal 
 none 	and so the issue is what are some other filters that you could use  uh  in that sense of  filter   and  um  as i was saying  i think the simplest thing to do is not to train anything  but just to do some sort of  uh  uh  hamming or hanning  uh  kind of window  kind of thing  just sort of to de emphasize the jarring  so i think that would sort of be the first thing to do 
 none 	mm hmm 
 none 	right  mm hmm 
 none 	but then  yeah  the l_d_a i  uh  is interesting because it would sort of say well  suppose you actually trained this up to do the best you could by some criterion  what would the filter look like then 
 none 	uh huh 
 none 	uh  and  um  that s sort of what we re doing in this aur  aurora stuff  and  uh  it s still not clear to me in the long run whether the best thing to do would be to do that or to have some stylized version of the filter that looks like these things you ve trained up  because you always have the problem that it s trained up for one condition and it isn t quite right for another  so  uh   that s   that s why   that s why rasta filter has actually ended up lasting a long time  people still using it quite a bit  because y  you don t change it  so doesn t get any worse 
 none 	uh 
 none 	huh  o  o_k  so  um  a  actually i was just thinking about what i was asking about earlier  wi  which is about having less than say twelve seconds in the smartkom system to do the mean subtraction  you said in systems where you use cepstral mean subtraction  they concatenate utterances and  do you know how they address this issue of  um  testing versus training  can  
 none 	anyway 
 none 	i think what they do is they do it always on line  i mean  that you just take what you have from the past  that you calculate the mean of this and subtract the mean 
 none 	go ahead 
 none 	o_k  um  
 none 	and then you can   yeah  you   you can increase your window whi  while you get   while you are getting more samples 
 none 	o_k  um  and  um  so   so in tha  in that case  wh  what do they do when they re t  um  performing the cepstral mean subtraction on the training data 
 none 	so   because you d have hours and hours of training data  so do they cut it off and start over 
 none 	at intervals  or    
 none 	so do you have   uh  you   you mean you have files which are hours of hours long  or    
 none 	oh  well  no  i guess not  but  
 none 	yeah  i mean  usually you have in the training set you have similar conditions  i mean  file lengths are  i guess the same order or in the same size as for test data  or aren t they 
 none 	o_k  but it s   o_k  so if someone s interacting with the system  though  uh  morgan   uh  morgan said that you would tend to  um  chain utterances together um  r 
 none 	well  i think what i was s  i thought what i was saying was that  um  at any given point you are gonna start off with what you had from before 
 none 	oh 
 none 	from   and so if you re splitting things up into utterances   so  for instance  in a dialogue system  where you re gonna be asking  uh  you know  th  for some information  there s some initial th  something  and  you know  the first time out you   you might have some general average  but you   you d  you don t have very much information yet 
 none 	but at   after they ve given one utterance you ve got something  you can compute your mean cepstra from that  and then can use it for the next thing that they say  uh  so that  you know  the performance should be better that second time 
 none 	mm hmm 
 none 	um  and i think the heuristics of exactly how people handle that and how they handle their training
 none 	i m sure vary from place to place  but i think the   ideally  it seems to me anyway  that you   you would wanna do the same thing in training as you do in test 
 none 	but that s   that s just  uh  a prejudice  and i think anybody working on this with some particular task would experiment 
 none 	right 
 none 	i g  i guess the question i had was  um  amount of data e  u  was the amount of data that you d give it to  um update this estimate  because say you   if you have say five thousand utterances in your training set  um  and you   you keep the mean from the last utterance  by the time it gets to the five thousandth utterance  
 none 	no  but those are all different people with different   i mean  i  in y 
 none 	so for instance  in   in the   in a telephone task  these are different phone calls  so you don t wanna chain it together from a   from a different phone call 
 none 	o_k  so   so   so they would   g  s 
 none 	so it s within speaker  within phone call  if it s a dialogue system  it s within whatever this characteristic you re trying to get rid of is expected to be consistent over  right 
 none 	yeah 
 none 	hmm 
 none 	r  and it   right  o_k  so you d   you   and so in training you would start over at   at every new phone call or at every new speaker  yeah  o_k 
 none 	yeah 
 none 	yeah  now  you know  maybe you d use something from the others just because at the beginning of a call you don t know anything  and so you might have some kind of general thing that s your best guess to start with  but  
 none 	so  s  i   i   you know  a lot of these things are proprietary so we re doing a little bit of guesswork here  i mean  what do comp  what do people do who really face these problems in the field  well  they have companies and they don t tell other people exactly what they do  but   but i mean  when you   the   the hints that you get from what they   when they talk about it are that they do   they all do something like this 
 none 	r  right 
 none 	right  o_k  i see  bec  because i   so this smartkom task first off  it s this t_v and movie information system  and  
 none 	yeah  but you might have somebody who s using it and then later you might have somebody else who s using it  and so you d wanna set some   yeah 
 none 	yeah 
 none 	yeah 
 none 	right  right  i   i see  i was   i was about to say  so if   if you ask it  what   what movies are on t_v tonight    if i look at my wristwatch when i say that it s about two seconds  the way i currently have the mean subtraction  um  set up  the   the analysis window is two seconds  so what you just said  about what do you start with  raises a question of what do i start with then  i guess it   because  
 none 	yeah 
 none 	yeah 
 none 	mm hmm 
 none 	well  w  o_k  so in that situation  though  th  maybe what s a little different there  is i think you re talking about   there s only one   it   it   it also depends   we re getting a little off track here  r  but   but   but  
 none 	oh  right 
 none 	uh  there s been some discussion about whether the work we re doing in that project is gonna be for the kiosk or for the mobile or for both  and i think for this kind of discussion it matters 
 none 	if it s in the kiosk  then the physical situation is the same 
 none 	it s gonna   you know  the exact interaction of the microphone s gonna differ depending on the person and so forth  but at least the basic acoustics are gonna be the same 
 none 	so f  if it s really in one kiosk  then i think that you could just chain together and   and you know  as much   as much speech as possible to   because what you re really trying to get at is the   is the reverberation characteristic 
 none 	yeah 
 none 	but in   in the case of the mobile  uh  presumably the acoustic s changing all over the place 
 none 	right 
 none 	and in that case you probably don t wanna have it be endless because you wanna have some sort of   it s   it s not a question of how long do you think it s   you can get an approximation to a stationary something  given that it s not really stationary  so 
 none 	right 
 none 	hmm 
 none 	right 
 none 	and i   i g  i guess i s  just started thinking of another question  which is  for   for the very first frame  w  what   what do i do if i m   if i take   if i use that frame to calculate the mean  then i m just gonna get n  nothing 
 none 	mm hmm 
 none 	right 
 none 	um  so i should probably have some kind of default mean for the first f  couple of frames  o_k 
 none 	yeah 
 none 	yeah 
 none 	yeah  or subtract nothing  i mean  it s  
 none 	or subtract nothing  and   and that s   that s   i guess that s something that s p  people have figured out how to deal with in cepstral mean subtraction as well 
 none 	yeah  yeah 
 none 	yeah  people do something  they   they  uh  they have some  um  uh  in   in cepstral mean subtraction  for short term window   analysis windows  as is usually done  you re trying to get rid of some very general characteristic  and so  uh  if you have any other information about what a general kind of characteristic would be  then you   you can do it there 
 none 	you can also   you can also reflect the data 
 none 	so you take  uh   you know  i m not sure how many frames you need  but you take that many from the front and flip it around to   a  as the negative value  so you can always  
 none 	uh huh 
 none 	yeah  that s  
 none 	yeah 
 none 	the other thing is that   and   and  
 none 	i   i remember b_b_ n doing this  is that if you have a multi pass system  um  if the first pass ta  it takes most of the computation  the second and the third pass could be very  very quick  just looking at a relatively small n  small  uh  space of hypotheses 
 none 	mmm  
 none 	uh huh 
 none 	then you can do your first pass without any subtraction at all 
 none 	oh 
 none 	and then your second pass  uh  uh  eliminates those   most of those hypotheses by  uh   by having an improved   improved version o  of the analysis  so 
 none 	o_k  
 none 	o_k 
 none 	o_k  so that was all i had  for now 
 none 	yeah 
 none 	do you wanna go  barry 
 none 	yeah  o_k  um  so for the past  uh  week an  or two 
 none 	i ve been just writing my  uh  formal thesis proposal 
 none 	um  so i m taking this qualifier exam that s coming up in two weeks  and i   i finish writing a proposal and submit it to the committee  um 
 none 	and uh  should i   should i explain  uh  more about what   what i m proposing to do  and s  and stuff 
 none 	yes  briefly 
 none 	yeah briefly 
 none 	o_k 
 none 	um  so briefly  i m proposing to do a n  a new p  approach to speech recognition using um  a combination of  uh  multi band ideas and ideas  um  about the uh  acoustic phonec  phonetic approach to speech recognition 
 none 	um  so i will be using these graphical models that   um  that implement the multi band approach to recognize a set of intermediate categories that might involve  uh  things like phonetic features or other   other f  feature things that are more closely related to the acoustic signal itself 
 none 	um  and the hope in all of this is that by going multi band and by going into these  um intermediate classifications  that we can get a system that s more robust to   to unseen noises  and situations like that  um  and so  some of the research issues involved in this are  um  one  what kind of intermediate categories do we need to classify 
 none 	um  another one is um  what   what other types of structures in these multi band graphical models should we consider in order to um  combine evidence from the sub bands 
 none 	and  uh  the third one is how do we   how do we merge all the  uh  information from the individual uh  multi band classifiers to come up with word   word recognition or   or phone recognition things 
 none 	um  so basically that s   that s what i ve been doing  and 
 none 	so you ve got two weeks  huh 
 none 	i got two weeks to brush up on d  um  presentation stuff and  um 
 none 	oh  i thought you were finishing your thesis in two weeks 
 none 	but 
 none 	oh  that too 
 none 	yeah 
 none 	yeah 
 none 	are you gonna do any dry runs for your thing  or are you just gonna  
 none 	yes  yes  i  um   i m   i m gonna do some  would you be interested 
 none 	sure 
 none 	to help out 
 none 	sure 
 none 	o_k  thanks 
 none 	yeah 
 none 	is that it  hhh 
 none 	that s it 
 none 	o_k  uh  hhh  let s see  so we ve got forty minutes left  and it seems like there s a lot of material  an  any suggestions about where we   where we should go next 
 none 	mmm    
 none 	uh 
 none 	do you wanna go  sunil  maybe we ll just start with you 
 none 	yeah  but i actually stuck most of this in our m  last meeting with guenter 
 none 	um  but i ll just  
 none 	um  so the last week  uh  i showed some results with only speechdat car which was like some fifty six percent 
 none 	and  uh  i didn t h  i mean  i   i found that the results   i mean  i wasn t getting that r  results on the t_i digit  so i was like looking into  why  what is wrong with the t_i digits    why   why i was not getting it  and i found that  the noise estimation is a reason for the t_i digits to perform worse than the baseline 
 none 	so  uh  i actually  picked th 
 none 	i mean  the first thing i did was i just scaled the noise estimate by a factor which is less than one to see if that   because i found there are a lot of zeros in the spectrogram for the t_i digits when i used this approach  so the first thing i did was i just scaled the noise estimate  and i found  
 none 	so the   the results that i ve shown here are the complete results using the new  
 none 	well  the n  the new technique is nothing but the noise estimate scaled by a factor of point five 
 none 	so it s just an ad hoc   i mean  some intermediate result  because it s not optimized for anything 
 none 	so the results   the trend   the only trend i could see from those results was like the   the p  the current noise estimation or the  uh  noise composition scheme is working good for like the car noise type of thing  because i ve   the only   only   p  very good result in the t_i digits is the noise   car noise condition for their test a_   which is like the best i could see that uh  for any non stationary noise like  babble  or  subway  or any    street   some  restaurant  noise  it s like   it s not performing w  very well 
 none 	so  the   so that   that s the first thing i c  uh  i could make out from this stuff  and  
 none 	yeah  i think what is important to see is that there is a big difference between the training modes 
 none 	uh huh  if you have clean training  you get also a fifty percent improvement 
 none 	yeah 
 none 	yeah 
 none 	but if you have muddy condition training you get only twenty percent 
 none 	yeah 
 none 	yeah 
 none 	mm hmm 
 none 	mm hmm 
 none 	uh  and in that twenty percent  it s very inconsistent across different noise conditions  so i have like a forty five percent for  car noise  and then there s a minus five percent for the  babble   and there s this thirty three for the  station  
 none 	mmm 
 none 	mmm 
 none 	and so it s   it s not   it s not actually very consistent across  so 
 none 	the only correlation between the speechdat car and this performance is the c  stationarity of the noise that is there in these conditions and the speechdat car 
 none 	mm hmm 
 none 	and  uh   so   so the overall result is like in the last page  which is like forty seven  which is still very imbalanced because there are like fifty six percent on the speechdat car and thirty five percent on the t_i digits 
 none 	and   uh  ps  the fifty six percent is like comparable to what the french telecom gets  but the thirty five percent is way off 
 none 	i m sort of confused but   this   i m looking on the second page  and it says
 none 	oh  yep 
 none 	 fifty percent    looking in the lower right hand corner   fifty percent relative performance  
 none 	for the clean training  u 
 none 	is that   is that fifty percent improvement 
 none 	and if you   if you look  
 none 	yeah 
 none 	yeah 
 none 	for   that s for the clean training and the noisy testing for the t_i digits 
 none 	so it s improvement over the baseline mel cepstrum 
 none 	yeah  yeah 
 none 	but the baseline mel cepstrum under those training doesn t do as well
 none 	i   i m   i m trying to understand why it s   it s eighty percent   that s an accuracy number  i guess  right 
 none 	yeah  yeah  yeah 
 none 	so that s not as good as the one up above 
 none 	no 
 none 	but the fifty is better than the one up above  so i m confused 
 none 	yeah 
 none 	uh  actually the noise compensation whatever  uh  we are put in it works very well for the high mismatch condition 
 none 	i mean  it s consistent in the speechdat car  and in the clean training also it gives it   but this fifty percent is   is that the   the high mismatch performance   equivalent to the high mismatch performance in the speech 
 none 	so n  s  so since the high mismatch performance is much worse to begin with  it s easier to get a better relative improvement 
 none 	yeah 
 none 	yeah  i do  yeah  yeah  so by putting this noise  
 none 	yeah 
 none 	yeah  if we look at the figures on the right  we see that the reference system is very bad 
 none 	oh 
 none 	yeah 
 none 	the reference drops like a very fast  
 none 	oh  oh  oh  oh  oh  oh  i see 
 none 	like for clean   clean training condition 
 none 	yeah 
 none 	i see 
 none 	nnn 
 none 	this is   this is t_i digits we re looking at  this whole page is t_i digits or this is    
 none 	yeah 
 none 	yeah 
 none 	oh  
 none 	oh  yeah  it s not written anywhere  yeah  it s t_i digits  the first r  spreadsheet is t_i digits 
 none 	hmm 
 none 	mmm  how does clean training do for the  uh   car  stuff  
 none 	the  car   oh  still   it still  uh   that   that s still consistent  i mean  i get the best performance in the case of  car   which is the third column in the a_ condition 
 none 	no  i mean  this is added noise  i mean  this is t_i digits  i m sorry  i meant   in   in the   in the  uh  multi language  uh  uh  finnish and  
 none 	uh  
 none 	this is next   next page  hmm 
 none 	that s the next   next spreadsheet  is  
 none 	so that is the performance for italian  finnish and spanish 
 none 	 training condition   
 none 	oh  right  so  clean  corresponds to  high mismatch  
 none 	yeah 
 none 	and  increase  
 none 	that s increase e 
 none 	improvement 
 none 	improvement  that s    percentage increase  is the percentage improvement over the baseline  so that s  
 none 	yeah 
 none 	it s   it s a  
 none 	which means decrease in word error rate 
 none 	yeah 
 none 	o_k  so  percentage increase  means decrease  o_k 
 none 	yeah  yeah 
 find_calendar_entry 	yeah   the   the w  there was a very long discussion about this on   on the   on the  uh   amsterdam   meeting   
 none 	yeah 
 none 	how to   how to calculate it then 
 none 	yeah  there s   there s a  
 none 	i   i   i guess you are using finally this   the scheme which they  
 none 	which is there in the spreadsheet  i m not changing anything in there 
 none 	o_k 
 none 	mmm 
 none 	alright 
 none 	so  uh  yeah  so all the hi  h_m_ numbers are w  very good  in the sense  they are better than what the french telecom gets  so 
 none 	but the   the only number that s still   i mean  which stephane also got in his result was that medium mismatch of the finnish  which is very   which is a very strange situation where we used the   we changed the proto for initializing the h_m_m   i mean  this   this is basically because it gets stuck in some local minimum in the training 
 none 	that seventy five point seven nine in the finnish mismatch which is that   the eleven point nine six what we see 
 none 	uh huh 
 none 	mmm 
 none 	yeah 
 none 	so we have to jiggle it somehow 
 none 	yeah   so we start with that different proto and it becomes eighty eight  which is like some fifty percent improvement 
 none 	s  wait a minute  start with a different what 
 none 	different prototype  which is like a different initialization for the  uh  s  transition probabilities 
 none 	it s just that right now  the initialization is to stay more in the current state  which is point four point six  right 
 none 	yeah 
 none 	yeah  and if it changes to point five point five  which is equal  for transition and self loop where it becomes eighty eight percent 
 none 	well  but that involves mucking with the back end  which is not allowed 
 none 	yeah  we can t do it 
 none 	yeah 
 none 	yeah 
 none 	mmm 
 none 	so 
 none 	i mean  it uh  like  i  i  i  it is well known  this   this medium match condition of the finnish data has some strange effects  i mean  that is  
 none 	yeah 
 none 	very s 
 none 	it has a very few at   uh  actually  c  uh  tran  i mean  words also  it s a very  very small set  actually 
 none 	yeah  that too  yeah  uh huh 
 none 	there is a l  a   there is a lot of   uh  there are a lot of utterances with music in   with music in the background 
 none 	so there is  
 none 	yeah 
 none 	yeah  yeah  yeah  yeah 
 none 	mmm 
 none 	uh huh 
 none 	yeah  it has some music also  i mean  very horrible music like like 4x  
 none 	i know 
 none 	so maybe for that one you need a much smarter v_a_d 
 none 	mmm  if it s music 
 none 	uh  
 none 	so 
 none 	that   that s the   that s about the results  and  uh  the summary is like   o_k  so there are   the other thing what i tried was  which i explained in the last meeting  is using the channel zero for  uh  for both dropping and estimating the noise 
 none 	and that s like just to f  n  get a feel of how good it is 
 none 	i guess the fifty six percent improvement in the speechdat car becomes like sixty seven percent 
 none 	like ten percent better 
 none 	but that s   that s not a   that s a cheating experiment  so 
 none 	that s just   so  m  w 
 none 	but the   but the  uh  forty seven point nine percent which you have now  that s already a remarkable improvement in comparison to the first proposal 
 none 	yeah  so we had forty  four percent in the first proposal  yeah 
 none 	o_k  mm hmm 
 none 	we have f  a big im  so the major improvement that we got was in all the high mismatch cases  because all those numbers were in sixties and seventies because we never had any noise compensations 
 none 	mmm 
 none 	so that s where the biggest improvement came up  not much in the well match and the medium match and t_i digits also right now 
 none 	so this is still at three or four percent improvement over the first proposal 
 none 	mmm 
 none 	mmm 
 none 	yeah  so that s good 
 none 	yeah  so 
 none 	then if we can improve the noise estimation  then it should get better 
 none 	yeah  i   i started thinking about also   i mean yeah  uh  i discovered the same problem when i started working on   uh  on this aurora task almost two years ago  that you have the problem with this mulit  a  at the beginning we had only this multi  condition training of the t_i digits 
 none 	yeah 
 none 	and  uh  i   i found the same problem  just taking um  what we were used to u  use 
 none 	i mean  uh  some type of spectral subtraction  y  you get even worse results than the basis and uh  
 none 	yeah  yeah  yeah 
 none 	i   i tried to find an explanation for it  so  
 none 	mmm 
 none 	so   yes  stephane also has the same experience of using the spectral subtraction right 
 none 	mmm 
 none 	mm hmm 
 none 	yeah 
 none 	yeah 
 none 	so here   here i mean  i found that it s   if i changed the noise estimate i could get an improvement 
 none 	so that s   so it s something which i can actually pursue  is the noise estimate 
 none 	mm hmm 
 none 	and  
 none 	yeah  i think what you do is in   when   when you have the   the   this multi condition training mode  um then you have   then you can train models for the speech  for the words  as well as for the pauses where you really have all information about the noise available 
 none 	yeah 
 none 	and it was surprising  
 none 	at the beginning it was not surprising to me that you get really the best results on doing it this way  i mean  in comparison to any type of training on clean data and any type of processing  but it was   so  u  u  it   it seems to be the best what   wh  wh  what   what we can do in this moment is multi condition training 
 none 	and every  when we now start introducing some   some noise reduction technique we   we introduce also somehow artificial distortions 
 none 	yeah 
 none 	and these artificial distortions   uh  i have the feeling that they are the reason why   why we have the problems in this multi condition training 
 none 	that means the h_m_ms we trained  they are   they are based on gaussians  and on modeling gaussians  and if you  
 none 	yeah 
 none 	can i move a little bit with this  yeah 
 none 	and if we introduce now this   this u  spectral subtraction  or wiener filtering stuff   so  usually what you have is maybe  um  
 none 	i m   i m showing now an envelope um maybe you ll   f  for this time 
 none 	so usually you have   maybe in clean condition you have something which looks like this  and if it is noisy it is somewhere here 
 none 	and then you try to subtract it or wiener filter or whatever  and what you get is you have always these problems  that you have this   these   these   these zeros in there 
 none 	yeah 
 none 	and you have to do something if you get these negative values  i mean  this is your noise estimate and you somehow subtract it or do whatever  uh  and then you have  
 none 	and then i think what you do is you introduce some   some artificial distribution in this uh in   in the models  i mean  i  you   you train it also this way but  i  somehow there is   u  u  there is no longer a   a gaussian distribution  it is somehow a strange distribution which we introduce with these artificial distortions 
 none 	and   and i was thinking that   that might be the reason why you get these problems in the   especially in the multi condition training mode  s 
 none 	mm hmm 
 none 	yeah  yeah  th  that s true 
 none 	yeah   the c  the models are not complex enough to absorb that additional variability that you re introducing 
 none 	thanks adam 
 none 	yeah 
 none 	yes 
 none 	well  that s  
 none 	i also have the feeling that um  the reason ye  why it doesn t work is   yeah  that the models are much   are t  um  not complex enough  because i   actually i als  always had a good experience with spectral subtraction  just a straight spectral subtraction algorithm when i was using neural networks  big neural networks  which maybe are more able to model strange distributions and  
 none 	yeah  so  
 none 	mm hmm 
 none 	but  
 none 	yeah 
 none 	then i tried the same   exactly the same spectral subtraction algorithm on these aurora tasks and it simply doesn t work 
 none 	it s even   it  uh  hurts even  so 
 none 	hmm 
 none 	we probably should at some point here try the tandem   the   the   the system  two kind of stuff with this  with the spectral subtraction for that reason  cuz again  it should do a transformation to a domain where it maybe   looks more gaussian 
 none 	hmm 
 none 	mm hmm 
 none 	hmm 
 none 	mm hmm 
 none 	yeah  y  i   i was   whe  w  w  just yesterday when i was thinking about it um w  what   what we could try to do  or do about it   i mean  if you   if you get at this   in this situation that you get this   this negative values and you simply set it to zero or to a constant or whatever if we   if we would use there a somehow  um   a random generator which   which has a certain distribution  u  not a certain   yeah  a special distribution we should see   we   we have to think about it 
 none 	it s  
 none 	and that we  so  introduce again some natural behavior in this trajectory 
 none 	mm hmm 
 none 	mm hmm  very different from speech 
 none 	still  i mean  it shouldn t confuse the  
 none 	yeah  i mean  similar to what   what you see really u  in   in the real um noisy situation 
 none 	o_k 
 none 	mm hmm 
 none 	or i  in the clean situation  but   but somehow a   a natural distribution 
 none 	but isn t that s  again sort of the idea of the additive thing  if it   as   as we had in the j_ stuff  i mean  basically if   if you have random data  um  in   in the time domain  then when you look at the s  spectrum it s gonna be pretty flat 
 none 	mm hmm 
 none 	and   and 
 none 	uh 
 none 	so just add something everywhere rather than just in those places  it s just a constant  right 
 none 	mm hmm 
 none 	yeah 
 none 	i think   e  yeah  it s   it s just especially in these segments  i mean  you introduce  um  very artificial behavior  and  
 none 	yeah 
 none 	yeah  well  see if you add something everywhere  it has almost no effect up   up   up on   on top 
 none 	mm hmm 
 none 	and it   and it   and it has significant effect down there  that was  sort of the idea 
 none 	mm hmm 
 none 	hmm 
 none 	yeah the   that s true  that   those   those regions are the cause for this   those negative values or whatever you get  yeah 
 none 	i 
 none 	mm hmm 
 none 	mm hmm 
 none 	so 
 none 	i mean  we   we could trit  uh  we   we could think how w  what   what we could try  i mean  it   it was just an idea  i mean  we   to  
 none 	yeah 
 none 	yeah  yeah 
 none 	mm hmm 
 none 	i think when it s noisy people should just speak up 
 none 	mmm 
 none 	so  
 search 	if we look at the  france telecom proposal    they use some kind of noise addition   
 none 	they have a random number generator  right 
 none 	and they add noise on the trajectory of  uh  the log energy only  right 
 none 	oh  they do 
 none 	yep 
 none 	oh 
 none 	c_z  c_zero and log energy also  yeah 
 none 	yeah 
 none 	um 
 none 	but i don t know how much effect it   this have  but they do that  yeah 
 none 	now 
 none 	uh huh 
 none 	oh 
 none 	hmm 
 none 	so it   it   it   it   it is l  somehow similar to what  
 none 	i think because they have th  log energy  yeah  and then just generate random number  they have some kind of mean and variance  and they add this number to   to the log energy simply 
 none 	to the l 
 none 	um  
 none 	yeah   the   the log energy  the   after the clean   cleaning up 
 none 	mm hmm 
 none 	so they add a random   random noise to it 
 none 	to the   just the energy  or to the mel   uh  to the mel filter 
 none 	no  on  only to the log energy 
 none 	only   yeah 
 none 	oh 
 none 	uh huh 
 none 	so it   cuz i mean  i think this is most interesting for the mel filters 
 none 	uh huh 
 none 	right  or   or f_f_ts  one or the other 
 none 	but   but they do not apply filtering of the log energy or what  
 none 	like  uh   i mean  
 none 	like   like a spectral subtraction or  
 none 	no   their filter is not m_ domain  
 none 	s  so they did filter their time signal and then what    u 
 none 	yeah  i kn 
 none 	and then they calculate from this  the log energy or    
 none 	yeah   then after that it is s  almost the same as the baseline prop  system 
 none 	mm hmm 
 none 	and then the final log energy that they   that they get  that   to the   to that they add some random noise 
 none 	yeah  but again  that s just log energy as opposed to filter bank energy  yeah 
 none 	yeah  so it s not the mel  you know  it s not the mel filter bank output 
 none 	mmm 
 none 	mm hmm 
 none 	these are log energy computed from the time s  domain signal  not from the mel filter banks 
 none 	mm hmm 
 none 	so   did  
 none 	hmm 
 none 	maybe it s just a way to decrease the importance of this particular parameter in the   in the world feature vector cu  if you add noise to one of the parameters  you widen the distributions and  
 none 	hmm 
 none 	becomes flat 
 none 	the variance  yeah  reduces  so 
 none 	hmm  yeah 
 none 	eee sss uh 
 none 	so it could reduce the dependence on the amplitude and so on  yeah 
 none 	yeah 
 none 	yeah 
 none 	although  
 none 	maybe 
 none 	so is  uh   is that about it 
 none 	mm hmm 
 none 	uh  so the   o_k  so the other thing is the  
 none 	or    
 none 	i m just looking at a little bit on the delay issue where the delay of the system is like a hundred and eighty millisecond  so i just   just tried another sk  system   i mean  another filter which i ve like shown at the end  which is very similar to the existing uh  filter 
 none 	only   uh  only thing is that the phase is   is like a totally nonlinear phase because it s a   it s not a symmetric filter anymore 
 none 	this is for the l_d_a 
 none 	yeah   so   so this   this is like   so this makes the delay like zero for l_d_a because it s completely causal  
 none 	so  
 none 	oh 
 none 	so i got actually just the results for the italian for that and that s like  
 none 	so the fifty one point o_ nine has become forty eight point o_ six  which is like three percent relative degradation 
 none 	so i have like the fifty one point o_ nine and   so 
 none 	mm hmm 
 none 	i don t know it f  fares for the other conditions  so it s just like   it s like a three percent relative degradation  with the  
 none 	but   but is there   is there a problem with the one hundred eighty milliseconds  or    
 none 	th  well  this is  
 none 	u  uh  may 
 none 	yeah  i mean  i talked to   to   uh  i ta 
 none 	uh  i talked  uh  about it with   with hynek  i mean  there is  
 none 	this is   so   so  basically our   our position is that  um  we shouldn t be unduly constraining the latency at this point because we re all still experimenting with trying to make the performance better in the presence of noise 
 none 	uh  there is a minority in that group who is a  arguing   who are arguing for um  uh  having a further constraining of the latency 
 none 	so we re s  just continuing to keep aware of what the trade offs are and  you know  what   what do we gain from having longer or shorter latencies  but since we always seem to at least get something out of longer latencies not being so constrained  we re tending to go with that if we re not told we can t do it 
 none 	mmm 
 none 	mm hmm 
 none 	what   where was the  um   the smallest latency of all the systems last time 
 none 	the french telecom 
 none 	well  france telecom was   was   was very short latency and they had a very good result 
 none 	it s  
 none 	what   what was it 
 none 	it was thirty five 
 none 	it was in the order of thirty milliseconds or  
 none 	yeah  th  th 
 none 	thirteen 
 none 	thirty 
 none 	thirty 
 none 	thirty four 
 none 	yeah 
 none 	yeah 
 none 	yeah  so it s possible to get very short latency  but  again  we re   the   the approaches that we re using are ones that take advantage of  
 none 	yeah 
 none 	i was just curious about where we are compared to  you know  the shortest that people have done 
 none 	but   but i think this thirty milliseconds   they   they did   it did not include the   the delta calculation  and this is included now  you know  
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	so if they include the delta  it will be an additional forty millisecond 
 none 	mm hmm 
 none 	yeah 
 none 	yeah 
 none 	i   i don t remember the   i  th  they were not using the h_t_k delta 
 none 	no  they re using a nine point window  which is like a four on either side  which is like   f  so   they didn t include that 
 none 	nine point 
 none 	o_k 
 none 	mmm 
 none 	yeah 
 none 	mm hmm 
 none 	so  
 none 	o_k 
 none 	where does the comprish  compression in decoding delay comes from 
 none 	that s the way the   the   the frames are packed  like you have to wait for one more frame to pack  because it s   the c_r_c is computed for two frames always 
 none 	mm hmm 
 none 	well  that   the  they would need that forty milliseconds also 
 none 	right 
 none 	no  they actually changed the compression scheme altogether 
 none 	mm hmm 
 none 	so they have their own compression and decoding scheme and they   i don t know what they have  but they have coded zero delay for that 
 none 	oh 
 none 	because they ch  i know they changed it  their compression  they have their own c_r_c   their   their own error correction mechanism  so they don t have to wait more than one more frame to know whether the current frame is in error 
 none 	oh 
 none 	oh  o_k 
 none 	so they changed the whole thing so that there s no delay for that compression and   part also 
 none 	hmm 
 none 	mm hmm 
 none 	even you have reported actually zero delay for the compression  i thought maybe you also have some different  
 none 	mmm  mmm 
 none 	no  i think i   i used this scheme as it was before 
 none 	o_k 
 none 	ah 
 none 	mm hmm 
 none 	o_k  we ve got twenty minutes so we should probably try to move along 
 none 	uh  did you wanna go next  stephane 
 none 	i can go next  yeah 
 none 	mmm 
 none 	oh 
 none 	it s  
 none 	wait a minute  it s  
 none 	yeah  we have to take  
 none 	wait a minute  i think i m confused 
 none 	well  
 none 	o_k 
 none 	alright 
 none 	so you have w  w  one sheet 
 none 	this one is   you don t need it  alright 
 none 	uh  
 none 	so you have to take the whole   the five  there should be five sheets 
 none 	o_k  i have four now because i left one with dave because i thought i was dropping one off and passing the others on  so  no  we re not  o_k 
 none 	thanks 
 none 	please give me one 
 none 	ah  we need one more over here 
 none 	o_k  maybe there s not enough for everybody  but  
 none 	i can share with barry 
 none 	oh  o_k 
 none 	yeah 
 none 	o_k 
 none 	can we look at this 
 none 	yeah 
 none 	so  yeah  there are two figures showing actually the  mmm 
 none 	um  performance of the current v_a_d 
 none 	so it s a n  neural network based on p_l_p parameters  uh  which estimate silence probabilities  and then
 none 	i just put a median filtering on this to smooth the probabilities  right 
 none 	um   i didn t use the   the scheme that s currently in the proposal because i don t want to  
 none 	in the proposal   well  in   in the system we want to add like speech frame before every word and a little bit of   of  uh  s  a couple of frames after also 
 none 	uh  but to estimate the performance of the v_a_d  we don t want to do that  because it would artificially increase the um   the false alarm rate of speech detection  right 
 none 	um  so  there is u  normally a figure for the finnish and one for italian 
 none 	and maybe someone has two for the italian because
 none 	i m missing one figure here 
 none 	no 
 none 	well  
 none 	well  whatever 
 none 	uh   yeah  so one surprising thing that we can notice first is that apparently the speech miss rate is uh  higher than the false alarm rate 
 none 	so 
 none 	so   so what is the lower curve and the upper curve 
 none 	it means  
 none 	mm hmm 
 none 	yeah  there are two curves 
 none 	yeah 
 none 	one curve s for the close talking microphone  which is the lower curve  and the other one is for the distant microphone which has more noise so  it s logical that it performs worse  so as i was saying  the miss rate is quite important uh  which means that we tend to label speech as   as a silence 
 none 	ah  o_k 
 none 	and  uh  i didn t analyze further yet  but i think it s   it may be due to the fricative sounds which may be   in noisy condition maybe label   labeled as silence 
 none 	and it may also be due to the alignment because   well  the reference alignment  because right now i just use an alignment obtained from   from a system trained on channel zero 
 none 	and
 none 	i checked it a little bit but there might be alignment errors 
 none 	um  yeah  e  like the fact that the   the models tend to align their first state on silence and their last state o  on silence also  so the reference   reference alignment would label as speech some silence frame before speech and after speech 
 none 	this is something that we already noticed before when   mmm 
 none 	so this cus  this could also explain  uh  the high miss rate maybe 
 none 	and   and this   this curves are the average over the whole database  so 
 none 	uh  
 none 	yeah  right 
 none 	mmm 
 none 	um  
 none 	yeah  and the different points of the curves are for five uh  thresholds on the probability uh from point three to point seven 
 none 	so that threshold   o_k 
 none 	mm hmm  yeah 
 none 	s  o_k   so d  the detection threshold is very  
 none 	so the v 
 none 	the v_a_d  yeah  there first  a threshold on the probability
 none 	yeah  yeah 
 none 	that puts all the values to zero or one  and then the median filtering 
 none 	mmm 
 none 	yeah  so the median filtering is fixed 
 none 	you just change the threshold  yeah 
 none 	yeah  it s fixed  yeah  mm hmm 
 none 	so  going from channel zero to channel one  uh  almost double the error rate 
 none 	um 
 none 	yeah 
 none 	well  so it s a reference performance that we can   you know  if we want to   to work on the v_a_d  we can work on this basis and  
 none 	 
 none 	mm hmm 
 none 	o_k 
 none 	is this   is this v_a_d a m_l_p 
 none 	yeah 
 none 	o_k  how   how big is it 
 none 	it s a very big one  i don t remember  m 
 none 	so three   three hundred and fifty inputs  uh  six thousand hidden nodes and two outputs  t  t 
 none 	o_k 
 none 	yeah 
 none 	mm hmm 
 none 	middle sized one 
 none 	yeah   
 none 	mm hmm 
 none 	yeah 
 none 	uh  ppp  i don t know  you have questions about that  or suggestions 
 none 	mmm 
 none 	s  so  
 none 	it seems   the performance seems worse in finnish  which   uh  
 none 	well  it s not trained on finnish 
 none 	it s worse 
 none 	it s not trained on finnish  yeah 
 none 	what s it trained on 
 none 	i mean  the m_l_p s not trained on finnish 
 none 	right  what s it trained on 
 none 	oh   oh  sorry  uh  it s italian t_i digits 
 none 	yeah  
 none 	oh  it s trained on italian  yeah  o_k 
 none 	yeah  that s right  
 none 	mm hmm 
 none 	and  
 none 	o_k 
 none 	and also there are like funny noises on finnish more than on italian  i mean  like music and um  
 none 	mm hmm 
 none 	yeah 
 none 	yeah  the   yeah  it s true 
 none 	so  yeah  we were looking at this  but for most of the noises  noises are   um 
 none 	i don t know if we want to talk about that  but  well  the   the  car  noises are below like five hundred hertz  and we were looking at the  music  utterances and in this case the noise is more about two thousand hertz 
 none 	well  the music energy s very low apparently 
 none 	yeah 
 none 	uh  uh  from zero to two   two thousand hertz 
 none 	so maybe just looking at this frequency range for   from five hundred to two thousand would improve somewhat the v_a_d and  
 none 	mmm 
 none 	yeah 
 none 	mmm  
 none 	so there are like some   some s  some parameters you wanted to use or something  or   yeah 
 none 	yeah  but  
 none 	yes 
 none 	mm hmm 
 none 	uh  the next  um   oh  it s there 
 none 	so is the   is the   is the training   is the training based on these labels files which you take as reference here 
 none 	wh  when you train the neural net y  y  you  
 none 	yeah 
 none 	no 
 none 	it s not 
 none 	it s   it was trained on some alignment obtained um  uh  
 none 	for the italian data 
 none 	i think we trained the neural network on   with embedded training  so re estimation of the alignment using the neural network  i guess 
 none 	that s right 
 none 	yeah  we actually trained  uh  the   on the italian training part  we   we had another system with u 
 none 	yeah 
 none 	so it was a f  f  a phonetic classification system for the italian aurora data 
 none 	yeah 
 none 	it must be somewhere 
 none 	yeah 
 none 	for the aurora data that it was trained on  it was different  like  for t_i digits you used a   a previous system that you had  i guess 
 none 	what  
 none 	no it   yeah  yeah  that s true 
 none 	so the alignments from the different database that are used for training came from different system 
 none 	syste 
 none 	yeah 
 none 	then we put them tog  together 
 none 	well  you put them together and trained the v_a_d on them  mmm 
 none 	yeah 
 none 	hmm 
 none 	yeah 
 none 	uh 
 none 	but did you use channel   did you align channel one also  or  
 none 	i just took their entire italian training part  so it was both channel zero plus channel one 
 none 	yeah 
 none 	so di 
 none 	yeah  so the alignments might be wrong then on channel one  right 
 none 	on one  possible 
 none 	so we might  yeah  at least want to retrain on these alignments  which should be better because they come from close talking microphone 
 none 	we can do a realignment  that s true 
 none 	yeah  the   that was my idea  i mean  if   if it ha  if it is not the same labeling which is taking the spaces 
 none 	yeah 
 none 	o_k 
 none 	yeah  possible 
 none 	yeah 
 none 	mmm 
 none 	yeah 
 none 	i mean  it   so the system   so the v_a_d was trained on maybe different set of labels for channel zero and channel one and   was the alignments were w  were different for   s  certainly different because they were independently trained  we didn t copy the channel zero alignments to channel one 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	yeah 
 none 	yeah 
 none 	but for the new alignments what you generated  you just copied the channel zero to channel one  right 
 none 	right 
 none 	yeah 
 none 	yeah 
 none 	um  and eh  hhh actually when we look at   at the v_a_d  for some utterances it s almost perfect  i mean  it just dropped one frame  the first frame of speech or   so there are some utterances where it s almost one hundred percent
 none 	hmm 
 none 	v_a_d performance 
 none 	uh  but   yeah 
 none 	mmm  
 none 	yep 
 none 	so the next thing is um 
 none 	i have the spreadsheet for three different system 
 none 	but for this you only have to look right now on the speechdat car performance uh  because i didn t test   so   i didn t test the spectral subtraction on t_i digits yet 
 none 	uh  so you have three she  sheets  one is the um proposal one system  actually  it s not exe  exactly proposal one  it s the system that
 none 	sunil just described 
 none 	um  but with uh  wiener filtering from um  france telecom included 
 none 	um  so this gives like fifty seven point seven percent  uh  s  uh  error rate reduction on the speechdat car data 
 none 	mmm  and then i have two sheets where it s for a system where   uh  so it s again the same system  but in this case we have spectral subtraction with a maximum overestimation factor of two point five 
 none 	uh  there is smoothing of the gain trajectory with some kind of uh  low pass filter  which has forty milliseconds latency 
 none 	and then  after subtraction um  i add a constant to the energies and
 none 	i have two cases d  where   the first case is where the constant is twenty five d_b below the mean speech energy and the other is thirty d_b below 
 none 	um  and for these s  two system we have like fifty five point  uh  five percent improvement  and fifty eight point one 
 none 	so again  it s around fifty six  fifty seven  uh  
 none 	cuz i notice the t_i digits number is exactly the same for these last two 
 none 	yeah  because i didn t  
 none 	for the france telecom uh  spectral subtraction included in the   our system  the t_i digits number are the right one  but not for the other system because i didn t test it yet   this system  including   with spectral subtraction on the t_i digits data 
 none 	i just tested it on speechdat car 
 none 	ah  so   so that means the only thing  
 none 	mm hmm  so   so   so these numbers are simply   yeah  o_k 
 none 	this  we have to   yeah  yes 
 none 	yeah  so you   so you just should look at that fifty eight perc  point o_ nine percent and so on  o_k  good 
 none 	but this number 
 none 	right  right 
 none 	mm hmm 
 none 	um 
 none 	yeah 
 none 	so this  
 none 	s 
 none 	so by   uh  by   by reducing the noise a   a decent threshold like minus thirty d_b  it s like  
 none 	yeah 
 none 	uh  you are like r  r  reducing the floor of the noisy regions  right 
 none 	yeah  the floor is lower 
 none 	um  mm hmm 
 none 	uh huh 
 none 	i m sorry  so when you say minus twenty five or minus thirty d_b  with respect to what 
 none 	to the average um  speech energy which is estimated on the world database 
 none 	o_k  so basically you re creating a signal to noise ratio of twenty five or thirty d_b  uh r 
 none 	yeah 
 none 	but it s not   it   it s  
 none 	i   i   i think what you do is this  i  when   when you have this  after you subtracted it  i mean  then you get something w  w  with this  uh  where you set the values to zero and then you simply add an additive constant again 
 none 	yeah 
 none 	so you shift it somehow  this   this whole curve is shifted again 
 none 	right 
 none 	but did you do that before the thresholding to zero  or    
 none 	it s  
 create_single_reminder 	but  it s after the thresholding   so  maybe   maybe we might  do it before   yeah  
 none 	oh  so you d really want to do it before  right 
 none 	yeah  because then the   then you would have less of that phenomenon 
 none 	yeah 
 none 	e  hhh 
 none 	i think  c 
 none 	uh  
 none 	yeah 
 none 	but still  when you do this and you take the log after that  it   it reduce the   the variance  but   mmm 
 none 	yeah  it   it  
 none 	right 
 none 	yeah  that will reduce the variance  that ll help  but maybe if you does   do it before you get less of these funny looking things he s drawing  
 none 	mm hmm 
 none 	um 
 none 	but   but  
 none 	so before it s like adding this  col  to the   to the   o  exi  original  
 none 	we would  
 none 	right at the point where you ve done the subtraction 
 none 	o_k 
 none 	um  essentially you re adding a constant into everything 
 none 	mm hmm 
 none 	but the way stephane did it  it is exactly the way i have implemented in the phone  so 
 none 	oh  yeah  better do it different  then  yeah 
 none 	um 
 none 	yeah 
 none 	just you   you just ta  you just set it for a particular signal to noise ratio that you want 
 none 	yeah i  
 none 	i made s  similar investigations like stephane did here  just uh  adding this constant and   and looking how dependent is it on the value of the constant and then  must choose them somehow to give on average the best results for a certain range of the signal to noise ratios 
 none 	yeah 
 none 	yeah 
 none 	mm hmm 
 none 	yeah 
 none 	uh huh 
 none 	mm hmm 
 none 	so  
 none 	oh  it s clear  i should have gi  given other results  also it s clear when you don t add noise  it s much worse  like  around five percent worse i guess 
 none 	uh huh 
 none 	and if you add too much noise it get worse also  and it seems that right now this   this is c  a constant that does not depend on   on anything that you can learn from the utterance  it s just a constant noise addition 
 none 	um 
 none 	and i   i think w  w 
 none 	i   i m sorry  then   then i m confused  i thought   you re saying it doesn t depend on the utterance but i thought you were adding an amount that was twenty five d_b down from the signal energy 
 none 	i think  
 none 	yeah  so the way i did that  i  i just measured the average speech energy of the   all the italian data 
 none 	oh 
 none 	and then  
 none 	i   i have   i used this as mean speech energy 
 none 	mm hmm 
 none 	oh  it s just a constant amount over all 
 none 	yeah  and   wha  what i observed is that for italian and spanish  when you go to thirty and twenty five d_b  uh it   it s good  it stays   in this range  it s  uh  the p  u  well  the performance of the   this algorithm is quite good  but for finnish  you have a degradation already when you go from thirty five to thirty and then from thirty to twenty five 
 none 	o_k 
 none 	oh 
 none 	and  
 none 	i have the feeling that maybe it s because just finnish has a mean energy that s lower than   than the other databases  and due to this the thresholds should be   the   the a  the noise addition should be lower and  
 none 	yeah 
 none 	but in   i mean  in the real thing you re not gonna be able to measure what people are doing over half an hour or an hour  or anything  right  so you have to come up with this number from something else 
 none 	yeah 
 none 	so  
 none 	uh  but you are not doing it now language dependent  or    
 none 	it s not  it s just something that s fixed  yeah  mm hmm  um  
 none 	no  it s overall  o_k 
 none 	but what he is doing language dependent is measuring what that number i  reference is that he comes down twenty  five down from 
 none 	yeah  so i g 
 none 	no 
 none 	it   no  because i did it   i started working on italian  i obtained this average energy and then i used this one 
 none 	no 
 none 	yeah 
 none 	for all the languages  o_k 
 none 	yeah 
 none 	so it s sort of arbitrary  i mean  so if y  if   yeah  yeah 
 none 	yeah 
 none 	yep 
 none 	um  yeah  so the next thing is to use this as   as maybe initialization and then use something on line  but   and i expect improvement at least in finnish because eh   the way  
 none 	uh huh 
 none 	something more adaptive  yeah 
 none 	o_k 
 none 	well  um  for italian and spanish it s   th  this value works good but not necessarily for finnish 
 none 	mmm 
 none 	but unfortunately there is  like  this forty millisecond latency and  um  
 none 	yeah  so i would try to somewhat reduce this   
 none 	i already know that if i completely remove this latency  so  um  it   um there is a three percent hit on italian 
 none 	mm hmm  i 
 none 	d  does latency   sorry  go ahead 
 none 	yeah  your   your smoothing was uh  over this s  so to say  the   the factor of the wiener 
 none 	and then it s  uh  
 none 	what was it  this   this smoothing  it was over the subtraction factor  so to say 
 none 	mm hmm 
 none 	it s a smoothing over the   the gain of the subtraction algorithm 
 none 	was this done  
 none 	mm hmm 
 none 	and   and you are looking into the future  into the past 
 none 	right 
 none 	and smoothing  mm hmm 
 none 	so  to smooth this thing  yeah 
 none 	um  
 none 	and did   did you try simply to smooth um
 none 	to smooth the   the   t  to   to smooth stronger the   the envelope 
 none 	um  no  i did not 
 none 	mmm 
 none 	mmm 
 none 	because i mean  it should have a similar effect if you  
 none 	yeah 
 none 	i mean  you   you have now several stages of smoothing  so to say  you start up 
 none 	as far as i remember you   you smooth somehow the envelope  you smooth somehow the noise estimate  and   and later on you smooth also this subtraction factor 
 none 	mm hmm 
 none 	mmm  
 none 	uh  no  it s   it s just the gain that s smoothed actually but it s smoothed  
 none 	uh  actually i d  i do all the smoothing  yeah  yeah 
 none 	ah  oh  it w  it was you  yeah 
 none 	uh   yeah  yeah 
 none 	yeah 
 none 	no  in this case it s just the gain  and  
 none 	uh huh 
 none 	but the way it s done is that um  for low gain  there is this non  nonlinear smoothing actually  for low gains um 
 none 	i use the smoothed sm  uh  smoothed version but   for high gain it s   i don t smooth 
 none 	uh 
 none 	mm hmm 
 none 	i just  uh   it   experience shows you  if   if you do the  
 none 	the best is to do the smoo  smoothing as early as possible 
 none 	uh huh 
 none 	so w  when you start up  i mean  you start up with the   with the   somehow with the noisy envelope 
 none 	mm hmm 
 none 	and  best is to smooth this somehow 
 none 	mm hmm 
 none 	uh  yeah  i could try this  um 
 none 	and  
 none 	so  before estimating the s_n_r   smooth the envelope 
 none 	yeah 
 none 	yeah 
 none 	uh huh 
 none 	mm hmm 
 none 	but  
 none 	yeah 
 none 	then i   i would need to find a way to like smooth less also when there is high energy 
 none 	cuz i noticed that it   it helps a little bit to s  like smooth more during low energy portions and less during speech  because if you smooth then y  you kind of distort the speech 
 none 	yes  y 
 none 	yeah 
 none 	yeah 
 none 	right 
 none 	um 
 none 	mm hmm 
 none 	yeah  i think when w  you   you could do it in this way that you say  if you   if i m   you have somehow a noise estimate  and  if you say i m   i m   with my envelope i m close to this noise estimate  then you have a bad signal to noise ratio and then you   you would like to have a stronger smoothing 
 none 	mm hmm 
 none 	yeah 
 none 	mm hmm 
 none 	so you could   you could base it on your estimation of the signal to noise ratio on your actual  
 none 	yeah 
 none 	mm hmm 
 none 	mm hmm 
 none 	mmm 
 none 	yeah  or some silence probability from the vad if you have  
 none 	um  yeah  but i don t trust the current vad  so 
 none 	yeah  uh  so not   not right now maybe 
 none 	well  maybe 
 none 	the vad later will be much better  yeah  so 
 none 	maybe 
 none 	i see 
 none 	so is that it 
 none 	uh  fff i think that s it  yeah  uh 
 none 	s  so to summarize the performance of these 
 none 	speechdat car results is similar than   than yours so to say 
 none 	yeah  so the fifty eight is like the be  some fifty six point   yeah  that s true 
 none 	yeah 
 none 	y  you have   you have fifty six point four and   and   and dependent on this additive constant  it is s  better or   or worse  yeah 
 none 	yeah 
 none 	slightly better 
 none 	mm hmm 
 none 	yeah 
 none 	mm hmm 
 none 	and  yeah  i  i  i  the condition where it s better than your approach  it s   it   just because maybe it s better on well matched and that the weight on well matched is   is bigger  because   if you don t weigh differently the different condition  you can see that your   well  the win  the two stage wiener filtering is maybe better or  
 none 	yeah  yeah  you   you caught up   yep  that s true 
 none 	yeah 
 none 	it s better for high mismatch  right 
 none 	yeah  it s better for high mismatch 
 none 	mm hmm 
 none 	but a little bit worse for well matched  uh huh 
 none 	so over all it gets  yeah  worse for the well matched condition  so y 
 none 	so we need to combine these two 
 none 	uh  that s   that s the best thing  is like the french telecom system is optimized for the well matched condition  they c  yeah 
 none 	mm hmm 
 none 	so they know that the weighting is good for the well matched  and so there s   everywhere the well matched s s  s  performance is very good for the french telecom 
 none 	yeah 
 none 	mm hmm 
 none 	mm hmm 
 none 	t  we are   we may also have to do something similar   
 none 	mm hmm 
 none 	well   our tradition here has always been to focus on the mismatched  cuz it s more interesting 
 none 	um the  
 none 	mu  my   mine was it too  i mean 
 none 	yeah 
 none 	before i started working on this aurora  so 
 none 	yeah  yeah 
 none 	yeah 
 none 	o_k 
 none 	carmen  do you  uh  
 none 	well  i only say that the   this is  a summary of the   of all the v_t_s experiments and say that the result in the last um  for italian   the last experiment for italian  are bad 
 none 	i make a mistake when i write  up at d_ i copy one of the bad result 
 none 	so you  
 none 	and  
 none 	there  you know  this 
 none 	um  well 
 none 	if we put everything  we improve a lot u  the spectral use of the v_t_s but the final result are not still mmm  good like the
 none 	wiener filter for example  i don t know  maybe it s   it s possible to   to have the same result  i don t know exactly 
 none 	that s somewhere  
 none 	mmm  because i have  mmm  worse result in medium mismatch and high mismatch 
 none 	you s  you have a better r 
 none 	yeah  you have some results that are good for the high mismatch 
 none 	and   yeah  i someti  are more or less similar but   but are worse 
 none 	and still i don t have the result for t_i digits 
 none 	the program is training  maybe for this weekend i will have result t_i digits and i can complete that s  like this 
 none 	well 
 none 	uh 
 none 	right 
 none 	one thing that i note are not here in this result but are speak   are spoken before with sunil
 none 	i   i improve my result using clean l_d_a filter 
 none 	mm hmm 
 none 	mm hmm 
 none 	if i use  eh  the l_d_a filter that are training with the noisy speech  that hurts the res  my results 
 none 	so what are these numbers here  are these with the clean or with the noisy 
 none 	this is with the clean 
 none 	o_k 
 none 	with the noise i have worse result  that if i doesn t use it 
 none 	uh huh 
 none 	but m  that may be because with this technique we are using really   really clean speech 
 none 	the speech   the representation that go to the h_t_k is really clean speech because it s from the dictionary  the code book and maybe from that  i don t know 
 none 	because i think that you   did some experiments using the two   the two l_d_a filter  clean and noi  and noise  and it doesn t matter too much 
 none 	mm hmm 
 none 	it s  
 none 	um  yeah  i did that but it doesn t matter on speechdat car  but  it matters  uh  a lot on t_i digits 
 none 	it s better to use clean 
 none 	using the clean filter 
 none 	yeah  d  uh  it s much better when you   we used the clean derived
 none 	mm hmm  maybe you can do d  also this 
 none 	l_d_a filter 
 none 	yeah 
 none 	to use clean speech 
 none 	uh  but  yeah  sunil in   in your result it s  
 none 	yeah  i ll try 
 none 	i   i ll try the cle 
 none 	no  i   i   my result is with the noisy   noisy l_d_a 
 none 	it s with the noisy one  yeah 
 none 	yeah 
 none 	oh 
 none 	it s with the noisy  yeah  it s   it s not the clean l_d_a 
 none 	so  
 none 	um  
 none 	it s   in   in the front sheet  i have like   like the summary  yeah 
 none 	and   and your result is with the  
 none 	it s with the clean l_d_a 
 none 	oh  this is   your results are all with the clean l_d_a result  
 none 	yeah  with the clean l_d_a 
 none 	yeah 
 none 	o_k   
 none 	is that the reason  
 none 	and in your case it s all   all noisy  yeah  but  
 none 	all noisy  yeah 
 none 	and  
 none 	uh  
 none 	yeah 
 none 	uh  
 none 	but i observe my case it s in  uh  uh  at least on speechdat car it doesn t matter but t_i digits it s like two or three percent absolute  uh  better 
 none 	on t_i digits this matters 
 none 	absolute 
 none 	uh  
 create_single_reminder 	so you really might wanna  try the clean  i think   yeah 
 none 	so if  
 none 	yeah  i   i   i will have to look at it  yeah  that s true 
 none 	yeah  that could be sizeable right there 
 none 	and this is everything 
 none 	yeah 
 find_calendar_entry 	maybe  you   you  are  leaving   in   in about two weeks   carmen    no 
 none 	o_k 
 none 	yeah 
 none 	yeah 
 none 	so i mean  if   if   if i would put it   put on the head of a project mana  manager   i   i   i  i would say  uh  um   i mean there is not so much time left now  i mean  if   um  what   what i would do is i   i   i would pick the best consolation  which you think  and c  create   create all the results for the whole database that you get to the final number as   as sunil did it and um and maybe also to   to write somehow a document where you describe your approach  and what you have done 
 none 	be my guest 
 none 	and prepare at the s 
 none 	yeah  i was thinking to do that next week 
 none 	yeah 
 none 	yeah 
 none 	yeah 
 none 	i ll   i ll borrow the head back and   and agree 
 none 	yeah  i wi  i   i will do that next week 
 none 	yeah  that s   that s  
 none 	right 
 none 	in fact  actually i g  i guess the  uh   the spanish government  uh  requires that anyway  they want some kind of report from everybody who s in the program  so 
 none 	mm hmm 
 none 	and of course i d   we d   we d like to see it too  so  yeah 
 none 	o_k 
 none 	so  um  what s   do you think we  uh  should do the digits or skip it  or what are   what do you think 
 none 	uh  we have them now 
 none 	yeah  got them 
 none 	uh  why don  why don t we do it 
 none 	o_k 
 none 	just   just take a minute 
 none 	i can send yet 
 none 	would you pass those down 
 none 	oh  sorry 
 none 	o_k  um  so i guess i ll go ahead 
 none 	um 
 none 	this is transcript l_ dash two eight three 
 none 	six six  two eight  three six  five one  five zero 
 none 	eight  four six eight  seven five  two three nine  zero 
 none 	six two  three nine  zero six  four three  three nine 
 none 	five five  one six  nine four  three five  zero six 
 none 	seat 
 none 	six seven one  three seven  nine four five one 
 none 	six five six nine  eight two eight four  nine four four six 
 none 	nine three one nine  eight  six five eight 
 none 	six six  five four  five eight  eight eight  nine five 
 none 	me 
 none 	transcript l_ dash three o_ three 
 none 	one three six o_ eight four  o_ one o_ 
 none 	dave 
 none 	is it the channel  or the mike  i don t remember  it s the mike 
 none 	one o_ four  o_ one  two three eight o_ 
 none 	mike 
 none 	mike five 
 none 	six seven three  seven four  seven four three o_ 
 none 	o_ six one  five three six  three nine one one 
 none 	it s not four 
 none 	three two one  four seven  two four one seven 
 none 	eight  one eight zero  one eight  three eight seven  seven 
 none 	seven  three five eight  eight nine  four three eight  one 
 none 	o_ eight three  seven three four  six one nine 
 none 	transcript l_ dash three zero four 
 none 	this is date and time 
 none 	one one  six four  eight zero  zero three  four nine 
 none 	eight two one  nine seven  four two zero eight 
 none 	no 
 none 	six two nine one  two six four five  six seven six one 
 none 	on the channel  channel 
 none 	four eight two  seven four nine  five five eight 
 none 	six one zero  one one  nine zero  nine two 
 none 	six seven  zero three  four four  nine five  one two 
 none 	zero three  eight zero  two seven  four six  nine six 
 none 	eight one nine  one six three  eight zero four 
 none 	this is transcript l_ dash three o_ five 
 none 	two four  two one  eight seven  two zero  eight three 
 none 	three  one o_ eight  nine six  three five one  zero 
 none 	six zero eight zero  o_ one eight three  four seven eight eight 
 none 	nine  nine one seven  zero six  seven o_ two  six 
 none 	five none   f  five nine one six  zero  four zero zero 
 none 	one six six  one o_ four  eight nine eight five 
 none 	two nine zero  five three six  three six three seven 
 none 	one four  two five  two two  seven zero  three one 
 none 	transcript l_ dash three o_ two 
 none 	five seven  eight five  eight seven  six two  zero nine 
 none 	seven two five  one six three  zero four four four 
 none 	eight nine  three zero  six two  eight two  seven six 
 none 	eight seven two nine  seven  zero one five 
 none 	three eight  zero four  five zero  four three  four seven 
 none 	eight nine two six  six one one nine  five seven three six 
 none 	six two three  one zero five  nine zero seven 
 none 	what is this  qual whispering
 none 	seven one four four  four two two two  seven two one eight 
 none 	t 
 none 	transcript l_ dash three zero zero  five one  two four  eight nine  zero two  four three 
 none 	zero eight eight seven  six two two two  zero nine five six 
 none 	two two nine three  nine two four four  four nine three zero 
 none 	two three seven four  zero four two two  six five seven one 
 none 	five  four six zero  eight five  five zero six  five 
 none 	eight nine  one six  eight six  four zero  seven eight 
 none 	zero one two  nine four seven  seven eight one 
 none 	nine four two two  three two six four  eight zero five three 
 none 	transcript l_ dash three zero one 
 none 	seven six nine  eight eight seven  nine nine two five 
 none 	two  one four nine  one nine  eight nine eight  nine 
 none 	nine four one  one three four  nine five four three 
 none 	eight three nine  five six zero  four nine one one 
 none 	one seven six  seven three four  three zero four 
 none 	six  four six nine  three eight  eight one eight  five 
 none 	one two nine three  eight  two one two 
 none 	one seven five eight  two zero zero nine  zero two five five 
 none 	transcript l_ dash two eighty two 
 none 	six seven three  zero zero  zero five nine six 
 none 	seven three three  zero five one  eight five zero 
 none 	zero four  five seven  five five  five eight  two eight 
 none 	two nine one five  one  five eight one 
 none 	four three zero  six six nine  two zero seven three 
 none 	eight six three  eight one seven  seven three eight six 
 none 	one five eight one  nine six three nine  five nine six seven 
 none 	five six  four two  five three  four seven  six two 
 none 	o_k  if you could just leave  um  your mike on top of your  uh  digit form i can fill in any information that s missing 
 none 	o_k 
 none 	that s uh  
 none 	i didn t get a chance to fill them out ahead of time 
 none 	yeah  the seat numbers have fallen off here 
 none 	yeah  we re gonna have to fix that 
 none 	what   what are the seat numbers  i wonder 
 none 	uh  let s see  it starts with one here  and then goes around and ends with nine here 
 none 	seven 
 none 	so i   i m eight  you re seven 
 none 	so he s eight  you re seven 
 none 	i just put   yes   
 none 	would that be
 none 	yeah 
 none 	eight  eight  three 
 none 	o_k  we re going 
 none 	this is three 
 none 	yep  yep 
 none 	test 
 none 	hmm  let s see 
 none 	move it bit  test 
 none 	test  o_k  i guess it s alright 
 none 	so  let s see 
 none 	yeah  barry s not here and dave s not here  um  i can say about   just q  just quickly to get through it  that dave and i submitted this a_s_r_u 
 none 	this is for a_s_r_u 
 none 	yeah  so 
 none 	um 
 none 	yeah  it s   it s interesting  i mean  basically we re dealing with rever  reverberation  and  um  when we deal with pure reverberation  the technique he s using works really  really well 
 none 	uh  and when they had the reverberation here  uh  we ll measure the signal to noise ratio and it s  uh  about nine d_b 
 none 	so  um  a fair amount of  
 none 	hmm 
 none 	you mean  from the actual  uh  recordings 
 none 	k 
 none 	yeah 
 none 	it s nine d_b 
 none 	yeah  um  
 none 	and actually it brought up a question which may be relevant to the aurora stuff too 
 none 	um  i know that when you figured out the filters that we re using for the mel scale  there was some experimentation that went on at   at  uh   at o_g_i 
 none 	um  but one of the differences that we found between the two systems that we were using  the   the aurora h_t_k system baseline system and the system that we were   the   the uh  other system we were using  the uh  the s_r_i system  was that the s_r_i system had maybe a  um  hundred hertz high pass 
 none 	yep 
 none 	and the  uh  aurora h_t_k  it was like twenty 
 none 	s  sixty four 
 none 	uh 
 none 	s  sixty four 
 none 	sixty four  uh 
 none 	yeah  if you re using the baseline 
 none 	is that the ba  band center 
 none 	no  the edge 
 none 	the edge is really  uh  sixty four  for some reason  uh 
 none 	yeah  
 none 	so the  uh  center would be somewhere around like hundred and   hundred and   hundred   hundred and   maybe   it s like   fi  hundred hertz 
 none 	dave thought it was twenty  but 
 none 	but do you know  for instance  h  how far down it would be at twenty hertz 
 none 	what the   how much rejection would there be at twenty hertz  let s say 
 none 	at twenty hertz 
 none 	yeah  any idea what the curve looks like 
 none 	twenty hertz frequency  
 none 	oh  it s   it s zero at twenty hertz  right  the filter 
 none 	yea  actually  the left edge of the first filter is at sixty four  so  
 none 	sixt  s  sixty four  so anything less than sixty four is zero 
 none 	mmm 
 none 	it s actually set to zero 
 none 	yeah 
 none 	what kind of filter is that 
 none 	yeah 
 none 	is this   oh  from the   from  
 none 	it  
 none 	this is the filter bank in the frequency domain that starts at sixty four  yeah 
 none 	oh  so you  uh   so you really set it to zero  the f_f_t 
 none 	yeah  yeah  so it s   it s a weight on the ball spectrum 
 none 	triangular weighting 
 none 	right  o_k 
 none 	um  
 none 	o_k  so that s   that s a little different than dave thought  i think  but   but  um  still  it s possible that we re getting in some more noise 
 none 	so i wonder  is it    was there   their experimentation with  uh  say  throwing away that filter or something  and  uh  
 none 	uh  throwing away the first 
 none 	yeah 
 none 	um  yeah  we   we ve tried including the full   full bank 
 none 	right  from zero to four k_ 
 none 	and that s always worse than using sixty four hertz 
 none 	mm hmm 
 none 	right  but the question is  whether sixty four hertz is   is  uh  too  uh  low 
 none 	yeah  i mean  make it a hundred or so 
 none 	yeah 
 none 	i t  i think i ve tried a hundred and it was more or less the same  or slightly worse 
 none 	on what test set 
 none 	on the same  uh  speechdat car  aurora 
 none 	um  it was on the speechdat car 
 none 	yeah 
 none 	so i tried a hundred to four k_  yeah 
 none 	um  and on   and on the  um  um 
 none 	so it was  
 none 	t_i digits also 
 none 	no  no  no  i think i just tried it on speechdat car 
 none 	mmm  that d be something to look at sometime because what  um  eh  he was looking at was performance in this room 
 none 	mm hmm 
 none 	would that be more like  
 none 	well  you d think that d be more like speechdat car  i guess  in terms of the noise 
 none 	the speechdat car is more  uh  sort of roughly stationary  a lot of it  and   and t_i digits maybe is not so much as   yeah 
 none 	yeah 
 none 	mm hmm 
 none 	yeah 
 none 	mm hmm 
 none 	o_k  well  maybe it s not a big deal 
 none 	but  um  
 none 	anyway  that was just something we wondered about 
 none 	but  um  uh  certainly a lot of the noise  uh  is  uh  below a hundred hertz  uh  the signal to noise ratio  you know  looks a fair amount better if you   if you high pass filter it from this room 
 none 	yeah 
 none 	but  um   but it s still pretty noisy  even   even for a hundred hertz up  it s   it s still fairly noisy  the signal to noise ratio is   is   is actually still pretty bad 
 none 	mm hmm 
 none 	so  um  i mean  the main   the   the  
 none 	hmm 
 none 	so that s on th  that s on the f  the far field ones though  right  yeah 
 none 	yeah  that s on the far field  yeah  the near field s pretty good 
 none 	so wha  what is  uh   what s causing that 
 none 	well  we got a   a video projector in here  uh  and  uh   which we keep on during every   every session we record  which  you know  i   i   w  we were aware of but   but we thought it wasn t a bad thing  i mean  that s a nice noise source  uh  and there s also the  uh   uh  air conditioning 
 none 	yeah 
 none 	uh huh 
 none 	yeah 
 none 	hmm 
 none 	which  uh  you know  is a pretty low frequency kind of thing  but   but  uh  
 none 	mm hmm 
 none 	so  those are   those are major components  i think  uh  for the stationary kind of stuff 
 none 	i see 
 none 	mmm 
 none 	um  but  um  it  uh   i guess  i   maybe i said this last week too but it   it   it really became apparent to us that we need to   to take account of noise 
 none 	and  uh  so i think when   when he gets done with his prelim study i think one of the next things we d want to do is to take this  uh   uh  noise  uh  processing stuff and   and  uh   uh  synthesize some speech from it  and then  
 none 	when are his prelims 
 none 	um  i think in about  um  a little less than two weeks 
 none 	oh 
 none 	wow 
 none 	yeah 
 none 	yeah  so 
 none 	uh  it might even be sooner  uh  let s see  this is the sixteenth  seventeenth 
 none 	yeah  i don t know if he s before   it might even be in a week 
 none 	a week  week and a half 
 none 	so  i  huh  i   i guessed that they were gonna do it some time during the semester but they ll do it any time  huh 
 none 	they seem to be   well  the semester actually is starting up 
 none 	is it already 
 none 	yeah  the semester s late   late august they start here 
 none 	yikes 
 none 	so they do it right at the beginning of the semester 
 none 	yeah 
 none 	yeah 
 none 	so  uh   yep  i mean  that   that was sort of one   i mean  the overall results seemed to be first place in   in   in the case of either  um  artificial reverberation or a modest sized training set 
 none 	uh  either way  uh  i  uh  it helped a lot 
 none 	and   but if you had a   a really big training set  a recognizer  uh  system that was capable of taking advantage of a really large training set  
 none 	i thought that   one thing with the h_t_k is that is has the   as we re using   the configuration we re using is w  s  is   being bound by the terms of aurora  we have all those parameters just set as they are  so even if we had a hundred times as much data  we wouldn t go out to  you know  ten or t  or a hundred times as many gaussians or anything  so  um  it s kind of hard to take advantage of   of   of big chunks of data 
 none 	mmm  yeah 
 none 	mm hmm 
 none 	uh  whereas the other one does sort of expand as you have more training data  it does it automatically  actually 
 none 	and so  um  uh  that one really benefited from the larger set  and it was also a diverse set with different noises and so forth  uh  so  um  that  uh   that seemed to be   so  if you have that   that better recognizer that can   that can build up more parameters  and if you  um  have the natural room  which in this case has a p  a pretty bad signal to noise ratio  then in that case  um  the right thing to do is just do   u  use speaker adaptation 
 none 	and   and not bother with   with this acoustic  uh  processing  but i think that that would not be true if we did some explicit noise processing as well as  uh  the convolutional kind of things we were doing 
 none 	mm hmm 
 none 	so 
 none 	that s sort of what we found 
 none 	hmm 
 none 	i  um   uh  started working on the uh  
 none 	mississippi state recognizer 
 none 	oh  o_k 
 find_email 	so   i  got in touch with  joe  and   and  uh  from your email and things like that   and  uh  they added me to the list   uh  the mailing list  and he gave me all of the pointers and everything that i needed  and so i downloaded the  um  
 none 	o_k  great 
 none 	there were two things  uh  that they had to download 
 none 	one was the  uh  i guess the software 
 none 	and another wad   was a  um  sort of like a sample   a sample run 
 none 	so i downloaded the software and compiled all of that  and it compiled fine  no problems 
 none 	eight 
 none 	oh  eh  great 
 none 	and  um  i grabbed the sample stuff but i haven t  uh  compiled it 
 none 	that sample was released only yesterday or the day before  right 
 none 	no   well  i haven t grabbed that one yet  so there s two 
 none 	oh  there is another short sample set   o  o  sample  o_k 
 none 	there was another short one  yeah  and so i haven t grabbed the latest one that he just  uh  put out yet 
 none 	oh  o_k  f  yeah  o_k 
 none 	so 
 none 	um  but  the software seemed to compile fine and everything  so 
 none 	and  um 
 none 	so 
 none 	is there any word yet about the issues about  um  adjustments for different feature sets or anything 
 none 	no  i   i d 
 none 	you asked me to write to him and i think i forgot to ask him about that 
 none 	yeah 
 none 	or if i did ask him  he didn t reply  i   i don t remember yet  
 none 	uh  i ll   i ll d  i ll double check that and ask him again 
 none 	yeah 
 none 	yeah  it s like that   that could r  turn out to be an important issue for us  yeah 
 none 	hmm  mmm 
 none 	yeah  yeah 
 none 	cuz they have it  
 none 	maybe i ll send it to the list 
 none 	yeah 
 none 	cuz they have  uh  already frozen those in i  insertion penalties and all those stuff is what   i feel  because they have this document explaining the recognizer 
 none 	uh huh 
 search 	and they have these  tables with  uh  various language model weights  insertion penalties    u 
 none 	o_k  i haven t seen that one yet 
 none 	uh  it s th  it s there on that web  and  uh  on that  i mean  they have run some experiments using various insertion penalties and all those  
 none 	so 
 none 	o_k 
 none 	and so they ve picked   the values  oh  o_k  o_k 
 none 	yeah  i think they pi  p  yeah  they picked the values from  
 none 	for r  w  what test set 
 none 	uh  p  the one that they have reported is a nist evaluation  wall street journal 
 none 	but that has nothing to do with what we re testing on  right 
 none 	you know  no  so they re  like   um  
 none 	mm hmm 
 none 	so they are actually trying to  uh  fix that   those values using the clean  uh  training part of the wall street journal  which is   i mean  the aurora 
 none 	aurora has a clean subset  i mean  they want to train it and then this   they re going to run some evaluations 
 none 	right 
 none 	so they re set  they re setting it based on that 
 none 	yeah 
 none 	o_k  so now  we may come back to the situation where we may be looking for a modification of the features to account for the fact that we can t modify these parameters  but  um  uh   but it s still worth  i think  just   since   you know  just chatting with joe about the issue 
 none 	yeah 
 none 	yeah 
 none 	yeah  o_k  do you think that s something i should just send to him or do you think i should send it to this   there s an   a m  a mailing list 
 none 	um  
 none 	well  it s not a secret  i mean  we re  you know  certainly willing to talk about it with everybody  but i think   i think that  um   um  it s probably best to start talking with him just to  
 none 	o_k 
 none 	uh  you know  it s a dialogue between two of you about what   you know  what does he think about this and what   what   you know   what could be done about it  um  if you get ten people in   involved in it there ll be a lot of perspectives based on  you know  how   you know  uh   but  i mean  i think it all should come up eventually  but if   if   if there is any  uh  uh  way to move in   a way that would   that would  you know  be more open to different kinds of features  but if   if  uh   if there isn t  and it s just kind of shut down and   and then also there s probably not worthwhile bringing it into a larger forum where   where political issues will come in 
 none 	yeah 
 none 	o_k 
 none 	yeah 
 none 	right 
 none 	o_k 
 none 	yeah 
 none 	o_k 
 none 	oh   so this is now   it s   it s compiled under solaris 
 none 	yeah 
 none 	yeah  o_k  because he   there was some mail r  saying that it s   may not be stable for linux and all those 
 none 	yep 
 none 	yeah 
 none 	yeah  i  that was a particular version 
 none 	susi yeah 
 none 	yeah  susi or whatever it was but we don t have that  so 
 none 	yeah  yeah 
 none 	yeah  o_k 
 none 	o_k  that s fine  yeah 
 none 	should be o_k  yeah  it compiled fine actually  no   no errors  nothing  so 
 none 	that s good 
 none 	uh  this is slightly off topic but  uh 
 none 	i noticed  just glancing at the  uh  hopkins workshop  uh  web site that  uh  um   one of the thing  i don t know   well  we ll see how much they accomplish  but one of the things that they were trying to do in the graphical models thing was to put together a   a  uh  tool kit for doing  uh r  um  arbitrary graphical models for  uh  speech recognition 
 none 	hmm 
 none 	so   and jeff  uh   the two jeffs were
 none 	who s the second jeff 
 search 	uh   oh  uh  do you know  geoff zweig   
 none 	no 
 none 	oh  uh  he   he  uh   he was here for a couple years and he  uh   got his p_h_d  he  
 none 	oh  o_k 
 none 	and he s  uh  been at i_b_m for the last couple years 
 none 	oh  o_k 
 none 	so  uh  so he did   he did his p_h_d on dynamic bayes nets  uh  for   for speech recognition  he had some continuity built into the model  presumably to handle some  um  inertia in the   in the production system  and  um  
 none 	wow  that would be neat 
 none 	hmm 
 none 	so 
 none 	hmm 
 none 	um  i ve been playing with  first  the  um  v_a_d 
 none 	um  so it s exactly the same approach  but the features that the v_a_d neural network use are  uh  m_f_c_c after noise compensation 
 none 	oh  i think i have the results 
 none 	what was it using before 
 none 	before it was just
 none 	p_l_ps  so 
 none 	yeah  it was actually   no  not   i mean  it was just the noisy features i guess  yeah  yeah  yeah  not compensated  
 none 	yeah  noisy   noisy features 
 none 	um  
 none 	this is what we get after  
 none 	this   so  actually  we  yeah  here the features are noise compensated and there is also the l_d_a filter 
 none 	um  and then it s a pretty small neural network which use  um  nine frames of   of six features from c_zero to c_fives  plus the first derivatives 
 none 	and it has one hundred hidden units 
 none 	is that nine frames u  s  uh  centered around the current frame  or  
 none 	yeah  mm hmm 
 none 	s  so  i m   i m sorry  there s   there s   there s how many   how many inputs 
 none 	so it s twelve times nine 
 none 	twelve times nine inputs  and a hundred  uh  hidden 
 none 	hidden and two outputs 
 none 	two outputs 
 none 	two outputs 
 none 	o_k  so i guess about eleven thousand parameters  which   actually shouldn t be a problem  even in   in small phones  yeah 
 none 	mm hmm 
 none 	so  i m   i m   s  so what is different between this and   and what you  
 none 	it should be o_k 
 none 	so the previous syst  it s based on the system that has a fifty three point sixty six percent improvement 
 none 	it s the same system  the only thing that changed is the n  a p  eh   a es  the estimation of the silence probabilities 
 none 	ah  o_k 
 none 	which now is based on  uh  cleaned features 
 none 	and  it s a l  it s a lot better 
 none 	wow 
 none 	yeah  um  
 none 	that s great 
 none 	so it s   it s not bad  but the problem is still that the latency is too large 
 none 	what s the latency 
 none 	because   um   the   the latency of the v_a_d is two hundred and twenty milliseconds 
 none 	and  uh  the v_a_d is used uh  i  for on line normalization  and it s used before the delta computation 
 none 	so if you add these components it goes t  to a hundred and seventy  right 
 none 	i   i m confused  you started off with two twenty and you ended up with one seventy 
 none 	with two an  two hundred and seventy 
 none 	if   yeah  if you add the c  delta comp  delta computation which is done afterwards 
 none 	two seventy 
 none 	oh 
 none 	um  
 none 	so it s two twenty  i  the  is this   are these twenty millisecond frames  is that why  is it after downsampling  or  
 none 	the two twenty is one hundred milliseconds for the um   no  it s forty milliseconds for t  for the  uh  uh  cleaning of the speech 
 none 	um   then there is  um  the neural network which use nine frames  so it adds forty milliseconds 
 none 	a 
 none 	o_k 
 none 	um  after that  um  you have the um  filtering of the silence probabilities 
 none 	which is a million filter it   and it creates a one hundred milliseconds delay 
 none 	so  um  
 none 	plus there is a delta at the input 
 none 	yeah  and there is the delta at the input which is  um  
 none 	one hundred milliseconds for smoothing 
 none 	so it s    
 none 	uh  median 
 none 	it s like forty plus   forty   plus  
 none 	mmm  forty  
 none 	and then forty   forty p 
 none 	this forty plus twenty  plus one hundred 
 none 	so it s two hundred actually 
 none 	uh  
 none 	yeah  there are twenty that comes from  
 none 	there is ten that comes from the l_d_a filters also  right 
 none 	oh  o_k 
 none 	uh  so it s two hundred and ten  yeah 
 none 	if you are using   t  if you are using three frames   if you are phrasing f  using three frames  it is thirty here for delta 
 none 	uh  
 none 	plus the frame  so it s two twenty 
 none 	yeah  i think it s   it s five frames  but 
 none 	so five frames  that s twenty 
 none 	o_k  so it s who un  two hundred and ten 
 none 	uh  p  wait a minute  it s forty   forty for the   for the cleaning of the speech  forty for the i_n_   a_n_n  a hundred for the smoothing 
 none 	so  forty cleaning 
 none 	yeah 
 none 	well  but at ten    
 none 	twenty for the delta 
 none 	at th  at the input  i mean  that s at the input to the net 
 none 	twenty for delta 
 none 	yeah 
 none 	and there i 
 none 	delta at input to net 
 none 	yeah 
 none 	yeah 
 none 	so it s like s  five  six cepstrum plus delta at nine   nine frames of  
 none 	and then ten milliseconds for   ten milliseconds for l_d_a filter  and t  and ten   another ten milliseconds you said for the frame 
 none 	fi  there s an l_d_a filter 
 none 	for the frame i guess  i computed two twenty   yeah  well  it s  
 none 	i guess it s for the fr   the  
 none 	o_k  and then there s delta besides that 
 none 	so this is the features that are used by our network and then afterwards  you have to compute the delta on the  uh  main feature stream  which is um  delta and double deltas  which is fifty milliseconds 
 none 	o_k 
 none 	yeah  no  i mean  the   after the noise part  the forty   the   the other hundred and eighty  
 none 	well  i mean  hhh 
 none 	wait a minute  some of this is  uh   is  uh   is in parallel  isn t it  i mean  the l_d_a  
 none 	oh  you have the l_d_a as part of the v_d_  uh  v_a_d  or  
 none 	the v_a_d use  uh  l_d_a filtered features also 
 none 	oh  it does 
 none 	mm hmm 
 none 	ah 
 none 	so in that case there isn t too much in parallel 
 none 	uh  
 none 	no  there is  um 
 none 	just downsampling  upsampling  and the l_d_a 
 none 	um  so the delta at the end is how much 
 none 	it s  
 none 	it s fifty 
 none 	fifty 
 none 	alright  so  
 none 	but well  we could probably put the delta  um  before on line normalization  it should not that make a big difference  because  
 none 	what if you used a smaller window for the delta 
 none 	could that help a little bit 
 none 	i mean  i guess there s a lot of things you could do to  
 none 	yeah 
 none 	yeah 
 none 	yeah  but  nnn  
 none 	so  yeah  so if you   if you put the delta before the  uh  ana  on line   if   yeah   uh   then   then it could go in parallel  and then y  then you don t have that additive  
 none 	mm hmm  cuz i 
 none 	yep 
 none 	yeah  cuz the time constant of the on line normalization is pretty long compared to the delta window  so 
 none 	o_k 
 none 	it should not make  
 none 	o_k 
 none 	and you ought to be able to shove tw    uh   sh  uh   pull off twenty milliseconds from somewhere else to get it under two hundred  right  i mean  
 none 	mm hmm 
 none 	is two hundred the d 
 none 	the hundred milla  mill  a hundred milliseconds for smoothing is sort of an arbitrary amount  it could be eighty and   and probably do   
 none 	yeah  yeah 
 none 	i  a hun  uh   wh  what s the baseline you need to be under 
 none 	well  we don t know  they re still arguing about it  i mean  if it s two   if   if it s  uh   if it s two fifty  then we could keep the delta where it is if we shaved off twenty  if it s two hundred  if we shaved off twenty  we could   we could  uh  meet it by moving the delta back 
 none 	two hundred 
 none 	oh 
 none 	so  how do you know that what you have is too much if they re still deciding 
 none 	uh  we don t  but it s just   i mean  the main thing is that since that we got burned last time  and   you know  by not worrying about it very much  we re just staying conscious of it 
 none 	uh huh 
 none 	oh  o_k  i see 
 none 	and so  th  i mean  if   if   if a week before we have to be done someone says   well  you have to have fifty milliseconds less than you have now   it would be pretty frantic around here  so  
 none 	ah  o_k 
 none 	uh  
 none 	but still  that s   that s a pretty big  uh  win  and it doesn t seem like you re   in terms of your delay  you re  uh  that  
 none 	he added a bit on  i guess  because before we were   we were   had   were able to have the noise  uh  stuff  uh  and the l_v_a be in parallel  and now he s   he s requiring it to be done first 
 none 	hmm 
 none 	well  but  i think the main thing  maybe  is the cleaning of the speech  which takes forty milliseconds or so 
 none 	and   and   but   the l_d_a is  well  pretty short right now  yeah 
 none 	right  well  so you say   let s say ten milliseconds   seconds for the l_d_a 
 none 	well  ten 
 none 	and then forty for the other 
 none 	yeah  the l_d_a   l_d_a   we don t know  is  like   is it very crucial for the features  right 
 none 	no  i just  
 none 	this is the first try  i mean  i   maybe the l_d_a s not very useful then 
 none 	yeah 
 none 	s  s  h 
 none 	right  so you could start pulling back  but  
 none 	yeah  l 
 none 	but i think you have   i mean  you have twenty for delta computation which y  now you re sort of doing twice  right  but yo  w  were you doing that before 
 none 	mmm 
 none 	on the   in the   mm hmm 
 none 	well  in the proposal  um  the input of the v_a_d network were just three frames  i think 
 none 	just  
 none 	yeah  just the static  no delta 
 none 	uh  static features 
 none 	right 
 none 	so  what you have now is fort  uh  forty for the   the noise  twenty for the delta  and ten for the l_d_a  that s seventy milliseconds of stuff which was formerly in parallel  right 
 none 	so i think  you know  that s   that s the difference as far as the timing  right 
 none 	mm hmm 
 none 	yeah 
 none 	um  and you could experiment with cutting various pieces of these back a bit  but  
 none 	i mean  we re s  we re not   we re not in terrible shape 
 none 	yeah  that s what it seems like to me  it s pretty good 
 none 	mm hmm 
 none 	yeah  it s   it s not like it s adding up to four hundred milliseconds or something 
 none 	where   where is this   where is this fifty seven point o_ two in   in comparison to the last evaluation 
 none 	well  it s   i think it s better than anything  uh  anybody got 
 none 	yeah 
 none 	oh  is that right 
 none 	the best was fifty four point five 
 none 	yeah 
 none 	point s 
 none 	oh 
 none 	yeah  uh 
 none 	and our system was forty nine  but with the neural network 
 none 	wow  so this is almost ten percent 
 none 	with the f  with the neural net  yeah  and r  and  
 none 	yeah  so this is   this is like the first proposal  the proposal  one  it was forty four  actually 
 none 	it would 
 none 	yeah  yeah  and we still don t have the neural net in  so   so it s   you know  so it s  
 none 	wow 
 none 	we re   we re doing better  i mean  we re getting better recognition  i mean  i m sure other people working on this are not sitting still either  but   but   but  uh  
 none 	this is   this is really good 
 none 	yeah 
 none 	uh  i mean  the important thing is that we learn how to do this better  and  you know  so 
 none 	um 
 none 	yeah  so  our  um  
 none 	yeah  you can see the kind of   kind of numbers that we re having  say  on speechdat car which is a hard task  cuz it s really  um   i think it s just sort of   sort of reasonable numbers  starting to be 
 none 	mm hmm 
 none 	i mean  it s still terri 
 none 	yeah  even for a well matched case it s sixty percent error rate reduction  which is  
 none 	yeah 
 none 	yeah  probably half 
 none 	good 
 none 	um 
 none 	yeah 
 none 	so actually  this is in between what we had with the previous v_a_d and what sunil did with an i_d_l v_a_d 
 none 	which gave sixty two percent improvement  right 
 none 	yeah  it s almost that  it s almost an average somewhere around   yeah 
 none 	so  
 none 	yeah 
 none 	what was that  say that last part again 
 none 	so  if you use  like  an i_d_l v_a_d  uh  for dropping the frames  the best that we can get   i  that means that we estimate the silence probability on the clean version of the utterances 
 none 	o  o 
 none 	or the best we can get 
 none 	then you can go up to sixty two percent error rate reduction  globally 
 none 	mmm 
 none 	mmm  
 none 	yeah 
 none 	so that would be even   that wouldn t change this number down here to sixty two 
 none 	yeah 
 none 	yeah  so you   you were get 
 none 	if you add a g  good v  very good v_a_d  that works as well as a v_a_d working on clean speech  then you wou  you would go  
 none 	yeah 
 none 	yeah 
 none 	so that s sort of the best you could hope for 
 none 	mm hmm 
 none 	i see 
 none 	probably  yeah 
 none 	so fi  si  fifty three is what you were getting with the old v_a_d 
 none 	yeah 
 none 	and  uh   and sixty two with the   the  you know  quote  unquote  cheating v_a_d  and fifty seven is what you got with the real v_a_d 
 none 	mm hmm 
 none 	that s great 
 none 	uh  yeah  the next thing is  i started to play  
 none 	well  i don t want to worry too much about the delay  no  maybe it s better to wait for the decision from the committee 
 none 	o_k 
 none 	yeah 
 none 	uh  but i started to play with the  um  uh  tandem neural network 
 none 	mmm
 none 	i just did the configuration that s very similar to what we did for the february proposal 
 none 	and  
 none 	um  so  there is a f  a first feature stream that use uh straight
 none 	m_f_c_c features 
 none 	mm hmm 
 none 	well  these features actually 
 none 	and the other stream is the output of a neural network  using as input  also  these  um  cleaned
 none 	m_f_c_c 
 none 	um  
 none 	i don t have the comp  mmm 
 none 	those are th  those are th  what is going into the tandem net 
 none 	those two 
 none 	so there is just this feature stream  the fifteen m_f_c_c plus delta and double delta 
 none 	no 
 none 	yeah 
 none 	um  so it s   makes forty five features that are used as input to the h_t_k 
 none 	and then  there is   there are more inputs that comes from the tandem m_l_p 
 none 	oh  oh  o_k  i see 
 none 	yeah  h  he likes to use them both  cuz then it has one part that s discriminative  one part that s not 
 none 	uh  huh 
 none 	yeah  um  
 none 	right  o_k 
 none 	so  um  uh  yeah  right now it seems that   i  i just tested on speechdat car while the experiment are running on your   on t_i digits 
 none 	well  it improves on the well matched and the mismatched conditions  but it get worse on the highly mismatched 
 none 	um 
 none 	compared to these numbers 
 none 	compared to these numbers  yeah 
 none 	um  like  on the well match and medium mismatch  the gain is around five percent relative  but it goes down a lot more  like fifteen percent on the h_m case 
 none 	y 
 none 	you re just using the full ninety features 
 none 	the   i 
 none 	y  you have ninety features 
 none 	i have  um  
 none 	from the networks  it s twenty eight  so  
 none 	and from the other side it s forty five  so it s   you have seventy three features  and you re just feeding them like that 
 none 	so  d  i  it s forty five  yeah 
 none 	yeah 
 none 	mm hmm 
 none 	there isn t any k_l_t or anything 
 none 	there s a k_l_t after the neural network  as   as before 
 none 	that s how you get down to twenty eight 
 none 	yeah 
 none 	why twenty eight 
 none 	i don t know  uh  it s   i  i  i  it s because it s what we did for the first proposal  we tested  uh  trying to go down and yeah 
 none 	oh 
 none 	ah 
 none 	it s a multiple of seven 
 none 	yeah  yeah  yeah 
 none 	so  
 none 	um 
 none 	i wanted to do something very similar to the proposal as a first   first try 
 none 	i see 
 none 	yeah 
 none 	yeah  that makes sense 
 none 	but we have to   for sure  we have to go down  because the limit is now sixty features  so  uh  we have to find a way to decrease the number of features 
 none 	yeah 
 none 	um  
 none 	so  it seems funny that  
 none 	i don t know  maybe i don t u  quite understand everything  but that adding features  
 none 	i guess   i guess if you re keeping the back end fixed 
 none 	maybe that s it  because it seems like just adding information shouldn t give worse results  but i guess if you re keeping the number of gaussians fixed in the recognizer  then  
 none 	well  yeah  but  i mean  just in general  adding information  
 none 	mmm 
 none 	suppose the information you added  well   was a really terrible feature and all it brought in was noise 
 none 	yeah 
 none 	right  so   so  um  
 none 	or   or suppose it wasn t completely terrible  but it was completely equivalent to another one feature that you had  except it was noisier 
 none 	uh huh 
 none 	right  in that case you wouldn t necessarily expect it to be better at all 
 none 	oh  yeah  i wasn t necessarily saying it should be better 
 none 	i m just surprised that you re getting fifteen percent relative worse on the wel  on the highly mismatch  yeah 
 none 	uh huh 
 none 	but it s worse 
 none 	on the highly mismatched condition 
 none 	yeah  i  
 none 	so   highly mismatched condition  means that in fact your training is a bad estimate of your test 
 none 	uh huh 
 none 	so having   having  uh  a g  a l  a greater number of features  if they aren t maybe the right features that you use  certainly can e  can easily  uh  make things worse 
 none 	i mean  you re right  if you have   if you have  uh  lots and lots of data  and you have   and your   your   your training is representative of your test  then getting more sources of information should just help  but   but it s  
 none 	it doesn t necessarily work that way 
 none 	huh 
 none 	mm hmm 
 none 	so i wonder  um 
 none 	well  what s your   what s your thought about what to do next with it 
 none 	um  i don t know  i m surprised  because
 none 	i expected the neural net to help more when there is more mismatch  as it was the case for the  
 none 	so  was the training set same as the p  the february proposal 
 none 	mm hmm 
 none 	yeah  it s the same training set  so it s timit with the t_i digits   uh  noises  uh  added 
 none 	o_k 
 none 	mm hmm 
 none 	um  
 create_single_reminder 	well  we might   uh  we might have to experiment with  uh better training sets  again  but  i   the other thing is  i mean  before you found that was the best configuration  but you might have to retest those things now that we have different  
 none 	mm hmm 
 none 	the rest of it is different  right  so  um  uh 
 none 	for instance  what s the effect of just putting the neural net on without the o  other   other path 
 none 	mm hmm 
 none 	yeah 
 none 	i mean  you know what the straight features do  that gives you this 
 none 	mm hmm 
 none 	you know what it does in combination 
 none 	you don t necessarily know what  
 none 	what if you did the   would it make sense to do the k_l_t on the full set of combined features 
 none 	instead of just on the  
 none 	yeah  i g  i guess  um  the reason i did it this ways is that in february  it   we   we tested different things like that  so  having two k_l_t  having just a k_l_t for a network  or having a global k_l_t 
 none 	oh  i see 
 none 	and  
 none 	so you tried the global k_l_t before and it didn t really  
 none 	well  
 none 	yeah  and  uh  th  yeah  the differences between these configurations were not huge  but   it was marginally better with this configuration 
 none 	i see 
 none 	uh huh  uh huh 
 none 	but  yeah  that s obviously another thing to try  since things are   things are different  and i guess if the  
 none 	um 
 none 	mm hmm  mm hmm 
 none 	these are all   so all of these seventy three features are going into  um  the  uh   the h_m_m 
 none 	yeah 
 none 	and is   are   i  i  are   are any deltas being computed of tha  of them 
 none 	of the straight features  yeah 
 none 	so 
 none 	n  not of the  
 none 	but n  th  the  um  tandem features are u  used as they are  so  yeah  maybe we can add some context from these features also as  
 none 	are not 
 none 	could  i 
 none 	dan did in   in his last work 
 none 	yeah  but the other thing i was thinking was  um  
 none 	uh  now i lost track of what i was thinking  but 
 none 	what is the  
 none 	you said there was a limit of sixty features or something 
 none 	mm hmm 
 none 	what s the relation between that limit and the  um  forty eight   uh  forty eight hundred bits per second 
 none 	oh  i know what i was gonna say 
 none 	um  not   no relation  the f  the forty eight hundred bits is for transmission of some features 
 none 	no relation 
 none 	so i   i   i don t understand  because i 
 none 	i mean  if you re only using h 
 none 	and generally  i  it   s  allows you to transmit like  fifteen  uh  cepstrum 
 none 	the issue was that  um  this is supposed to be a standard that s then gonna be fed to somebody s recognizer somewhere which might be  you know  it   it might be a concern how many parameters are use   u  used and so forth  and so  uh  they felt they wanted to set a limit 
 none 	so they chose sixty 
 none 	some people wanted to use hundreds of parameters and   and that bothered some other people  u  and so they just chose that  i   i   i think it s kind of r  arbitrary too  but   but that s   that s kind of what was chosen  i   i remembered what i was going to say  what i was going to say is that  um  maybe   maybe with the noise removal  uh  these things are now more correlated 
 none 	uh huh 
 none 	so you have two sets of things that are kind of uncorrelated  uh  within themselves  but they re pretty correlated with one another 
 none 	mm hmm 
 none 	and  um  they re being fed into these  uh  variants  only gaussians and so forth  and   and  uh  so maybe it would be a better idea now than it was before to  uh  have  uh  one k_l_t over everything  to de correlate it 
 none 	mm hmm 
 none 	mm hmm 
 none 	yeah  i see 
 none 	maybe  you know  
 none 	what are the s_n_rs in the training set  timit 
 none 	it s  uh  ranging from zero to clean 
 none 	mm hmm 
 none 	yeah  from zero to clean 
 none 	yeah 
 none 	so we found this   this  uh   this macrophone data  and so forth  that we were using for these other experiments  to be pretty good  so that s   i  after you explore these other alternatives  that might be another way to start looking  is   is just improving the training set 
 none 	mm hmm 
 none 	mm hmm 
 none 	i mean  we were getting  uh  lots better recognition using that  than  
 none 	of course  you do have the problem that  um  u  i  we are not able to increase the number of gaussians  uh  or anything to  uh  uh  to match anything  so we re only improving the training of our feature set  but that s still probably something 
 none 	so you re saying  add the macrophone data to the training of the neural net  the tandem net 
 none 	yeah  that s the only place that we can train  we can t train the other stuff with anything other than the standard amount  so 
 none 	yeah 
 none 	right 
 none 	um  um  
 none 	what   what was it trained on again  the one that you used 
 none 	it s timit with noise 
 none 	uh huh 
 none 	so  yeah  it s rather a small  
 none 	yeah 
 none 	how big is the net  by the way 
 none 	um 
 none 	uh  it s  uh  five hundred hidden units  and  
 none 	and again  you did experiments back then where you made it bigger and it   and that was   that was sort of the threshold point  much less than that  it was worse  and much more than that  it wasn t much better 
 none 	yeah 
 none 	yeah 
 none 	hmm 
 none 	so is it   is it though the performance  big relation in the high ma  high mismatch has something to do with the  uh  cleaning up that you   that is done on the timit after adding noise  so   it s   i  all the noises are from the t_i digits  right 
 none 	yeah    
 none 	yeah 
 none 	so you   i 
 none 	um  
 none 	well  it  it s like the high mismatch of the speechdat car after cleaning up  maybe having more noise than the   the training set of timit after clean   s  after you do the noise clean up 
 none 	they   k  uh  
 none 	mmm 
 none 	i mean  earlier you never had any compensation  you just trained it straight away 
 none 	mm hmm 
 none 	so it had like all these different conditions of s_n_rs  actually in their training set of neural net 
 none 	mm hmm 
 none 	mm hmm 
 none 	but after cleaning up you have now a different set of s_n_rs  right 
 none 	for the training of the neural net 
 none 	yeah 
 none 	mm hmm 
 none 	and   is it something to do with the mismatch that   that s created after the cleaning up  like the high mismatch  
 none 	you mean the   the most noisy occurrences on speechdat car might be a lot more noisy than  
 none 	mm hmm 
 none 	of   that   i mean  the s_n_r after the noise compensation of the speechdat car 
 none 	oh  so   right  so the training   the   the neural net is being trained with noise compensated stuff  which makes sense  but  uh  you re saying   yeah  the noisier ones are still going to be  even after our noise compensation  are still gonna be pretty noisy 
 none 	maybe 
 none 	yeah 
 none 	yeah  yeah 
 none 	yeah 
 none 	yeah 
 none 	mm hmm 
 none 	yeah  so now the after noise compensation the neural net is seeing a different set of s_n_rs than that was originally there in the training set 
 none 	of timit  because in the timit it was zero to some clean 
 none 	right 
 none 	so the net saw all the s_n_r conditions  now after cleaning up it s a different set of s_n_r 
 none 	yes 
 none 	right 
 none 	right 
 none 	and that s_n_r may not be  like  com  covering the whole set of s_n_rs that you re getting in the speechdat car 
 none 	right  but the speechdat car data that you re seeing is also reduced in noise by the noise compensation 
 none 	yeah  yeah  yeah  yeah  it is  but  i m saying  there could be some   some issues of  
 none 	yeah 
 none 	so 
 none 	mm hmm 
 none 	yeah 
 none 	well  if the initial range of s_n_r is different  we   the problem was already there before  and  
 none 	yeah 
 none 	because  
 none 	mmm  
 none 	yeah  i mean  it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set  uh  
 none 	hmm 
 none 	on the test set  yeah 
 none 	right  i mean  you re saying there s a mismatch in noise that wasn t there before  but if they were both the same before  then if they were both reduic  reduced equally  then  there would not be a mismatch 
 none 	hmm 
 none 	mm hmm 
 none 	mm hmm 
 none 	so  i mean  this may be  
 none 	heaven forbid  this noise compensation process may be imperfect  but  uh  so maybe it s treating some things differently 
 none 	well  i  
 none 	yeah  uh  
 none 	i don t know  i   i just   that could be seen from the t_i digits  uh  testing condition because  um  the noises are from the t_i digits  right  noise  
 none 	yeah  so  
 none 	so cleaning up the t_i digits and if the performance goes down in the t_i digits mismatch   high mismatch like this   on a clean training  or zero d_b testing 
 none 	clean training  yeah 
 none 	yeah  we ll   so we ll see  uh  maybe 
 none 	yeah  then it s something to do 
 none 	mm hmm  yeah 
 none 	i mean  one of the things about   i mean  the macrophone data  um  i think  you know  it was recorded over many different telephones 
 none 	mm hmm 
 none 	and  um  so  there s lots of different kinds of acoustic conditions 
 none 	i mean  it s not artificially added noise or anything 
 none 	so it s not the same  i don t think there s anybody recording over a car from a car  but   i think it s   it s varied enough that if   if doing this adjustments  uh  and playing around with it doesn t  uh  make it better  the most   uh  it seems like the most obvious thing to do is to improve the training set 
 none 	um   i mean  what we were   uh   the condition   it   it gave us an enormous amount of improvement in what we were doing with meeting recorder digits  even though there  again  these m  macrophone digits were very  very different from  uh  what we were going on here  i mean  we weren t talking over a telephone here 
 none 	but it was just   i think just having a   a nice variation in acoustic conditions was just a good thing 
 none 	mm hmm 
 none 	mmm 
 none 	yep 
 none 	yeah  actually to s  eh  what i observed in the h_m case is that the number of deletion dramatically increases  it   it doubles 
 none 	number of deletions 
 none 	when i added the num  the neural network it doubles the number of deletions 
 none 	yeah  so i don t you know how to interpret that  but  mmm  
 none 	yeah  me either 
 none 	t 
 none 	and   and did   an  other numbers stay the same  insertion substitutions stay the same 
 none 	they p  stayed the same  they   maybe they are a little bit uh  lower 
 none 	roughly 
 none 	uh huh 
 none 	they are a little bit better  yeah  but  
 none 	mm hmm 
 none 	did they increase the number of deletions even for the cases that got better  say  for the   i mean  it   so it s only the highly mismatched 
 none 	no  it doesn t  no 
 none 	and it   remind me again  the  highly mismatched  means that the  
 none 	clean training and  
 none 	uh  sorry 
 none 	it s clean training   well  close microphone training and distant microphone  um  high speed  i think  well  
 none 	close mike training  
 none 	the most noisy cases are the distant microphone for testing 
 none 	right 
 none 	so  
 none 	well  maybe the noise subtraction is subtracting off speech  wh 
 none 	separating  
 none 	yeah 
 none 	but   yeah 
 none 	i mean  but without the neural network it s   well  it s better  it s just when we add the neural networks  the feature are the same except that  
 none 	yeah  right  uh  that s right  that s right  um  
 none 	well that   that says that  you know  the  um   the models in   in  uh  the recognizer are really paying attention to the neural net features 
 none 	yeah  mm hmm 
 none 	uh 
 none 	but  yeah  actually   the timit noises are sort of a range of noises and they re not so much the stationary driving kind of noises  right  it s   it s pretty different  isn t it 
 none 	uh  there is a car noise  so there are f  just four noises  um  uh   car   i think 
 none 	 babble  
 none 	 babble    subway   right  and   and    street  isn t     train station   yeah 
 none 	 street  or  airport  or something 
 none 	or  train station  
 none 	yeah 
 none 	so   it s mostly   well   car  is stationary 
 none 	mm hmm 
 none 	 babble   it s a stationary background plus some voices  some speech over it  and the other two are rather stationary also 
 none 	mm hmm 
 none 	well  i   i think that if you run it  
 none 	actually  you   maybe you remember this  when you   in   in the old experiments when you ran with the neural net only  and didn t have this side path  um  uh  with the   the pure features as well  did it make things better to have the neural net  was it about the same 
 none 	mm hmm 
 none 	uh  w  i 
 none 	it was   b  a little bit worse 
 none 	than    
 none 	than just the features  yeah 
 none 	so  until you put the second path in with the pure features  the neural net wasn t helping at all 
 none 	mm hmm 
 none 	well  that s interesting 
 none 	it was helping  uh  if the features are b  were bad  i mean 
 none 	yeah 
 none 	just plain p_l_ps or m_f_c_cs 
 none 	yeah 
 none 	but as soon as we added l_d_a on line normalization  and all these things  then  
 none 	they were doing similar enough things 
 none 	well  i still think it would be k  sort of interesting to see what would happen if you just had the neural net without the side thing  and   and the thing i   i have in mind is  uh  maybe you ll see that the results are not just a little bit worse  maybe that they re a lot worse 
 none 	yeah  mm hmm 
 none 	you know  and  um  
 none 	but if on the ha  other hand  uh  it s  say  somewhere in between what you re seeing now and   and   and  uh  what you d have with just the pure features  then maybe there is some problem of a   of a  uh  combination of these things  or correlation between them somehow 
 none 	mm hmm 
 none 	if it really is that the net is hurting you at the moment  then
 none 	i think the issue is to focus on   on  uh  improving the   the net 
 none 	yeah  mm hmm 
 none 	um 
 none 	so what s the overall effe  i mean  you haven t done all the experiments but you said it was i  somewhat better  say  five percent better  for the first two conditions  and fifteen percent worse for the other one 
 none 	but it s   but of course that one s weighted lower  so i wonder what the net effect is 
 none 	y  yeah  oh  yeah 
 none 	i d  i  
 none 	i think it s   it was one or two percent 
 none 	that s not that bad  but it was l  like two percent relative worse on speechdat car 
 none 	i have to   to check that  well  i have   i will 
 none 	well  it will   overall it will be still better even if it is fifteen percent worse  because the fifteen percent worse is given like f  w  twenty five   point two five eight 
 none 	right 
 none 	mm hmm 
 none 	hmm 
 none 	right  so the   so the worst it could be  if the others were exactly the same  is four  and   and  uh  in fact since the others are somewhat better  
 none 	is it like  
 none 	yeah  so it s four 
 none 	is i 
 none 	so either it ll get cancelled out  or you ll get  like  almost the same 
 none 	yeah  it was   it was slightly worse  um 
 none 	uh 
 none 	slightly bad 
 none 	yeah 
 none 	yeah  it should be pretty close to cancelled out 
 none 	yeah 
 none 	mm hmm 
 none 	you know  i ve been wondering about something  in the  um   a lot of the  um   the hub five systems  um  recently have been using l_d_a  and   and they  um  
 none 	they run l_d_a on the features right before they train the models 
 none 	so there s the   the l_d_a is   is right there before the h_m_ms 
 none 	yeah 
 none 	so  you guys are using l_d_a but it seems like it s pretty far back in the process 
 none 	uh  this l_d_a is different from the l_d_a that you are talking about  the l_d_a that you   saying is  like  you take a block of features  like nine frames or something  and then do an l_d_a on it  and then reduce the dimensionality to something like twenty four or something like that 
 none 	yeah 
 none 	uh huh 
 none 	and then feed it to h_m_m 
 none 	yeah  you c  you c  you can  i mean  it s   you know  you re just basically i 
 none 	yeah  so this is like a two d  two dimensional tile  
 none 	you re shifting the feature space  yeah 
 none 	so this is a two dimensional tile  
 none 	and the l_d_a that we are f  applying is only in time  not in frequency   high cost frequency  so it s like   more like a filtering in time  rather than doing a r 
 none 	ah  o_k 
 none 	so what i  what about  um   i  u  what i  w  i mean  i don t know if this is a good idea or not  but what if you put   ran the other kind of l_d_a  uh  on your features right before they go into the h_m_m 
 none 	uh  it  
 none 	m 
 none 	mm hmm  no  actually  i think   i  well  what do we do with the a_n_n is   is something like that except that it s not linear  but it s   it s like a nonlinear discriminant analysis  but 
 none 	yeah 
 none 	right  it s the   it s   right  the   so   yeah  so it s sort of like   the tandem stuff is kind of like i  nonlinear l_d_a  i g  yeah 
 none 	yeah  it s  
 none 	yeah 
 none 	yeah 
 none 	uh 
 none 	but i mean  w  but the other features that you have  um  th  the non  tandem ones 
 none 	mm hmm 
 none 	yeah  i know  that   that   yeah  well  in the proposal  they were transformed u  using p_c_a  but  
 none 	uh huh 
 none 	yeah  it might be that l_d_a could be better 
 none 	the a  the argument i  is kind of i  in   and it s not like we really know  but the argument anyway is that  um  uh  we always have the prob  i mean  discriminative things are good  l_d_a  neural nets  they re good 
 none 	yeah 
 none 	uh  they re good because you   you   you learn to distinguish between these categories that you want to be good at distinguishing between 
 none 	and p_c_a doesn t do that  it   p_a_c  p_c_a   low order p_c_a throws away pieces that are uh  maybe not   not gonna be helpful just because they re small  basically 
 none 	right 
 none 	but  uh  the problem is  training sets aren t perfect and testing sets are different 
 none 	so you f  you   you face the potential problem with discriminative stuff  be it l_d_a or neural nets  that you are training to discriminate between categories in one space but what you re really gonna be g  getting is   is something else 
 none 	uh huh 
 none 	and so  uh  stephane s idea was  uh  let s feed  uh  both this discriminatively trained thing and something that s not 
 none 	so you have a good set of features that everybody s worked really hard to make  and then  uh  you   you discriminately train it  but you also take the path that   that doesn t have that  and putting those in together 
 none 	yeah 
 none 	uh huh 
 none 	and that   that seem  so it s kind of like a combination of the   uh  what  uh  dan has been calling  you know  a feature   uh  you know  a feature combination versus posterior combination or something  it s   it s  you know  you have the posterior combination but then you get the features from that and use them as a feature combination with these   these other things 
 none 	and that seemed  at least in the last one  as he was just saying  he   he   when he only did discriminative stuff  i  it actually was   was   it didn t help at all in this particular case  there was enough of a difference  i guess  between the testing and training 
 none 	yeah 
 none 	but by having them both there   the fact is some of the time  the discriminative stuff is gonna help you 
 none 	mm hmm 
 none 	and some of the time it s going to hurt you  and by combining two information sources if  you know   if   if  
 none 	right 
 none 	so you wouldn t necessarily then want to do l_d_a on the non tandem features because now you re doing something to them that  
 none 	that i  i 
 none 	i think that s counter to that idea  now  again  it s   we re just trying these different things  we don t really know what s gonna work best  but if that s the hypothesis  at least it would be counter to that hypothesis to do that 
 none 	yeah  right 
 none 	right 
 none 	um  and in principle you would think that the neural net would do better at the discriminant part than l_d_a 
 none 	right 
 none 	yeah  well   y 
 none 	though  maybe not 
 none 	yeah  exactly  i mean  we  uh   we were getting ready to do the tandem  uh  stuff for the hub  five system  and  um  andreas and i talked about it  and the idea w  the thought was   well  uh  yeah  that i  you know   th  the neural net should be better  but we should at least have uh  a number  you know  to show that we did try the l_d_a in place of the neural net  so that we can you know  show a clear path  you know  that you have it without it  then you have the l_d_a  then you have the neural net  and you can see  theoretically  so 
 none 	right 
 none 	i was just wondering   i   i  
 none 	well  i think that s a good idea 
 none 	yeah 
 none 	did   did you do that or   tha  that s a  
 none 	um  no  that s what   that s what we re gonna do next as soon as i finish this other thing  so 
 none 	yeah  yeah  no  well  that s a good idea 
 none 	i   i   i  yeah 
 none 	we just want to show  i mean  it   everybody believes it  but you know  we just  
 none 	oh  no it s a g 
 none 	no  no  but it might not   not even be true  i mean  it s   it s   it s   it s   it s a great idea  i mean  one of the things that always disturbed me  uh  in the   the resurgence of neural nets that happened in the eighties was that  um  a lot of people   because neural nets were pretty easy to   to use   a lot of people were just using them for all sorts of things without  uh  looking at all into the linear  uh   uh  versions of them  and  uh  people were doing recurrent nets but not looking at i_i_r filters  and   you know  i mean  uh  so i think  yeah  it s definitely a good idea to try it 
 none 	yeah 
 none 	yeah 
 none 	mm hmm 
 none 	yeah 
 none 	yeah  and everybody s putting that on their systems now  and so  i  that s what made me wonder about this  but 
 none 	well  they ve been putting them in their systems off and on for ten years  but   but   but  uh 
 none 	yeah  what i mean is it s   it s like in the hub five evaluations  you know  and you read the system descriptions and everybody s got  you know  l_d_a on their features  and so  uh 
 none 	and now they all have that 
 none 	i see 
 none 	yeah 
 none 	it s the transformation they re estimating on  
 none 	well  they are trained on the same data as the final h_m_m are 
 none 	yeah  so it s different  yeah  exactly  cuz they don t have these  you know  mismatches that   that you guys have  so that s why i was wondering if maybe it s not even a good idea  i don t know 
 none 	mm hmm 
 none 	mm hmm 
 none 	i   i don t know enough about it  but   um 
 none 	mm hmm 
 none 	i mean  part of why   i   i think part of why you were getting into the k_l_t   y  you were describing to me at one point that you wanted to see if  uh  you know  getting good orthogonal features was   and combining the   the different temporal ranges   was the key thing that was happening or whether it was this discriminant thing  right  so you were just trying  
 none 	i think you r  i mean  this is   it doesn t have the
 none 	l_d_a aspect but th  as far as the orthogonalizing transformation  you were trying that at one point  right 
 none 	mm hmm 
 none 	mm hmm 
 none 	i think you were 
 none 	yeah 
 none 	does something  it doesn t work as well 
 none 	yeah 
 none 	yeah 
 none 	so  yeah  i ve been exploring a parallel v_a_d without neural network with  like  less latency using s_n_r and energy  um  after the cleaning up 
 none 	so what i d been trying was  um  uh  
 none 	after the b  after the noise compensation  n  i was trying t  to f  find a f  feature based on the ratio of the energies  that is  cl  after clean and before clean 
 none 	so that if   if they are  like  pretty c  close to one  which means it s speech  and if it is n  if it is close to zero  which is  
 none 	so it s like a scale  probability value 
 none 	so i was trying  uh  with full band and multiple bands  m  ps  uh   separating them to different frequency bands and deriving separate decisions on each bands  and trying to combine them 
 none 	uh  the advantage being like it doesn t have the latency of the neural net if it   if it can g  and it gave me like  uh  one point  
 none 	mm hmm 
 none 	one   more than one percent relative improvement  so  from fifty three point six it went to fifty f  four point eight  so it s  like  only slightly more than a percent improvement  just like  
 none 	mm hmm 
 none 	which means that it s   it s doing a slightly better job than the previous v_a_d  uh  at a l  lower delay 
 none 	mm hmm 
 none 	mm hmm 
 none 	um  so  um   so   u 
 none 	but   i  d  i m sorry  does it still have the median filter stuff 
 none 	it still has the median filter  so  
 none 	so it still has most of the delay  it just doesn t  
 none 	yeah  so d  with the delay  that s gone is the input  which is the sixty millisecond 
 none 	the forty plus twenty 
 none 	at the input of the neural net you have this  uh  f  nine frames of context plus the delta 
 none 	well  w  i 
 none 	mm hmm 
 none 	oh  plus the delta  right  o_k 
 none 	yeah  so that delay  plus the l_d_a 
 none 	mm hmm 
 none 	uh  so the delay is only the forty millisecond of the noise cleaning  plus the hundred millisecond smoothing at the output 
 none 	mm hmm  mm hmm 
 none 	um 
 none 	so  yeah  so the   the   di  the biggest  
 none 	the problem f  for me was to find a consistent threshold that works well across the different databases  because i t 
 none 	i try to make it work on tr  speechdat car and it fails on t_i digits  or if i try to make it work on that it s just the italian or something  it doesn t work on the finnish 
 none 	mm hmm 
 none 	mm hmm 
 none 	so  um 
 none 	so there are   there was  like  some problem in balancing the deletions and insertions when i try different thresholds  so  
 none 	mm hmm 
 none 	the  
 none 	i m still trying to make it better by using some other features from the   after the p  clean up   maybe  some  uh  correlation   auto correlation or some s  additional features of   to mainly the improvement of the vad  
 none 	i ve been trying 
 none 	now this   this   this  uh 
 none 	 before and after clean   it sounds like you think that s a good feature 
 none 	that   that  it   you th  think that the  uh   the   i  it appears to be a good feature  right 
 none 	mm hmm  yeah 
 none 	what about using it in the neural net 
 none 	yeah  eventually we could   could just
 none 	yeah  so   yeah  so that s the   yeah  so we ve been thinking about putting it into the neural net also 
 none 	yeah 
 none 	because they did   that itself  
 none 	then you don t have to worry about the thresholds and   but just  
 none 	there s a threshold and   yeah  yeah  so that   that s  uh  
 none 	yeah 
 none 	yeah  so if we   if we can live with the latency or cut the latencies elsewhere  then   then that would be a  uh  good thing  um  anybody   has anybody   you guys or   or naren   uh  somebody  tried the  uh  um  second th  second stream thing 
 none 	yeah  yeah 
 none 	uh 
 none 	oh  i just   i just h  put the second stream in place and  uh ran one experiment  but just like   just to know that everything is fine 
 none 	uh huh 
 none 	so it was like  uh  forty five cepstrum plus twenty three mel   log mel 
 none 	yeah 
 none 	and   and   just  like  it gave me the baseline performance of the aurora  which is like zero improvement 
 none 	yeah 
 none 	yeah 
 none 	so i just tried it on italian just to know that everything is   but i   i didn t export anything out of it because it was  like  a weird feature set 
 none 	yeah 
 none 	so 
 none 	yeah  well  what i think  you know  would be more what you d want to do is   is   is  uh  put it into another neural net 
 none 	yeah  yeah  yeah  yeah 
 none 	mm hmm 
 none 	right  and then  
 none 	but  yeah  we re   we re not quite there yet  so we have to figure out the neural nets  i guess 
 none 	yeah 
 none 	the uh  other thing i was wondering was  um  if the neural net  um  has any   because of the different noise con  unseen noise conditions for the neural net  where  like  you train it on those four noise conditions  while you are feeding it with  like  a  additional   some four plus some   f  few more conditions which it hasn t seen  actually  from the   f  f  while testing  um   instead of just h  having c  uh  those cleaned up t  cepstrum  sh  should we feed some additional information  like  
 none 	mm hmm 
 none 	yeah  yeah  right 
 none 	the   the   we have the v_a_d flag  i mean  should we f  feed the v_a_d flag  also  at the input so that it   it has some additional discriminating information at the input 
 none 	hmm  hmm  um  
 none 	wh  uh  the   the v_a_d what 
 none 	we have the v_a_d information also available at the back end 
 none 	uh huh 
 none 	so if it is something the neural net is not able to discriminate the classes  
 none 	yeah 
 none 	i mean  
 none 	because most of it is sil 
 none 	i mean  we have dropped some silence f 
 none 	we have dropped so  silence frames  no  we haven t dropped silence frames still 
 none 	mm hmm 
 none 	uh  still not  yeah 
 none 	yeah  so   the b  b  biggest classification would be the speech and silence 
 none 	th 
 none 	so  by having an additional  uh  feature which says  this is speech and this is nonspeech    i mean  it certainly helps in some unseen noise conditions for the neural net 
 none 	what  
 none 	do y  do you have that feature available for the test data 
 none 	well  i mean  we have   we are transferring the v_a_d to the back end   feature to the back end  because we are dropping it at the back end after everything   all the features are computed  so   so the neural   so that is coming from a separate neural net or some v_a_d 
 none 	oh  oh  i see  i see 
 none 	o_k  o_k 
 none 	which is   which is certainly giving a to   yeah  so it  it s an   additional discriminating information 
 none 	so you re saying  feed that  also  into the neural net  yeah  yeah 
 none 	right 
 create_single_reminder 	you  could  feed it into the neural net     the other thing  you  could do is  just  um  p  modify the  uh  output probabilities of the   of the  uh  uh  um  neural net  tandem neural net  based on the fact that you have a silence probability   
 none 	so that  
 none 	mm hmm 
 none 	right 
 none 	mm hmm 
 create_single_reminder 	so you have an independent estimator of what the silence probability is  and  you  could  multiply the two things  and renormalize   
 none 	uh  i mean  you d have to do the nonlinearity part and deal with that  uh  i mean  go backwards from what the nonlinearity would  you know   would be  but   but  uh  
 none 	yeah 
 none 	through   t  to the soft max  
 none 	yeah  so   maybe  yeah  when  
 none 	but in principle wouldn t it be better to feed it in  and let the net do that 
 none 	well  u  not sure 
 none 	i mean  let s put it this way  i mean  y  you   you have this complicated system with thousands and thousand parameters and you can tell it  uh    learn this thing   
 none 	hmm 
 none 	yeah 
 none 	or you can say   it s silence  go away   
 none 	i mean  i mean  i  doesn t     i think   i think the second one sounds a lot more direct  uh 
 none 	what   what if you   right 
 none 	so  what if you then  uh   since you know this  what if you only use the neural net on the speech portions 
 none 	well  uh 
 none 	that s what  
 none 	well  i guess that s the same  uh  that s similar 
 none 	yeah  i mean  y  you d have to actually run it continuously  but it s     
 none 	but i mean   i mean  train the net only on  
 none 	well  no  you want to train on   on the nonspeech also  because that s part of what you re learning in it  to   to   to generate  that it s   it has to distinguish between 
 none 	speech 
 none 	but i mean  if you re gonna   if you re going to multiply the output of the net by this other decision  uh  would   then you don t care about whether the net makes that distinction  right 
 none 	well  yeah  but this other thing isn t perfect 
 none 	ah 
 none 	so that you bring in some information from the net itself 
 none 	right  o_k  that s a good point 
 none 	yeah  now the only thing that   that bothers me about all this is that i   i   i  
 none 	the   the fact   i  i  it s sort of bothersome that you re getting more deletions 
 none 	yeah 
 none 	but  
 none 	so i might maybe look at  is it due to the fact that um  the probability of the silence at the output of the network  is  uh  too   too high or  
 none 	is too high 
 none 	if it s the case  then multiplying it again by   i  by something  mm hmm 
 none 	yeah  so maybe   so  
 none 	it may not be   it  
 none 	yeah  it   it may be too   it s too high in a sense  like  everything is more like a  um  flat probability 
 none 	yeah 
 none 	yeah 
 none 	so  like  it s not really doing any distinction between speech and nonspeech   or  i mean  different   among classes 
 none 	oh eee hhh 
 none 	uh  yeah 
 none 	yeah 
 none 	mm hmm 
 none 	be interesting to look at the   yeah  for the  
 none 	i wonder if you could do this 
 none 	but if you look at the  um  highly mism  high mismat  the output of the net on the high mismatch case and just look at  you know  the distribution versus the   the other ones  do you   do you see more peaks or something 
 none 	yeah 
 none 	yeah  like the entropy of the   the output  or  
 none 	yeah 
 none 	yeah  for instance 
 none 	it   it seems that the v_a_d network doesn t   well  it doesn t drop  uh  too many frames because the dele  the number of deletion is reasonable 
 none 	but i   bu 
 none 	but it s just when we add the tandem  the final m_l_p  and then   u 
 none 	yeah  now the only problem is you don t want to ta  i guess wait for the output of the v_a_d before you can put something into the other system  cuz that ll shoot up the latency a lot  right  am i missing something here 
 none 	mm hmm 
 none 	but  
 none 	yeah 
 none 	right 
 none 	yeah  so that s maybe a problem with what i was just saying  but   but   i  i guess  
 none 	but if you were gonna put it in as a feature it means you already have it by the time you get to the tandem net  right 
 none 	um  well  we   w  we don t have it  actually  because it s   it has a high rate energy   the v_a_d has a  
 none 	no 
 none 	ah 
 none 	yeah 
 none 	o_k 
 none 	it s kind of done in   i mean  some of the things are  not in parallel  but certainly  it would be in parallel with the   with a tandem net 
 none 	right 
 none 	in time 
 none 	so maybe  if that doesn t work  um  
 none 	but it would be interesting to see if that was the problem  anyway 
 none 	and   and   and then i guess another alternative would be to take the feature that you re feeding into the v_a_d  and feeding it into the other one as well 
 none 	mm hmm 
 none 	mm hmm 
 none 	and then maybe it would just learn   learn it better 
 none 	um  
 create_single_reminder 	but that s   yeah   that s an interesting thing to try to see  if what s going on is that in the highly mismatched condition  it s  um  causing deletions by having this silence probability up   up too high   
 none 	mm hmm 
 none 	at some point where the v_a_d is saying it s actually speech 
 none 	yeah  so  m 
 none 	which is probably true 
 none 	cuz   well  the v_a_  if the v_a_d said   since the v_a_d is   is   is right a lot  uh  
 none 	yeah 
 none 	hmm  anyway 
 none 	might be 
 none 	mm hmm 
 none 	yeah  well  we just started working with it  but these are   these are some good ideas i think 
 none 	mm hmm 
 none 	yeah  and the other thing   well  there are other issues maybe for the tandem  like  uh  well  do we want to  w  uh n 
 none 	do we want to work on the targets  or  like  instead of using phonemes  using more context dependent
 none 	units 
 none 	for the tandem net you mean  hmm 
 none 	well  i m  
 none 	yeah  i m thinking  also  a w  about
 none 	dan s work where he   he trained a network  not on phoneme targets but on the h_m_m state targets 
 none 	and   it was giving s  slightly better results 
 none 	problem is  if you are going to run this on different m  test sets  including large vocabulary  um 
 none 	yeah 
 none 	yeah 
 none 	uh  
 none 	mmm  i was just thinking maybe about  like  generalized diphones  and   come up with a   a reasonable  not too large  set of context dependent units  and  
 none 	i think  
 none 	and  
 none 	yeah 
 none 	and then anyway we would have to reduce this with the k_l_t  so  but   i don t know 
 none 	yeah 
 none 	yeah  well  maybe 
 none 	mm hmm 
 none 	but i d  i d  it   it   i  it s all worth looking at  but it sounds to me like  uh  looking at the relationship between this and the   speech noise stuff is   is   is probably a key thing 
 none 	mm hmm 
 none 	that and the correlation between stuff 
 none 	so if  uh   if the  uh  high mismatch case had been more like the  uh  the other two cases in terms of giving you just a better performance  how would this number have changed 
 none 	mm hmm 
 none 	oh  it would be  
 none 	yeah 
 none 	around five percent better  i guess  if   if   i 
 none 	y  like sixty 
 none 	well  we don t know what s it s gonna be the t_i digits yet  he hasn t got the results back yet 
 none 	yeah 
 none 	if you extrapolate the speechdat car well matched and medium mismatch  it s around  yeah  maybe five 
 none 	uh huh 
 none 	yeah 
 none 	so this would be sixty two 
 none 	sixty  two 
 none 	sixty two  yeah 
 none 	yeah 
 none 	somewhere around sixty  must be 
 none 	which is  
 none 	right  yeah 
 none 	well  it s around five percent  because it s   s  right  if everything is five percent 
 none 	yeah  yeah 
 none 	mm hmm 
 none 	all the other ones were five percent  the  
 none 	i d  i d  i just have the speechdat car right now  so  
 none 	yeah 
 none 	yeah 
 none 	it s running   it shou  we should have the results today during the afternoon  but  
 none 	hmm 
 none 	well 
 none 	hmm 
 none 	well  
 none 	um  
 none 	so i won t be here for  
 none 	when  
 find_calendar_entry 	when do  you   leave   
 none 	uh  i m leaving  next wednesday  
 none 	may or may not be in in the morning  i leave  in the afternoon  
 none 	um  so i  
 find_calendar_entry 	but  you re   are you   you re  not gonna be around  this afternoon   
 none 	yeah 
 find_calendar_entry 	oh  well  i m talking about next week    i m   leaving   leaving   next wednesday   
 none 	oh 
 create_calendar_entry 	this afternoon   uh   oh  right  for the meeting meeting  yeah  that s just cuz of something on campus 
 none 	uh huh 
 none 	ah  o_k  o_k 
 none 	yeah 
 find_calendar_entry 	but  um  yeah  so  next week i won t  and the week after  i won t  cuz i ll be in  finland   
 none 	and the week after that i won t 
 none 	by that time you ll be  
 none 	uh  you ll both be gone from here 
 none 	so there ll be no   definitely no  meeting  on   on  september sixth   
 none 	uh  and  
 find_calendar_entry 	what s  september sixth   
 none 	uh  that s during  eurospeech  
 none 	oh  oh  right  o_k 
 none 	so  uh  sunil will be in oregon  uh  stephane and i will be in denmark 
 none 	uh  
 none 	right 
 none 	so it ll be a few weeks  really  before we have a meeting of the same cast of characters 
 none 	um  but  uh  
 none 	i guess  just  
 none 	i mean  you guys should probably meet  and maybe barry   barry will be around  and   and then uh  uh  we ll start up again with
 none 	dave and   dave and barry and stephane and us on the  uh  twentieth 
 none 	no 
 none 	thirteenth 
 none 	about a month 
 none 	so  uh  you re gonna be gone for the next three weeks or something 
 none 	i m gone for two and a half weeks starting   starting next wed  late next wednesday 
 none 	so that s   you won t be at the next three of these meetings 
 none 	is that right 
 none 	uh  i won t   it s probably four because of   is it three  let s see  twenty third  thirtieth  sixth  that s right  next three 
 none 	and the   the third one won t   probably won t be a meeting  cuz   cuz  uh  su  sunil  stephane  and i will all not be here 
 none 	oh  right  right 
 none 	um  
 none 	mmm  so it s just  uh  the next two where there will be   there  you know  may as well be meetings  but i just won t be at them 
 none 	o_k 
 none 	and then starting up on the thirteenth  uh  we ll have meetings again but we ll have to do without sunil here somehow  so 
 find_calendar_entry 	when do  you   go back   
 none 	thirty first  august  
 none 	yeah 
 none 	yeah 
 none 	so 
 none 	cool  
 find_calendar_entry 	when is the  evaluation     november   or something 
 none 	yeah  it was supposed to be  november fifteenth   has anybody heard anything different 
 find_calendar_entry 	i don t know   the  meeting  in   is  the five and six of december   
 none 	p  s  it s like   yeah  it s tentatively all full   yeah 
 none 	so  
 none 	mm hmm 
 none 	uh  that s a proposed date  i guess 
 none 	yeah  um   so the evaluation should be on a week before or  
 none 	yeah 
 none 	yep 
 none 	but  no  this is good progress 
 none 	so 
 none 	uh  
 none 	o_k 
 none 	guess we re done 
 none 	should we do digits 
 none 	digits  yep 
 none 	transcript l_ dash three five two 
 none 	five seven six four  five six seven zero  four six nine three 
 none 	six eight five zero  nine one three nine  four six four eight 
 none 	three four four two  seven  one eight two 
 none 	one eight seven four  nine nine eight four  five eight nine seven 
 none 	one eight three nine  zero one four five  three six two nine 
 none 	five four three  six two  six six seven three 
 none 	seven one five one  six zero seven two  five nine four two 
 none 	nine eight eight  eight one  nine eight one eight 
 none 	transcript l_ dash three five three 
 none 	seven nine one  one two six  five four two 
 none 	eight seven three  nine eight four  nine six four six 
 none 	three five  seven four  two two  five nine  six one 
 none 	five nine  nine seven  nine eight  five one  eight two 
 none 	seven five four five  six six five three  zero one one two 
 none 	nine nine zero seven  three  nine two six 
 none 	zero one nine  three nine eight  zero three five zero 
 none 	two eight six  two zero two  one eight one 
 none 	transcript l_ dash three five four 
 none 	two nine six  eight six three  seven six zero five 
 none 	seven one five six  one three seven zero  four two five six 
 none 	nine five three seven  zero  two one eight 
 none 	one eight six three  nine eight seven one  one zero two nine 
 none 	three five three three  four nine three nine  zero three one five 
 none 	four zero eight six  four eight  nine five zero  three 
 none 	eight zero two eight  nine  seven nine one 
 none 	eight nine  nine one  three five  one eight  zero four 
 none 	transcr  transcript l_ dash three five zero 
 none 	eight four four  two three two  two six one seven 
 none 	one two  eight three  one nine  nine one  one three 
 none 	four five  two four  five nine  six two  three three 
 none 	three  eight four six  five five  two zero two  five 
 none 	four  six nine three  one three  three six four  six 
 none 	two  eight four six  four one  four four six  four 
 none 	two nine nine four  three two eight seven  eight seven four two 
 none 	four two eight  two zero  seven four eight zero 
 none 	o_k 
 none 	it s a wrap 
